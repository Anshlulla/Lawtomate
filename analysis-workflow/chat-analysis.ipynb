{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "from langchain.chains import create_retrieval_chain, create_history_aware_retriever\n",
    "from langchain_chroma import Chroma\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.messages import HumanMessage, AIMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_community.document_loaders.pdf.PyPDFLoader at 0x1867e94b0b0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = r\"C:\\Users\\Ansh Lulla\\VS-Code\\Full_Stack_Frontend\\summarization-workflow\\SampleContract-Shuttle.pdf\"\n",
    "loader = PyPDFLoader(file_path=file_path)\n",
    "loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'producer': 'Acrobat Distiller 9.3.2 (Windows)', 'creator': 'PScript5.dll Version 5.2.2', 'creationdate': '2012-07-11T18:52:58-07:00', 'author': 'kshultz', 'moddate': '2012-07-11T18:52:58-07:00', 'title': 'Microsoft Word - SampleContract-Shuttle', 'source': 'C:\\\\Users\\\\Ansh Lulla\\\\VS-Code\\\\Full_Stack_Frontend\\\\summarization-workflow\\\\SampleContract-Shuttle.pdf', 'total_pages': 10, 'page': 0, 'page_label': '1'}, page_content='Page 1 \\nSample Contract \\n \\nContract No.___________ \\nPROFESSIONAL SERVICES AGREEMENT \\n \\n \\nTHIS AGREEMENT made and entered into this _______day of                      , 20     by and between the SANTA \\nCRUZ COUNTY REGIONAL TRANSPORTATION COMMISSION, hereinafter called COMMISSION, and \\n________    ____, hereinafter called CONSULTANT for __________________ (services/project name).   \\n \\n1. DUTIES.  \\nA. CONSULTANT agrees to exercise special skill to accomplish the following results in a manner \\nreasonably satisfactory to COMMISSION: ______________________________, as specified in Exhibit \\nA: Scope of Services, which by this reference is incorporated herein. \\n \\nB. CONSULTANT shall provide the personnel listed below to perform the above-specified services, which \\npersons are hereby designated as key personnel under this Agreement.   \\n Name     F i r m     F u n c t i o n  \\n         P r i n c i p a l  i n  C h a r g e  \\n         P r o j e c t  M a n a g e r  \\n \\nC. No person named in paragraph B of this Section, or his or her successor, shall be removed or replaced by \\nCONSULTANT, nor shall his or her agreed-upon function hereunder be changed, without the prior \\nwritten consent of COMMISSION.  Such consent shall not be unreasonably withheld. \\n \\nD. CONSULTANT’S PROGRESS REPORTS AND/OR MEETINGS \\n1) The CONSULTANT shall submit written progress reports with each invoice. The report should be \\nsufficiently detailed for the Contract Manager to determine if the CONSULTANT is performing to \\nexpectations or is on schedule; to provide communication of interim findings; and to sufficiently \\naddress any difficulties or special problems encountered, so remedies can be developed. \\n2) The CONSULTANT’s Project Manager shall meet with the COMMISSION’s Contract Manager, as \\nneeded, to discuss progress on the contract. \\n \\n2. COMPENSATION.  \\nIn consideration for CONSULTANT accomplishing said result, COMMISSION agrees to pay \\nCONSULTANT as follows:  \\nA. Total payment is not to exceed $_____for time and materials at the rates and conditions set forth in \\nExhibit B: Fee Schedule, which by this reference is incorporated herein.  \\n \\nB. In no event, will the CONSULTANT be reimbursed for overhead costs at a rate that exceeds the \\noverhead rate set forth in the Fee Schedule.  \\n \\nC. Transportation and subsistence costs shall not exceed the rates authorized to employees under current \\nU.S. General Service Administration rules. \\n \\nD. Reimbursable expenses will be billed by CONSULTANT and processed for payment upon approval of \\nthe Contract Manager. \\n \\nE. Progress payments will be made no less than monthly in arrears based on satisfactory services provided \\nand actual allowable incurred costs. A pro rata portion of the CONSULTANT’s fixed fee, if applicable, \\nwill be included in the monthly progress payments. If CONSULTANT fails to submit the required')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs = loader.load()\n",
    "docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43\n"
     ]
    }
   ],
   "source": [
    "splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=150)\n",
    "chunks = splitter.split_documents(docs)\n",
    "print(len(chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OllamaEmbeddings(model='llama3.2:latest', base_url=None, client_kwargs={}, mirostat=None, mirostat_eta=None, mirostat_tau=None, num_ctx=None, num_gpu=None, keep_alive=None, num_thread=None, repeat_last_n=None, repeat_penalty=None, temperature=None, stop=None, tfs_z=None, top_k=None, top_p=None)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_model = OllamaEmbeddings(model=\"llama3.2:latest\")\n",
    "embedding_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_chroma.vectorstores.Chroma at 0x1867ebe2e70>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorstore = Chroma.from_documents(documents=chunks, embedding=embedding_model)\n",
    "vectorstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VectorStoreRetriever(tags=['Chroma', 'OllamaEmbeddings'], vectorstore=<langchain_chroma.vectorstores.Chroma object at 0x000001867EBE2E70>, search_kwargs={})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever = vectorstore.as_retriever()\n",
    "retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"\n",
    "    You are an expert at analysing Legal Documents and Contracts. Answer the questions regarding the user input (pdf or a docs file) and respond in a clear manner with considering the legal terms mentioned in the document.\n",
    "    Here's the context:\n",
    "    {context}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", system_prompt),\n",
    "    (\"human\", \"{input}\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatOllama(model='llama3.2:latest', temperature=0.4)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm = ChatOllama(model=\"llama3.2:latest\", temperature=0.4)\n",
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableBinding(bound=RunnableBinding(bound=RunnableAssign(mapper={\n",
       "  context: RunnableLambda(format_docs)\n",
       "}), kwargs={}, config={'run_name': 'format_inputs'}, config_factories=[])\n",
       "| ChatPromptTemplate(input_variables=['context', 'input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context'], input_types={}, partial_variables={}, template=\"\\n    You are an expert at analysing Legal Documents and Contracts. Answer the questions regarding the user input (pdf or a docs file) and respond in a clear manner with considering the legal terms mentioned in the document.\\n    Here's the context:\\n    {context}\\n\"), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])\n",
       "| ChatOllama(model='llama3.2:latest', temperature=0.4)\n",
       "| StrOutputParser(), kwargs={}, config={'run_name': 'stuff_documents_chain'}, config_factories=[])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa_chain = create_stuff_documents_chain(llm=llm, prompt=prompt)\n",
    "qa_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableBinding(bound=RunnableAssign(mapper={\n",
       "  context: RunnableBinding(bound=RunnableLambda(lambda x: x['input'])\n",
       "           | VectorStoreRetriever(tags=['Chroma', 'OllamaEmbeddings'], vectorstore=<langchain_chroma.vectorstores.Chroma object at 0x000001867EBE2E70>, search_kwargs={}), kwargs={}, config={'run_name': 'retrieve_documents'}, config_factories=[])\n",
       "})\n",
       "| RunnableAssign(mapper={\n",
       "    answer: RunnableBinding(bound=RunnableBinding(bound=RunnableAssign(mapper={\n",
       "              context: RunnableLambda(format_docs)\n",
       "            }), kwargs={}, config={'run_name': 'format_inputs'}, config_factories=[])\n",
       "            | ChatPromptTemplate(input_variables=['context', 'input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context'], input_types={}, partial_variables={}, template=\"\\n    You are an expert at analysing Legal Documents and Contracts. Answer the questions regarding the user input (pdf or a docs file) and respond in a clear manner with considering the legal terms mentioned in the document.\\n    Here's the context:\\n    {context}\\n\"), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])\n",
       "            | ChatOllama(model='llama3.2:latest', temperature=0.4)\n",
       "            | StrOutputParser(), kwargs={}, config={'run_name': 'stuff_documents_chain'}, config_factories=[])\n",
       "  }), kwargs={}, config={'run_name': 'retrieval_chain'}, config_factories=[])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_chain = create_retrieval_chain(retriever=retriever, combine_docs_chain=qa_chain)\n",
    "rag_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This appears to be a contract between a Commission (likely a government agency or organization) and a Consultant (a private company or individual providing services). The contract outlines the terms and conditions of their agreement, including:\n",
      "\n",
      "1. The scope of work and responsibilities of both parties.\n",
      "2. Payment terms and conditions, including the requirement for prior approval of work before payment.\n",
      "3. Authority to act on behalf of the Commission.\n",
      "4. Restrictions on changes to the project or Consultant's role without Commission consent.\n",
      "5. Requirements for progress reports and meetings between the Consultant and Commission.\n",
      "\n",
      "The contract also includes specific details about invoicing procedures, such as timing and required information for reimbursement.\n",
      "\n",
      "Overall, this document appears to be a standard contract for consulting services, with provisions that balance the needs of both parties to ensure successful project execution.\n"
     ]
    }
   ],
   "source": [
    "response = rag_chain.invoke({\"input\": \"What is the document about?\"})\n",
    "print(response[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['chat_history', 'input'], input_types={'chat_history': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x00000186738A59E0>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]]}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='\\n    Given a chat history and the latest user query, which might be a reference context in the chat history, formulate a standalone question which can be understood without the chat history. Do NOT answer the question, reformulate it if needed otherwise return it as it is.    \\n'), additional_kwargs={}), MessagesPlaceholder(variable_name='chat_history'), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contextualize_q_system_prompt = (\"\"\"\n",
    "    Given a chat history and the latest user query, which might be a reference context in the chat history, formulate a standalone question which can be understood without the chat history. Do NOT answer the question, reformulate it if needed otherwise return it as it is.    \n",
    "\"\"\")\n",
    "\n",
    "contextualize_q_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", contextualize_q_system_prompt),\n",
    "    MessagesPlaceholder(\"chat_history\"),\n",
    "    (\"human\", \"{input}\")\n",
    "])\n",
    "\n",
    "contextualize_q_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableBinding(bound=RunnableBranch(branches=[(RunnableLambda(lambda x: not x.get('chat_history', False)), RunnableLambda(lambda x: x['input'])\n",
       "| VectorStoreRetriever(tags=['Chroma', 'OllamaEmbeddings'], vectorstore=<langchain_chroma.vectorstores.Chroma object at 0x000001867EBE2E70>, search_kwargs={}))], default=ChatPromptTemplate(input_variables=['chat_history', 'input'], input_types={'chat_history': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x00000186738A59E0>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]]}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='\\n    Given a chat history and the latest user query, which might be a reference context in the chat history, formulate a standalone question which can be understood without the chat history. Do NOT answer the question, reformulate it if needed otherwise return it as it is.    \\n'), additional_kwargs={}), MessagesPlaceholder(variable_name='chat_history'), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])\n",
       "| ChatOllama(model='llama3.2:latest', temperature=0.4)\n",
       "| StrOutputParser()\n",
       "| VectorStoreRetriever(tags=['Chroma', 'OllamaEmbeddings'], vectorstore=<langchain_chroma.vectorstores.Chroma object at 0x000001867EBE2E70>, search_kwargs={})), kwargs={}, config={'run_name': 'chat_retriever_chain'}, config_factories=[])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_aware_retriever = create_history_aware_retriever(llm, retriever, contextualize_q_prompt)\n",
    "history_aware_retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", system_prompt),\n",
    "    MessagesPlaceholder(\"chat_history\"),\n",
    "    (\"human\", \"{input}\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableBinding(bound=RunnableAssign(mapper={\n",
       "  context: RunnableBinding(bound=RunnableBranch(branches=[(RunnableLambda(lambda x: not x.get('chat_history', False)), RunnableLambda(lambda x: x['input'])\n",
       "           | VectorStoreRetriever(tags=['Chroma', 'OllamaEmbeddings'], vectorstore=<langchain_chroma.vectorstores.Chroma object at 0x000001867EBE2E70>, search_kwargs={}))], default=ChatPromptTemplate(input_variables=['chat_history', 'input'], input_types={'chat_history': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x00000186738A59E0>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]]}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='\\n    Given a chat history and the latest user query, which might be a reference context in the chat history, formulate a standalone question which can be understood without the chat history. Do NOT answer the question, reformulate it if needed otherwise return it as it is.    \\n'), additional_kwargs={}), MessagesPlaceholder(variable_name='chat_history'), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])\n",
       "           | ChatOllama(model='llama3.2:latest', temperature=0.4)\n",
       "           | StrOutputParser()\n",
       "           | VectorStoreRetriever(tags=['Chroma', 'OllamaEmbeddings'], vectorstore=<langchain_chroma.vectorstores.Chroma object at 0x000001867EBE2E70>, search_kwargs={})), kwargs={}, config={'run_name': 'retrieve_documents'}, config_factories=[])\n",
       "})\n",
       "| RunnableAssign(mapper={\n",
       "    answer: RunnableBinding(bound=RunnableBinding(bound=RunnableAssign(mapper={\n",
       "              context: RunnableLambda(format_docs)\n",
       "            }), kwargs={}, config={'run_name': 'format_inputs'}, config_factories=[])\n",
       "            | ChatPromptTemplate(input_variables=['chat_history', 'context', 'input'], input_types={'chat_history': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x00000186738A59E0>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]]}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context'], input_types={}, partial_variables={}, template=\"\\n    You are an expert at analysing Legal Documents and Contracts. Answer the questions regarding the user input (pdf or a docs file) and respond in a clear manner with considering the legal terms mentioned in the document.\\n    Here's the context:\\n    {context}\\n\"), additional_kwargs={}), MessagesPlaceholder(variable_name='chat_history'), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])\n",
       "            | ChatOllama(model='llama3.2:latest', temperature=0.4)\n",
       "            | StrOutputParser(), kwargs={}, config={'run_name': 'stuff_documents_chain'}, config_factories=[])\n",
       "  }), kwargs={}, config={'run_name': 'retrieval_chain'}, config_factories=[])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa_chain = create_stuff_documents_chain(llm, qa_prompt)\n",
    "rag_chain = create_retrieval_chain(history_aware_retriever, qa_chain)\n",
    "rag_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the provided contract, the Commission party (COMMISSION) is responsible for:\n",
      "\n",
      "1. **Payment**: The Commission agrees to make payments to the Consultant in accordance with the terms and conditions of this Agreement.\n",
      "\n",
      "2. **Authorization**: The Executive Director of COMMISSION or their designee has the authority to act for and exercise any rights of COMMISSION as set forth in this Agreement, subsequent to, and in accordance with the authorization granted by COMMISSION.\n",
      "\n",
      "3. **Review and Approval Process**: The Commission requires the Consultant to furnish all necessary copies of data needed to complete the review and approval process for deliverables.\n",
      "\n",
      "4. **Ownership and Title**: Upon completion of all work under this contract, ownership and title to custom letters, reports, documents, plans, specifications, and estimates (deliverables) will automatically be vested in COMMISSION; no further agreement is necessary to transfer ownership.\n",
      "\n",
      "5. **Confidentiality**: Information derived from deliverables is deemed confidential and may not be disclosed to any other party without the express prior written consent of COMMISSION.\n",
      "\n",
      "6. **Insurance Coverage**: The Commission requires the Consultant to maintain insurance coverage for the duration of this contract, with a minimum of 30 days' notice prior to expiration, and new Certificate of Insurance subject to approval by COMMISSION.\n",
      "\n",
      "7. **Compliance with Requirements**: The Commission expects the Consultant to comply with the requirements outlined in the contract, including providing written progress reports, report of expenditures, and other documentation as mutually agreed upon.\n",
      "\n",
      "In summary, the Commission party is responsible for ensuring that payments are made, that deliverables meet certain standards, and that confidentiality agreements are respected. They also have authority to authorize actions on behalf of COMMISSION and require insurance coverage from the Consultant.\n",
      "---------------------\n",
      "Let's break down the responsibilities of the Commission party (COMMISSION) in more detail:\n",
      "\n",
      "**Payment and Compensation**\n",
      "\n",
      "* The Commission agrees to pay the Consultant for their services as outlined in the Fee Schedule.\n",
      "* Payments are made in accordance with the terms and conditions of this Agreement, including any applicable payment schedules or deadlines.\n",
      "\n",
      "**Authorization and Decision-Making**\n",
      "\n",
      "* The Executive Director of COMMISSION or their designee has the authority to act for and exercise any rights of COMMISSION as set forth in this Agreement.\n",
      "* This includes making decisions regarding the scope of work, payment amounts, and other matters related to the contract.\n",
      "\n",
      "**Review and Approval Process**\n",
      "\n",
      "* The Consultant is required to furnish all necessary copies of data needed to complete the review and approval process for deliverables.\n",
      "* COMMISSION reserves the right to request additional information or clarification as needed.\n",
      "\n",
      "**Ownership and Title**\n",
      "\n",
      "* Upon completion of all work under this contract, ownership and title to custom letters, reports, documents, plans, specifications, and estimates (deliverables) will automatically be vested in COMMISSION.\n",
      "* This means that COMMISSION retains ownership of any intellectual property developed during the course of the project.\n",
      "\n",
      "**Confidentiality**\n",
      "\n",
      "* Information derived from deliverables is deemed confidential and may not be disclosed to any other party without the express prior written consent of COMMISSION.\n",
      "* This includes any proprietary or sensitive information shared between the Consultant and COMMISSION.\n",
      "\n",
      "**Insurance Coverage**\n",
      "\n",
      "* The Commission requires the Consultant to maintain insurance coverage for the duration of this contract, with a minimum of 30 days' notice prior to expiration.\n",
      "* New Certificate of Insurance must be submitted to COMMISSION for approval before taking effect.\n",
      "\n",
      "**Compliance with Requirements**\n",
      "\n",
      "* COMMISSION expects the Consultant to comply with the requirements outlined in the contract, including providing written progress reports, report of expenditures, and other documentation as mutually agreed upon.\n",
      "* The Consultant is responsible for ensuring that all work is completed in accordance with this Agreement and any applicable laws or regulations.\n",
      "\n",
      "Overall, the Commission party has significant responsibilities related to payment, decision-making, review and approval, ownership, confidentiality, insurance, and compliance. By fulfilling these obligations, COMMISSION can ensure a successful partnership with the Consultant.\n"
     ]
    }
   ],
   "source": [
    "chat_history = []\n",
    "question = \"What is the scope of work and responsibilities of the Commission party\"\n",
    "response1 = rag_chain.invoke({\"input\": question, \"chat_history\": chat_history})\n",
    "\n",
    "chat_history.extend([\n",
    "    HumanMessage(content=question),\n",
    "    AIMessage(content=response1[\"answer\"])\n",
    "])\n",
    "\n",
    "question2 = \"Tell me more about it.\"\n",
    "response2 = rag_chain.invoke({\"input\": question2, \"chat_history\": chat_history})\n",
    "print(response1[\"answer\"])\n",
    "print(\"---------------------\")\n",
    "print(response2[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
