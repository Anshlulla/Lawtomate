{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain.schema import AIMessage, SystemMessage, HumanMessage\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'C:\\\\Users\\\\Ansh Lulla\\\\VS-Code\\\\Langchain_tutorial\\\\summarization\\\\PlotPoint_Research_Paper.pdf', 'page': 0}, page_content='PlotPoint - An AI-Driven Framework for\\nAutomated Movie Scriptwriting and Scene\\nGeneration\\nAnsh Lulla, Aayush Koul, Rampalli Agni Mithra,\\nAniket K. Shahade ∗, Mayur Gaikwad, Shruti Patil\\nDepartment of AIML ,\\nSymbiosis Institute of Technology, Pune Campus , Symbiosis International (Deemed University), Pune, India\\n∗aniket.shahade@sitpune.edu.in\\nAbstract—Script writing has become a labor-intensive\\nprocess, especially when tailored to specific scene setting,\\nculture or character. Recent advancements in the field\\nof Natural Language Processing and Deep Learning\\nalgorithms have made it possible to automate the process\\nof script writing. With a simple prompt, it is possible to\\ngenerate the entire script for a movie, which would be\\ncustomizable by the input’s creativity and imagination.\\nRetrieval Augmented Generation has the potential to\\nfacilitate rapid prototyping of movie scripts by ingesting\\nthe data in a vector database and retrieving scripts\\nwhich would be most similar with the input prompt.\\nThese retrieved scripts would act as part of context\\nfor the Large Language Models and prevent them from\\nhallucinating. This approach enhances the potential of\\nthese LLMs to generate context-specific output which is\\nessential when taking into consideration the fine details\\nmentioned in the input prompt. Fine-tuning LLMs is\\nanother approach which helps downstream the LLMs to\\nlearn how to generate movie scripts. With the inclusion\\nof visualizing the script elements, one can conveniently\\nturn their ideas into a script and scenes. Combining the\\ncapabilities of Stable Diffusion with the LLMs, script\\ngeneration can be extended to scene generation. On\\ntraining multiple models on the dataset of movie scripts,\\nGemini-Pro (for RAG) was very effective with a cosine\\nsimilarity of 0.5713 whereas GPT-2 and Bloom (for fine-\\ntuning) showed a cosine similarity of 0.5011 and 0.5058\\nrespectively between the input prompt and the generated\\nscript, and perplexity of 1.7443 for GPT-2 and 1.6892\\nfor Bloom showing that GPT-2 is able to generate scripts\\nwhich are coherent and relevant to the input prompt and\\nhas thus understood the language structure and patterns\\nwell. A CLIP score of 0.3061 was achieved with using\\nCompVis for generation of movie scenes.\\nIndex Terms—NLP, Deep Learning, RAG, LLMs, Sta-\\nble Diffusion\\nI. I NTRODUCTION\\nA. Background\\nScriptwriting is an important part of the entertain-\\nment industry. Scripts contain dialogues, scene settings\\nand character development which makes it a time\\nconsuming and arduous process, particularly when\\ntailored content is needed for movies, television shows,\\ngaming and marketing.\\nIt is very important to create a vision of the scene to\\nallow the director to create a scene which engages and\\nappeals to the audience. Along with the increased de-\\nmand for personalized content, automating the process\\nof scriptwriting using Natural Language Processing\\nhas emerged as a promising solution to the problem\\nof generating scalable, high quality scripts along with\\nthe growing demand in the industry.\\nLeveraging Deep Learning models to create com-\\nplex and coherent scripts by retaining context dur-\\ning the generation of the entire script, allowing the\\nscriptwriter to focus on improving the idea itself,\\nsignificantly reduces the time and effort required for\\nscriptwriting.\\nB. Domain\\nNatural Language Generation is a subfield of Natu-\\nral Language Processing. It has proven to be a reliable\\ntool in generating complex and coherent text while\\nretaining contextual nuances throughout the generation\\nprocess.\\nLeveraging deep learning techniques allowing ma-\\nchines to learn the sequential patterns in text, NLG\\nsystems are able to use pre-existing datasets of movie\\nscripts and dialogues to create an understanding of\\nhuman-like dialogue structures. This understanding\\ncan be further used for the purpose of personalized\\nscript generation.\\nExisting tools primarily focus on general text gen-\\neration but have research gaps for developing systems'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\Ansh Lulla\\\\VS-Code\\\\Langchain_tutorial\\\\summarization\\\\PlotPoint_Research_Paper.pdf', 'page': 0}, page_content='can be further used for the purpose of personalized\\nscript generation.\\nExisting tools primarily focus on general text gen-\\neration but have research gaps for developing systems\\nthat allow personalization of scripts which include\\ncustomizable elements such as character description,\\nbehavior, and other specifications defined in the input\\nprompt about the scene and setting.\\nC. Motivation\\nStorytelling remains a crucial method of communi-\\ncation in films, gaming and marketing, thereby stream-\\nlining the process of script generation can enable\\nrapid prototyping and customization of inputs such as\\ntime of the day, number of characters and character\\ndescriptions can pioneer significant improvements in\\nplot complexity and quality by allowing writers to\\nfocus more on the plot itself rather than the process of'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\Ansh Lulla\\\\VS-Code\\\\Langchain_tutorial\\\\summarization\\\\PlotPoint_Research_Paper.pdf', 'page': 1}, page_content='writing it. This would reduce the barriers for anyone\\nwho wishes to turn their ideas into scripts, promoting\\ncreative freedom and enabling the refinement of ideas\\nrather than focusing on the mechanics of the scripts.\\nD. Contribution\\nAutomation of script generation has the potential\\nof transforming how humans develop and consume\\ncontent globally. As more and more people will have\\nthe convenience of creating high quality scripts out\\nof their imagination and ideas, simply by providing\\nprompts and necessary context to the LLMs or RAG\\nsystems fine-tuned on the movie script’s dataset, fa-\\ncilitating the generation of scripts and make changes\\naccording to preferences without worrying about the\\nback-end complexities of text generation.\\nII. L ITERATURE SURVEY\\nCelikyilmaz A et al. conducted a survey of evalua-\\ntion metrics for text generation including both human\\nand automated methods. Using word embeddings like\\nWord2Vec, Seq2Seq models like GRU and LSTM,\\nBERT and GPT, they highlighted the strengths of\\nhybrid metrics on datasets like WMT, Twitter Dialogue\\nand Daily Mail. Though effective, the study notes the\\nchallenges faced in human evaluation methods and\\nhence the need for standardized methods [1].\\nVasvani et al. introduced the Transformer architec-\\nture which is a fully attention-based approach which\\nenhances text generation tasks. Positional word em-\\nbeddings, shared weight matrix embeddings were used\\nalong with models like GCN, DeepWalk and Planetoid,\\non WMT-2014 dataset. The models though very pow-\\nerful, face a lot of challenges in terms of scalability\\ndue to the quadratic attention complexity [2].\\nLi et al. proposed the Diffusion-LM approach,\\nwhich was effective for controllable text generation\\nwithout the need for retraining. It has been tested\\non E2E and ROCStories datasets, using clustering\\nof learned embeddings, demonstrating strong BLEU-4\\nand ROUGE-L scores. Despite its effectiveness, there\\nare potential issues with high-dimensional tuning and\\nstability of the model in various scenarios [3].\\nFan et al. used over 300 thousand narratives to\\nexplore hierarchical story generation. They used pre-\\ntrained embeddings like FastText with fusion of Con-\\nvolutional, Seq2Seq and self-attention models. Due\\nto the complex architecture, they faced challenges\\nin tuning, but the low perplexity scores show good\\ncoherence in the test dataset [4].\\nBrown et al. showcased the flexibility and adaptabil-\\nity of GPT-3 models in tasks like sentiment analysis\\nand cloze tests. Although GPT-3 models struggled with\\nfine-tuning demands and interpretability issues, they\\nprovided high precision on datasets such as Common-\\nCrawl and WebText2 [5].\\nTambwekar et al. used the encoder-decoder archi-\\ntecture to introduce a reward-shaping technique to\\ngenerate plot-directed stories. They used WordNet and\\nVerbNet Sysnets embeddings and DRL models and\\nachieved low perplexity scores, but the comparisons\\nwere made on the existing corpus and not the unseen\\nplots [6].\\nMangal et al. used the Game of Thrones data to eval-\\nuate different RNN architectures like GRU, LSTM and\\nBidirectional RNN. LSTM and GRU models though\\ngenerated coherent texts, they failed to capture the\\nintricate character descriptions and interactions, indi-\\ncating room for improvement in complex sequences\\n[7].\\nYao et al. introduce the Plan-and-Write framework,\\nintegrating static and dynamic schema for coherence in\\nstory. Using GloVe embeddings and Seq2Seq models\\non ROCStories dataset, the models performed well but\\nfailed to handle complex narrative relationships and\\nevents [8].\\nZhu et al. develop a narrative-guided script genera-\\ntion model by using the Word2Vec embedding with\\nDL2R and MVLSTM models on the GraphMovie\\ndataset. The approach adheres strictly to the structured\\ndesign leading to limitation of creative storytelling [9].\\nBhat et al. apply hierarchical encoders to screen-\\nplay modelling, to classification of genre and mood\\nclassification using Bag-of-Embeddings and GRU on'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\Ansh Lulla\\\\VS-Code\\\\Langchain_tutorial\\\\summarization\\\\PlotPoint_Research_Paper.pdf', 'page': 1}, page_content='Bhat et al. apply hierarchical encoders to screen-\\nplay modelling, to classification of genre and mood\\nclassification using Bag-of-Embeddings and GRU on\\nthe ScriptBase-J corpus [10].\\nFang et al. used the WritingPrompts and WikiPlots\\ndatasets and proposed a fine-grained, controllable text\\ngeneration model that builds on cascaded events. They\\nused GloVe, TextRank, RAKE and BERT embed-\\ndings with models like FUSION, FIST and PSA and\\nachieved strong BLEU and ROUGE scores [11].\\nSakaguchi et al. developed the proScript framework\\nto solve the problem of producing high-quality par-\\ntially ordered scripts for everyday scenarios. The study\\nestablished two complementary tasks: script edge pre-\\ndiction and script generation, using a crowd sourced\\ndataset of 6,414 scripts, which was significantly larger\\nthan previous datasets. With the use of pre-trained\\nlanguage models such as T5, the models showed no-\\ntable gains in event generation and script organization,\\nattaining an F1 score of up to 75.71 in edge prediction.\\nDespite the progress, issues like generalization outside\\nof the domain and attaining human-level performance\\npoint to areas that require further study [12].\\nDayo et al. analyzed how AI has transformed con-\\ntemporary scriptwriting, emphasizing how it affects\\nthe cinema business and story development. They\\ncarried out a thorough examination of AI tools such\\nas AI authoring and Natural Language Processing\\n(NLP), showcasing how they might improve interactive\\nstorytelling, character development, and narrative cre-\\nation. Case studies like ”Sunspring” (2016) and ”Zone\\nOut” (2022) showed how human creativity and AI-\\ngenerated content may work together. Despite these\\ndevelopments, there are still issues to be resolved, such\\nas moral dilemmas, how to balance human and AI co-'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\Ansh Lulla\\\\VS-Code\\\\Langchain_tutorial\\\\summarization\\\\PlotPoint_Research_Paper.pdf', 'page': 2}, page_content='operation, and the requirement to preserve narrative’s\\nemotional nuance and cultural authenticity [13].\\nIII. M ETHODOLOGY\\nA. Model Architecture\\nThe Transformer architecture [2] is composed of\\ntwo parts: Encoder and the Decoder. The Encoder is\\nresponsible for processing the input sequences and\\ngenerating useful representations of the input (em-\\nbeddings). The Decoder is responsible for using the\\nencoder’s outputs and target sequences to generate\\npredictions.\\nTransformers address the issue of Seq2Seq models\\nthrough Attention Mechanism. In Seq2Seq models, the\\ndecoder uses the ”summarized” version of the input\\nsequence done by the encoder, which raises the issue\\nof lack of context. The Decoder cannot focus on the\\nimportant parts of the input which leads to sub-optimal\\noutputs.\\nThrough Attention Mechanism, transformers gain\\nthe ability to produce context-specific outputs by de-\\ntermining the relevance of each of the tokens in the\\nsequence with respect to others and focusing on certain\\naspects of the input which would help generate optimal\\noutputs. The type of attention mechanisms used in\\nTransformer architecture are Multi-Head and Masked\\nMulti-Head attention mechanisms.\\nFig. 1: Transformer Architecture\\nAttention Mechanism computes the attention scores\\nfor each token to evaluate the relevance of the token\\nwith respect to the output sequence to be generated.\\nTo compute the attention score, three vectors are used:\\n1) Query Matrix (Q): It represents the part of\\ninput sequence the model is focusing on.\\n2) Key Matrix (K): It represents the information\\ncarried by each input token.\\n3) Value Matrix (V): It represents the correspond-\\ning output tokens for which the input tokens are\\nbeing evaluated.\\nEach of the input elements (word embeddings for\\neach token) is projected onto these vectors via some\\nlearned weight matrices. Mathematically, the input\\nrepresentations are defined as:\\nQ = XWQ (1)\\nK = XWK (2)\\nV = XWV (3)\\nwhere X is Input matrix, and WQ, WK, WV are the\\nlearned weight matrices.\\nThe attention score then calculated as a dot product\\nof each element of the Query and Key matrices (q and\\nk respectively) and is scaled using a scaling factor -\\nsquare root of the key dimension dk to prevent large\\nvalues leading to unstable gradients.\\nScore(q, k) = q · k√dk\\n(4)\\nThe raw scores are passed through a softmax func-\\ntion which normalizes these scores to get a probability\\ndistribution, with each probability representing the\\nimportance of the input element.\\nαij = softmax\\n\\x12qi · kj√dk\\n\\x13\\n(5)\\nFinally, the weighted sum of each of the value\\nvectors (v) is computed with the attention scores being\\nthe weights.\\nAttention(Q, K, V) =\\nnX\\nj=1\\nαijvj (6)\\nThe above calculations are for a single-head at-\\ntention mechanism, since transformers use multi-head\\nattention mechanism, multiple single-head attention\\nmechanisms run parallelly and their individual results\\nare concatenated. Along with the concatenated heads\\nand a learned weight matrix WO, the Multi-Head\\nattention score is calculated.\\nMulti-Head(Q, K, V) =Concat(head1, . . . ,headh)WO\\n(7)\\nThe attention mechanism thus assists the transform-\\ners architecture to focus on the important parts of the\\ninput and generate contextually relevant outputs.\\nB. RAG Architecture\\nRAG - Retrieval Augmented Generation, is a frame-\\nwork used to help LLMs provide a better response\\nby providing relevant information from an external\\ndatabase (usually a vector database) which reduces\\nthe chance that the LLM will lead to inaccurate or\\nincomplete responses.'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\Ansh Lulla\\\\VS-Code\\\\Langchain_tutorial\\\\summarization\\\\PlotPoint_Research_Paper.pdf', 'page': 3}, page_content='Fig. 2: RAG Pipeline\\nLLMs have a tendency of hallucinating when it\\ncomes to generating responses and have a limitation\\nof knowledge, hence RAG helps mitigate these limi-\\ntations of LLMs and provide better responses.\\nThe scripts used for training are converted into\\nchunks using the Recursive Character Text splitter\\nwhich recursively identifies and segments scripts en-\\nsuring that each chunk maintains its coherent context\\nand structure,thereby focusing on specific character\\nscenes and transitions.\\nThese chunks are then converted into embeddings\\nusing sentence transformer in order to capture the\\nsemantic relationships within the chunks and between\\nthe chunks. The chunk embeddings are then stored in a\\nFAISS vector database, along with their metadata like\\nindex of the chunk and name of the movie that chunk\\nis from.\\nThis vector database is used for performing semantic\\nsimilarity search based on a query to retrieve top ’k’\\nchunks which are most similar to the query which will\\nbe used as contextual information for the LLMs, so as\\nto generate contextually relevant scripts (k value used\\nfor the proposed methodology is 5).\\nThe above semantic similarity search is further\\noptimized using IVF-Flat (Inverted File with Flat\\nQuantization), which segregates all the chunks into\\nclusters, this would help the RAG Framework to focus\\non only limited number of chunks for fetching the\\nsemantically most similar chunks rather than searching\\nin the entire database. The clustering is done using\\nthe K-Means Clustering, where in the data points\\nbeing close to each other are considered as ”similar”\\nand are therefore grouped in one cluster. Doing so\\nfor the entire vector database would help divide all\\nthe chunk embeddings into clusters. IVF-Flat thus\\nsignificantly improves upon the time complexity of\\nsearching especially when dealing with a dataset of\\nlarge number of movie scripts.\\nFor a given Query Embedding, the algorithm calcu-\\nlates the L2 Norm (Euclidean Distance) between the\\nQuery Embedding and the Centroid of each region\\n(cluster), in order to narrow-down the search and\\nperform semantic similarity search within that cluster\\nfor the top ’k’ chunks.\\nThe top ’k’ chunks are evaluated using cosine sim-\\nilarity (to measure degree of similarity between two\\nvectors or embeddings) and Euclidean Distance, this\\nway the retrieved chunks are ranked based on how high\\nis the cosine similarity and how low the Euclidean\\nDistance between the Query Embedding and chunk\\nembeddings (with priority given to cosine similarity).\\nThese retrieved chunks (along with their metadata)\\nwill be provided to the LLM to generate an accurate\\nscript which adheres to the input query while prevent-\\ning the LLM from hallucinating. The LLM used for\\nRAG implementation is Gemini-Pro.\\n1) Gemini-Pro\\nGemini-Pro developed by Google DeepMind, is\\na state-of-the-art LLM with enhanced capabilities\\nfor Natural Language Generation and Understanding\\ntasks. It excels in complex reasoning thereby gener-\\nating nuanced and coherent movie scripts tailored to\\nthe specifications. With the inclusion of RAG, Gemini-\\nPro’s potential hallucination is successfully mitigated.\\nGemini-Pro has the ability to use either decoder-\\nonly or encoder-decoder architecture, based on the\\nstructure and type of task, making it a versatile LLM.\\nC. Fine-Tuning LLMs\\nFine-tuning Large Language Models involves using\\na pre-trained model and down-streaming it to a specific\\ntask like script generation by training it on the task-\\nspecific dataset. This process modifies the weights of\\nthe pre-trained model to align the predictions accord-\\ning to the specific task.\\nUsing the embeddings of these pre-trained mod-\\nels ensures that the semantic relationships within the\\nmovie scripts are captured, so as to generate a proper\\ndialogue flow and adhere to specifications.'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\Ansh Lulla\\\\VS-Code\\\\Langchain_tutorial\\\\summarization\\\\PlotPoint_Research_Paper.pdf', 'page': 4}, page_content='Fig. 3: Fine-Tuning LLMs Pipeline\\n1) GPT-2\\nGPT-2 (Generative Pre-trained Transformer 2) [14]\\nis a state-of-the-art language model based on the trans-\\nformers architecture developed by OpenAI. It consists\\nof multiple self attention mechanisms and feed forward\\nneural networks to generate contextually relevant and\\ncoherent text. GPT-2 is a pre-trained model used for\\na variety of NLP tasks and thus fine tuning it on a\\ndownstream task like text generation would achieve\\ngreat results. The GPT-2 model used in this paper has\\napproximately 124 million parameters (GPT-2 Small).\\nGPT-2 uses its own tokenizer, as other basic tok-\\nenizers are unable to capture the contextual meaning\\nbehind the dialogues and scene settings in a script.\\nIt generates tokens based on the contextual under-\\nstanding of the sequences, thus capturing the relation\\nbetween different sequences.\\nIt tokenizes words into individual characters and\\nmakes character pairs based on consecutive characters.\\nThen it combines two characters into the same token\\nbased on the frequency of the repeating character pairs.\\nThis process is repeated until a predefined vocabulary\\nsize is reached, efficiently and deterministically form-\\ning a set of subword units which represent the text\\ncorpus.\\nThe GPT-2 tokenizer has a limitation of only allow-\\ning a maximum length of 1024 tokens to be encoded.\\nOn average the GPT-2 tokenizer makes approximately\\n4 tokens for every 3 words, therefore the scripts get\\nchunked into 700 word chunks and then tokenized.\\nThe model is then trained on these individual chunks,\\nretaining all information from the entire script.\\nOnce the tokenization is complete, it is ready to be\\nfit into the model for fine-tuning. This approach allows\\nthe model to fine-tune on scripts regardless of their size\\nand helps in retaining context as it trains the model on\\nthe largest possible chunks, learning patterns between\\nwords in a larger sequence.\\n2) Bloom\\nBloom (BigScience Large Open-science Open-\\naccess Multilingual) [15] is another state-of-the-art\\nlanguage model based on the transformers architecture.\\nSimilar to GPT-2, it also consists of multiple self at-\\ntention mechanisms and feed forward neural networks\\nto generate contextually relevant and coherent text.\\nBloom is a pre-trained model which is trained on mul-\\ntilingual data. It has 560 million parameters (Bloom\\n560m) therefore can still prove to have significantly\\npositive results for generating text in a single language.\\nBloom also uses its own tokenizer which tokenizes\\ntext based on a probabilistic approach which is op-\\ntimized for diverse scripts and has a more flexible\\ntokenization approach and allows better capturing of\\ncontext and relationships of words in diverse datasets.\\nIt uses SentencePiece which uses a uni-gram language\\nmodel to build its vocabulary.\\nSentencePiece iteratively learns tokens that are most\\nlikely to occur in the training data. It merges the most\\nfrequently occurring token pairs into larger tokens and\\nprobabilistically estimates the likelihood of merging\\npairs based on observed frequency distributions of\\nmerged tokens. This forms a set of subword units\\nwhich represent the text corpus.\\nThe Bloom tokenizer also has a maximum length of\\n2048 tokens to be encoded. Chunking is also used here\\nto chunk a maximum of 512 tokens per chunk. This\\nallowed for a more efficient tokenization process due\\nto the parallelization of the task using a GPU. After\\nthe tokenization, the tokens are ready to fit into the\\nBloom model for fine-tuning.\\nSince LLM is only using a small percentage of the\\ntotal parameters, there is loss of accuracy in the script\\ngeneration, the key is to find the trade-off between\\nthe loss of accuracy and reducing computational cost\\nwhich would make this approach scalable and efficient\\nfor large and complex datasets.'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\Ansh Lulla\\\\VS-Code\\\\Langchain_tutorial\\\\summarization\\\\PlotPoint_Research_Paper.pdf', 'page': 5}, page_content='D. Text-Image Generation\\nText-Image generation would allow users to visual-\\nize the scripts through scenes, and hence ideate upon\\nthe movie script generation in a robust manner. Text-\\nImage generation begins with tokenizing and creating\\nan embedding of the query to capture the semantic\\nmeaning and context of the query.\\nFig. 4: Working of Stable Diffusion for Text-Image\\nGeneration\\nTokenization creates tokens which are smaller com-\\nponents of the input query and the embedding is a\\nnumerical vector which represents the tokens. Stable\\nDiffusion [16], one of the best algorithms for image\\ngeneration, begins with random noise and progres-\\nsively learns to refine the noisy image by de-noising\\nit and eventually generating a clear image relevant\\nto the query. It operates within a latent space - a\\ncompressed space in which image generation can be\\ndone efficiently.\\nStable Diffusion uses a process called de-noising\\ndiffusion which refines the noisy latent representation\\nin a step-by-step process to create a meaningful image.\\nThe model aligns the patterns of the image with that\\nof the embedding to form an image which matches the\\nsemantical meaning of the given query. Once the image\\nde-noising is performed, a decoder model is used to\\nupsample this image and transform it into a visible\\nimage.\\nThe algorithm makes use of cross-attention layers\\nwhich allows the model to focus on different parts\\nof the query embedding at various stages of the de-\\nnoising process. This helps in refining the image in\\norder to maintain the coherence and semantic integrity\\nof the input text during the generation of the image.\\nThe Stable Diffusion model used for this approach\\nis CompVis.\\nIV. E VALUATION\\n1) Cosine Similarity:\\nCosine Similarity is a popular metric for assess-\\ning how semantically similar a generated script\\nis to its input prompt. In a multidimensional\\nspace, it is calculated as the cosine of the angle\\nformed by two vectors. The input prompt and the\\nresulting script’s text are represented by these\\nvectors, respectively.\\nThe range of a cosine similarity value is -1 to\\n1. A value of 1 denotes complete alignment, in\\nwhich the output script’s semantic meaning is\\nexactly the same as that of the input prompt.\\nBeing orthogonal, a value of 0 indicates no\\nsemantic resemblance. A value of -1, on the\\nother hand, indicates total dissimilarity, with the\\nvectors pointing in opposing directions.\\nThe model’s ability to preserve semantic co-\\nherence between the input and the generated\\noutput improves with increasing cosine similar-\\nity. When guaranteeing semantic consistency in\\ntext creation is a primary goal, this metric is\\nessential.\\nCosine Similarity(A, B) = A · B\\n∥A∥∥B∥ (8)\\nwhere, A and B are vectors.\\n2) Perplexity:\\nPerplexity is another crucial assessment metric ,\\nwhich is mainly applied to text generation tasks.\\nIt evaluates a probabilistic model’s ability to\\nanticipate a word sequence. The entropy of the\\nanticipated probability is used to calculate the\\nperplexity value, which goes from 1 to infinity.\\nThe model is more certain of its predictions for\\nthe subsequent token in the sequence when the\\nperplexity score is lower. On the other hand,\\ngreater uncertainty is indicated by a larger per-\\nplexity, which exposes flaws in the probability\\ndistribution of the model. A diagnostic method\\nfor assessing a language model’s dependability\\nand fluency is perplexity.\\nLow perplexity is a crucial parameter for as-\\nsessing performance in natural language genera-\\ntion tasks since models with low perplexity are\\ngenerally better able to generate coherent and\\ncontextually relevant sequences. Mathematically,\\nPerplexity (PPL) is calculated as:\\nPPL = exp\\n \\n− 1\\nN\\nNX\\ni=1\\nlog P(wi | w1, . . . , wi−1)\\n!\\n(9)\\nwhere, P(wi | w1, . . . , wi−1) is the conditional\\nprobability of the i-th word given all the previous\\nwords w1, . . . , wi−1 in the sequence and N is\\nthe total number of words in the test sequence.\\n3) CLIP Score:\\nIt is a metric used to assess how well created'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\Ansh Lulla\\\\VS-Code\\\\Langchain_tutorial\\\\summarization\\\\PlotPoint_Research_Paper.pdf', 'page': 5}, page_content='words w1, . . . , wi−1 in the sequence and N is\\nthe total number of words in the test sequence.\\n3) CLIP Score:\\nIt is a metric used to assess how well created\\nimages match the written prompts that go with\\nthem. CLIP generates vector representations for\\nthe created image and the text prompt using\\na shared embedding space. Cosine similarity is'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\Ansh Lulla\\\\VS-Code\\\\Langchain_tutorial\\\\summarization\\\\PlotPoint_Research_Paper.pdf', 'page': 6}, page_content='then used to calculate how similar these embed-\\ndings are to one another.\\nWhile a lower score signifies poor alignment,\\na higher CLIP Score shows that the resulting\\nimage closely reflects the text prompt’s semantic\\nintent. In multi-modal applications where pre-\\nserving the prompt’s integrity in the visual rep-\\nresentation is crucial, such as picture synthesis\\nfrom textual descriptions, this measure is very\\nuseful.\\nThe CLIP Score guarantees that produced out-\\nputs satisfy the required degree of semantic\\naccuracy by offering a measurable indicator of\\ntextual and visual coherence.\\nCLIP(T, I) = ET · EI\\n∥ET ∥∥EI∥ (10)\\nwhere, ET and EI are the embeddings of the\\ntext and image, respectively and ∥ET ∥ and ∥EI∥\\nrepresent the norms (magnitudes) of these em-\\nbedding vectors.\\nV. R ESULTS\\nTABLE I: Model evaluation metrics and their average\\nscores\\nModel Metric Score (Average)\\nGPT-2 Cosine Similarity 0.5011\\nGPT-2 Perplexity 1.7443\\nBloom Cosine Similarity 0.5058\\nBloom Perplexity 1.6892\\nGemini-Pro Cosine Similarity 0.5713\\nCompVis CLIP Score 0.3061\\n1) GPT-2 (Cosine Similarity):\\nFig.5 shows a density plot of cosine similarity\\nusing the fine-tuned GPT-2 model. The values\\ngo as high as 0.8 and as low as 0.2. The graph\\nsuggests that the generated script at times has\\nvery high contextual similarity between the input\\nquery and the generated script and at times very\\nlow.\\nFig. 5: Density Plot for Cosine Similarity (fine-tuned\\nGPT-2)\\nThe lower values can suggest poor generation\\nleading to lesser context being included in the\\ngenerated script or can be due to high creativity\\nwhich leads to a variety of information along\\nwith the details outlined in the prompt being\\nmentioned in the script.\\nThe higher values suggest that the script per-\\nfectly encompasses the required details from the\\nprompt but can also suggest that the generation\\nhad lesser creativity and did not add many details\\nwhich were not mentioned. This can suggest\\nthat a great input prompt with a lot of details\\nwas mentioned or the generation was with poor\\ncreativity.\\nMajority of the cosine similarity values lying\\nnear the average of 0.5011 suggests that the\\napproach was able to generate a script which\\ncontained the details from the prompt and was\\nalso able to include creative aspects in the script.\\n2) GPT-2 (Perplexity):\\nFig.6 shows a density plot of the perplexity using\\nfine-tuned GPT-2. The perplexity had an average\\nof 1.7443. The perplexity value varied on the\\nlower side and upper side of this average value.\\nThe lower values suggest that the model was\\nless surprised in the token generation of these\\nscripts leading to a well structured script where\\nfollowup words were expected more often than\\nnot.\\nFig. 6: Density Plot for Perplexity (GPT-2)\\nThe higher values can signify a script which\\nmade the model more surprised during the token\\ngeneration. This suggests that the grammatical\\nand semantic clarity of the sentences was jeopar-\\ndized and the sentences more often than not, did\\nnot make sense grammatically and contextually.\\nThe scripts with perplexity near the average\\nvalue can suggest that they made sense gram-\\nmatically and contextually to some degree but\\ncould have either left something to be desired\\nin the generation or the creative aspect of the\\ngeneration left the model more surprised at the\\ntoken generation, attributing to its slightly higher\\nperplexity score. This could suggest that the\\nideal value of perplexity for script generation\\nwhich includes good creativity could be that with\\nvalues near the average perplexity of 1.7443.\\n3) Bloom (Cosine Similarity):'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\Ansh Lulla\\\\VS-Code\\\\Langchain_tutorial\\\\summarization\\\\PlotPoint_Research_Paper.pdf', 'page': 7}, page_content='Fig.7 shows a density plot of cosine similar-\\nity using the fine-tuned Bloom model, which\\ndiffers from the fine-tuned GPT-2 model in its\\ndistribution and average values. While the cosine\\nsimilarity for GPT-2 averaged at 0.5011, the\\nBloom model’s average was 0.5058.\\nFig. 7: Density Plot for Cosine Similarity (fine-tuned\\nBloom)\\nBoth models showed a range of values from\\n0.2 to 0.8, indicating varying levels of con-\\ntextual similarity between the input query and\\nthe generated script. However, the Bloom model\\nappears to strike a slightly different balance, with\\nits clustering around the average suggesting a\\nconsistent ability to include prompt details while\\nintroducing creative aspects.\\nIn comparison, the GPT-2 model’s lower and\\nhigher values might more distinctly reflect out-\\nputs that either deviate significantly from the\\nprompt or align too closely, potentially at the\\nexpense of creativity. The differences in average\\nvalues and distributions suggest that Bloom may\\nprovide a more balanced generation, while GPT-\\n2 may exhibit greater variance in its outputs\\ndepending on the nature of the prompt.\\nAccording to the variations in average values\\nand distributions, Bloom might produce a more\\nbalanced generation, but GPT-2 might produce\\noutputs that vary more depending on the prompt.\\n4) Bloom (Perplexity):\\nFig.6 compares the density plots of perplexity\\nfor fine-tuned GPT-2 and Bloom models, demon-\\nstrating variations in their text generation. GPT-2\\nrecorded an average perplexity of 1.7443, while\\nBloom achieved a lesser average of 1.6892.\\nFig. 8: Density Plot for Perplexity (fine-tuned Bloom)\\nHigher perplexity values for GPT-2 indicate dif-\\nficulties in preserving grammatical or semantic\\nclarity, which frequently results in outputs that\\nlack contextual sense. Lower perplexity val-\\nues, on the other hand, indicate well-structured\\nscripts with predictable token generation. Al-\\nthough some may have had space for growth in\\ngeneration quality, scripts with ambiguity close\\nto the average demonstrated a balance between\\ncoherence and inventiveness.\\nBloom’s tighter grouping and lower confusion,\\non the other hand, point to a more reliable\\ncapacity for producing language that is both con-\\ntextually relevant and coherent. Its values close\\nto the mean show a steady equilibrium between\\nfollowing the prompt and adding originality.\\nBloom’s smaller range of perplexity scores sug-\\ngests a lower variability than GPT-2, which\\nmakes it more dependable for applications de-\\nmanding accuracy. However, applications that\\nvalue diversity and flexibility in script produc-\\ntion could find GPT-2 more appropriate due to\\nits wider range\\n5) Gemini-Pro (Cosine Similarity):\\nFig.9 shows the density plot shows the distri-\\nbution of cosine similarity values for outputs\\nproduced by the Gemini-Pro model using RAG,\\nwith an average cosine similarity of 0.5713.The\\nrange is from 0.2 to 0.8.\\nThis variability shows how well the model per-\\nforms in striking a balance between contex-\\ntual alignment of generated scripts and creative\\nflexibility; lower cosine similarity values, closer\\nto 0.2, indicate instances where the generated\\nscripts either lack sufficient context from the in-\\nput prompt or exhibit high creativity by deviating\\nfrom the input to include diverse information;\\nhigher values, approaching 0.8, indicate outputs\\nthat closely align with the prompt, effectively\\ncapturing its details; however, such outputs may\\nalso suggest limited creativity, as the generation\\nmay strictly follow the prompt without adding\\nsubtle or unique information.\\nFig. 9: Density Plot for Cosine Similarity (Gemini-\\nPro)\\nThe concentration of cosine similarity values\\naround the average of 0.5713 shows that Gemini-'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\Ansh Lulla\\\\VS-Code\\\\Langchain_tutorial\\\\summarization\\\\PlotPoint_Research_Paper.pdf', 'page': 8}, page_content='Pro successfully strikes a balance between cre-\\nativity and relevance, generating scripts that use\\nRAG to add meaningful and creative elabora-\\ntion to the content while incorporating relevant\\ninformation from the prompt.This performance\\nshows how well Gemini-Pro combines creative\\nflexibility with rapid alignment, outperforming\\nother models in the process.\\n6) CompVis (CLIP Score):\\nFig.10 shows a density plot for the CLIP score\\nof the image generated from the input prompt.\\nThe average CLIP score was 0.3061.\\nThis shows a weaker alignment of the image\\nwith the features mentioned in the prompt or\\ncould also suggest that the features in the image\\nare loosely related to the details in the prompt.\\nThis could be due to the model under-performing\\nor the input prompts not being detailed enough\\nto generate distinct features in the image.\\nFig. 10: Density Plot for CLIP Score (CompVis)\\nAside from lack of details in the prompt, abstract\\nor complex details could also lead to a lower\\nCLIP score since the model might be unable to\\nmake a strong connection between these con-\\ncepts and features in the image.\\n7) Reason why Gemini-Pro cannot be evalu-\\nated using Perplexity: To calculate perplexity,\\na probabilistic token-based prediction approach\\nis required but since Gemini-Pro is being inte-\\ngrated with the RAG Pipeline, it is not using\\nany probability distribution to predict the next\\ntokens, it rather combines the retrieval mecha-\\nnisms of RAG with generation.\\nSince RAG models do not use a probabilistic\\napproach to predict the next tokens, Gemini-Pro\\nthus does not produce a probability distribution\\nand perplexity cannot be used as an evaluation\\nmetric for Gemini-Pro.\\nVI. F UTURE SCOPE\\nDue to hardware constraints, the LLMs used in the\\nproposed methodology have limited capabilities. Al-\\nthough LLMs provided accurate responses to the query\\nand performed well on the evaluation metrics, better\\nmodels with a greater number of parameters can be\\nused to further refine the movie scripts to adhere to the\\nspecifications in a better way. Better stable diffusion\\nmodels could also be used to generate accurate text\\ninside an image, or generate higher quality images for\\nbetter visualization of the generated movie script.\\nThe models could also be optimized to give sug-\\ngestions for what kind of lighting or scene setting is\\nneeded to direct such a movie script in an apt manner\\nby storing more metadata about the script in the vector\\ndatabase.\\nVII. C ONCLUSION\\nThe proposed methodologies demonstrate the poten-\\ntial of advanced NLP techniques like RAG and Fine-\\nTuning LLMs, and Image Generation algorithms like\\nStable Diffusion in order to automate script and scene\\ngeneration in the cinema industry.\\nThe lower perplexity and high cosine similarity\\nvalues indicate a high level of coherence and fluency\\nin generated dialogues, which is important for main-\\ntaining human-like script writing techniques. CLIP\\nScore indicates that despite the room for improvement,\\nStable Diffusion can help visualize the input query in\\nthe form of a movie scene with a moderate level of\\nalignment.\\nThis approach reduces the barriers in creative pro-\\ncesses, allowing a better overall script generation.\\nACKNOWLEDGMENT\\nWe would like to extend our sincere gratitude to\\nSymbiosis Institute of Technology, Symbiosis Interna-\\ntional (Deemed University), Pune, India, for providing\\nthe invaluable support and platform necessary to con-\\nduct our research work. We are thankful for providing\\nthe nurturing environment where we had the privilege\\nto learn and explore.\\nREFERENCES\\n[1] Asli Celikyilmaz, Elizabeth Clark, and Jianfeng Gao. Eval-\\nuation of text generation: A survey. arXiv preprint\\narXiv:2006.14799, 2020.\\n[2] A Vaswani. Attention is all you need. Advances in Neural\\nInformation Processing Systems , 2017.\\n[3] Xiang Li, John Thickstun, Ishaan Gulrajani, Percy S Liang,\\nand Tatsunori B Hashimoto. Diffusion-lm improves con-\\ntrollable text generation. Advances in Neural Information'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\Ansh Lulla\\\\VS-Code\\\\Langchain_tutorial\\\\summarization\\\\PlotPoint_Research_Paper.pdf', 'page': 8}, page_content='[3] Xiang Li, John Thickstun, Ishaan Gulrajani, Percy S Liang,\\nand Tatsunori B Hashimoto. Diffusion-lm improves con-\\ntrollable text generation. Advances in Neural Information\\nProcessing Systems, 35:4328–4343, 2022.\\n[4] Angela Fan, Mike Lewis, and Yann Dauphin. Hierarchical\\nneural story generation. arXiv preprint arXiv:1805.04833 ,\\n2018.\\n[5] Tom B Brown. Language models are few-shot learners. arXiv\\npreprint arXiv:2005.14165, 2020.\\n[6] Pradyumna Tambwekar, Murtaza Dhuliawala, Lara J Martin,\\nAnimesh Mehta, Brent Harrison, and Mark O Riedl. Control-\\nlable neural story plot generation via reward shaping. arXiv\\npreprint arXiv:1809.10736, 2018.\\n[7] Sanidhya Mangal, Poorva Joshi, and Rahul Modak. Lstm vs.\\ngru vs. bidirectional rnn for script generation. arXiv preprint\\narXiv:1908.04332, 2019.\\n[8] Lili Yao, Nanyun Peng, Ralph Weischedel, Kevin Knight,\\nDongyan Zhao, and Rui Yan. Plan-and-write: Towards better\\nautomatic storytelling. In Proceedings of the AAAI Conference\\non Artificial Intelligence , volume 33, pages 7378–7385, 2019.\\n[9] Yutao Zhu, Ruihua Song, Zhicheng Dou, Jian-Yun Nie, and Jin\\nZhou. Scriptwriter: Narrative-guided script generation. arXiv\\npreprint arXiv:2005.10331, 2020.'),\n",
       " Document(metadata={'source': 'C:\\\\Users\\\\Ansh Lulla\\\\VS-Code\\\\Langchain_tutorial\\\\summarization\\\\PlotPoint_Research_Paper.pdf', 'page': 9}, page_content='[10] Gayatri Bhat, Avneesh Saluja, Melody Dye, and Jan Flor-\\njanczyk. Hierarchical encoders for modeling and interpreting\\nscreenplays. arXiv preprint arXiv:2004.14532 , 2020.\\n[11] Le Fang, Tao Zeng, Chaochun Liu, Liefeng Bo, Wen Dong,\\nand Changyou Chen. Outline to story: Fine-grained control-\\nlable story generation from cascaded events. arXiv preprint\\narXiv:2101.00822, 2021.\\n[12] Keisuke Sakaguchi, Chandra Bhagavatula, Ronan Le Bras,\\nNiket Tandon, Peter Clark, and Yejin Choi. proscript: Partially\\nordered scripts generation via pre-trained language models.\\narXiv preprint arXiv:2104.08251 , 2021.\\n[13] Fatima Dayo, Ahmed Ali Memon, and Nasrullah Dharejo.\\nScriptwriting in the age of ai: Revolutionizing storytelling with\\nartificial intelligence. Journal of Media & Communication ,\\n4(1):24–38, 2023.\\n[14] Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario\\nAmodei, Ilya Sutskever, et al. Language models are unsuper-\\nvised multitask learners. OpenAI blog, 1(8):9, 2019.\\n[15] Teven Le Scao, Angela Fan, Christopher Akiki, Ellie Pavlick,\\nSuzana Ili ´c, Daniel Hesslow, Roman Castagn ´e, Alexan-\\ndra Sasha Luccioni, Franc ¸ois Yvon, Matthias Gall ´e, et al.\\nBloom: A 176b-parameter open-access multilingual language\\nmodel. 2023.\\n[16] Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick\\nEsser, and Bj ¨orn Ommer. High-resolution image synthesis\\nwith latent diffusion models. In Proceedings of the IEEE/CVF\\nconference on computer vision and pattern recognition , pages\\n10684–10695, 2022.\\n[17] Y Zhang. Dialogpt: Large-scale generative pre-training\\nfor conversational response generation. arXiv preprint\\narXiv:1911.00536, 2019.')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader = PyPDFLoader(file_path=r\"C:\\Users\\Ansh Lulla\\VS-Code\\Langchain_tutorial\\summarization\\PlotPoint_Research_Paper.pdf\")\n",
    "docs = loader.load_and_split()\n",
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splitter = RecursiveCharacterTextSplitter(chunk_size=2000, chunk_overlap=200)\n",
    "chunks = splitter.split_documents(docs)\n",
    "len(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['text'], input_types={}, partial_variables={}, template='\\n    Write a concise summary of the document.\\n    text: {text}\\n    Summary:\\n')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "template = \"\"\"\n",
    "    Write a concise summary of the document.\n",
    "    text: {text}\n",
    "    Summary:\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(input_variables=[\"text\"], template=template)\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x000001C734CD8CB0>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x000001C734CFDEB0>, model_name='llama3-8b-8192', model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm = ChatGroq(model=\"llama3-8b-8192\", api_key=os.getenv(\"GROQ_API_KEY\"))\n",
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['text'], input_types={}, partial_variables={}, template='\\n    Provide the final summary of the entire speech with these important points.\\n    Add a motivational title, start the summary with a hook, and end with a call to action and provide the summary points in numbers. \\n    Text: {text}\\n')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_prompt = \"\"\"\n",
    "    Provide the final summary of the entire speech with these important points.\n",
    "    Add a motivational title, start the summary with a hook, and end with a call to action and provide the summary points in numbers. \n",
    "    Text: {text}\n",
    "\"\"\"\n",
    "\n",
    "final_prompt_template = PromptTemplate(input_variables=[\"text\"], template=final_prompt)\n",
    "final_prompt_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MapReduceDocumentsChain(verbose=True, llm_chain=LLMChain(verbose=True, prompt=PromptTemplate(input_variables=['text'], input_types={}, partial_variables={}, template='\\n    Write a concise summary of the document.\\n    text: {text}\\n    Summary:\\n'), llm=ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x000001C734CD8CB0>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x000001C734CFDEB0>, model_name='llama3-8b-8192', model_kwargs={}, groq_api_key=SecretStr('**********')), output_parser=StrOutputParser(), llm_kwargs={}), reduce_documents_chain=ReduceDocumentsChain(verbose=True, combine_documents_chain=StuffDocumentsChain(verbose=True, llm_chain=LLMChain(verbose=True, prompt=PromptTemplate(input_variables=['text'], input_types={}, partial_variables={}, template='\\n    Provide the final summary of the entire speech with these important points.\\n    Add a motivational title, start the summary with a hook, and end with a call to action and provide the summary points in numbers. \\n    Text: {text}\\n'), llm=ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x000001C734CD8CB0>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x000001C734CFDEB0>, model_name='llama3-8b-8192', model_kwargs={}, groq_api_key=SecretStr('**********')), output_parser=StrOutputParser(), llm_kwargs={}), document_prompt=PromptTemplate(input_variables=['page_content'], input_types={}, partial_variables={}, template='{page_content}'), document_variable_name='text')), document_variable_name='text')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# combine all the docs and create a summary\n",
    "chain = load_summarize_chain(llm=llm, \n",
    "                             chain_type=\"map_reduce\", \n",
    "                             map_prompt=prompt, \n",
    "                             combine_prompt=final_prompt_template, \n",
    "                             verbose=True)\n",
    "chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ansh Lulla\\AppData\\Local\\Temp\\ipykernel_7100\\3911700938.py:1: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  summary = chain.run(chunks)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new MapReduceDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "    Write a concise summary of the document.\n",
      "    text: PlotPoint - An AI-Driven Framework for\n",
      "Automated Movie Scriptwriting and Scene\n",
      "Generation\n",
      "Ansh Lulla, Aayush Koul, Rampalli Agni Mithra,\n",
      "Aniket K. Shahade ∗, Mayur Gaikwad, Shruti Patil\n",
      "Department of AIML ,\n",
      "Symbiosis Institute of Technology, Pune Campus , Symbiosis International (Deemed University), Pune, India\n",
      "∗aniket.shahade@sitpune.edu.in\n",
      "Abstract—Script writing has become a labor-intensive\n",
      "process, especially when tailored to specific scene setting,\n",
      "culture or character. Recent advancements in the field\n",
      "of Natural Language Processing and Deep Learning\n",
      "algorithms have made it possible to automate the process\n",
      "of script writing. With a simple prompt, it is possible to\n",
      "generate the entire script for a movie, which would be\n",
      "customizable by the input’s creativity and imagination.\n",
      "Retrieval Augmented Generation has the potential to\n",
      "facilitate rapid prototyping of movie scripts by ingesting\n",
      "the data in a vector database and retrieving scripts\n",
      "which would be most similar with the input prompt.\n",
      "These retrieved scripts would act as part of context\n",
      "for the Large Language Models and prevent them from\n",
      "hallucinating. This approach enhances the potential of\n",
      "these LLMs to generate context-specific output which is\n",
      "essential when taking into consideration the fine details\n",
      "mentioned in the input prompt. Fine-tuning LLMs is\n",
      "another approach which helps downstream the LLMs to\n",
      "learn how to generate movie scripts. With the inclusion\n",
      "of visualizing the script elements, one can conveniently\n",
      "turn their ideas into a script and scenes. Combining the\n",
      "capabilities of Stable Diffusion with the LLMs, script\n",
      "generation can be extended to scene generation. On\n",
      "training multiple models on the dataset of movie scripts,\n",
      "Gemini-Pro (for RAG) was very effective with a cosine\n",
      "similarity of 0.5713 whereas GPT-2 and Bloom (for fine-\n",
      "tuning) showed a cosine similarity of 0.5011 and 0.5058\n",
      "respectively between the input prompt and the generated\n",
      "script, and perplexity of 1.7443 for GPT-2 and 1.6892\n",
      "    Summary:\n",
      "\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "    Write a concise summary of the document.\n",
      "    text: tuning) showed a cosine similarity of 0.5011 and 0.5058\n",
      "respectively between the input prompt and the generated\n",
      "script, and perplexity of 1.7443 for GPT-2 and 1.6892\n",
      "for Bloom showing that GPT-2 is able to generate scripts\n",
      "which are coherent and relevant to the input prompt and\n",
      "has thus understood the language structure and patterns\n",
      "well. A CLIP score of 0.3061 was achieved with using\n",
      "CompVis for generation of movie scenes.\n",
      "Index Terms—NLP, Deep Learning, RAG, LLMs, Sta-\n",
      "ble Diffusion\n",
      "I. I NTRODUCTION\n",
      "A. Background\n",
      "Scriptwriting is an important part of the entertain-\n",
      "ment industry. Scripts contain dialogues, scene settings\n",
      "and character development which makes it a time\n",
      "consuming and arduous process, particularly when\n",
      "tailored content is needed for movies, television shows,\n",
      "gaming and marketing.\n",
      "It is very important to create a vision of the scene to\n",
      "allow the director to create a scene which engages and\n",
      "appeals to the audience. Along with the increased de-\n",
      "mand for personalized content, automating the process\n",
      "of scriptwriting using Natural Language Processing\n",
      "has emerged as a promising solution to the problem\n",
      "of generating scalable, high quality scripts along with\n",
      "the growing demand in the industry.\n",
      "Leveraging Deep Learning models to create com-\n",
      "plex and coherent scripts by retaining context dur-\n",
      "ing the generation of the entire script, allowing the\n",
      "scriptwriter to focus on improving the idea itself,\n",
      "significantly reduces the time and effort required for\n",
      "scriptwriting.\n",
      "B. Domain\n",
      "Natural Language Generation is a subfield of Natu-\n",
      "ral Language Processing. It has proven to be a reliable\n",
      "tool in generating complex and coherent text while\n",
      "retaining contextual nuances throughout the generation\n",
      "process.\n",
      "Leveraging deep learning techniques allowing ma-\n",
      "chines to learn the sequential patterns in text, NLG\n",
      "systems are able to use pre-existing datasets of movie\n",
      "scripts and dialogues to create an understanding of\n",
      "human-like dialogue structures. This understanding\n",
      "    Summary:\n",
      "\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "    Write a concise summary of the document.\n",
      "    text: systems are able to use pre-existing datasets of movie\n",
      "scripts and dialogues to create an understanding of\n",
      "human-like dialogue structures. This understanding\n",
      "can be further used for the purpose of personalized\n",
      "script generation.\n",
      "Existing tools primarily focus on general text gen-\n",
      "eration but have research gaps for developing systems\n",
      "    Summary:\n",
      "\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "    Write a concise summary of the document.\n",
      "    text: can be further used for the purpose of personalized\n",
      "script generation.\n",
      "Existing tools primarily focus on general text gen-\n",
      "eration but have research gaps for developing systems\n",
      "that allow personalization of scripts which include\n",
      "customizable elements such as character description,\n",
      "behavior, and other specifications defined in the input\n",
      "prompt about the scene and setting.\n",
      "C. Motivation\n",
      "Storytelling remains a crucial method of communi-\n",
      "cation in films, gaming and marketing, thereby stream-\n",
      "lining the process of script generation can enable\n",
      "rapid prototyping and customization of inputs such as\n",
      "time of the day, number of characters and character\n",
      "descriptions can pioneer significant improvements in\n",
      "plot complexity and quality by allowing writers to\n",
      "focus more on the plot itself rather than the process of\n",
      "    Summary:\n",
      "\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "    Write a concise summary of the document.\n",
      "    text: writing it. This would reduce the barriers for anyone\n",
      "who wishes to turn their ideas into scripts, promoting\n",
      "creative freedom and enabling the refinement of ideas\n",
      "rather than focusing on the mechanics of the scripts.\n",
      "D. Contribution\n",
      "Automation of script generation has the potential\n",
      "of transforming how humans develop and consume\n",
      "content globally. As more and more people will have\n",
      "the convenience of creating high quality scripts out\n",
      "of their imagination and ideas, simply by providing\n",
      "prompts and necessary context to the LLMs or RAG\n",
      "systems fine-tuned on the movie script’s dataset, fa-\n",
      "cilitating the generation of scripts and make changes\n",
      "according to preferences without worrying about the\n",
      "back-end complexities of text generation.\n",
      "II. L ITERATURE SURVEY\n",
      "Celikyilmaz A et al. conducted a survey of evalua-\n",
      "tion metrics for text generation including both human\n",
      "and automated methods. Using word embeddings like\n",
      "Word2Vec, Seq2Seq models like GRU and LSTM,\n",
      "BERT and GPT, they highlighted the strengths of\n",
      "hybrid metrics on datasets like WMT, Twitter Dialogue\n",
      "and Daily Mail. Though effective, the study notes the\n",
      "challenges faced in human evaluation methods and\n",
      "hence the need for standardized methods [1].\n",
      "Vasvani et al. introduced the Transformer architec-\n",
      "ture which is a fully attention-based approach which\n",
      "enhances text generation tasks. Positional word em-\n",
      "beddings, shared weight matrix embeddings were used\n",
      "along with models like GCN, DeepWalk and Planetoid,\n",
      "on WMT-2014 dataset. The models though very pow-\n",
      "erful, face a lot of challenges in terms of scalability\n",
      "due to the quadratic attention complexity [2].\n",
      "Li et al. proposed the Diffusion-LM approach,\n",
      "which was effective for controllable text generation\n",
      "without the need for retraining. It has been tested\n",
      "on E2E and ROCStories datasets, using clustering\n",
      "of learned embeddings, demonstrating strong BLEU-4\n",
      "and ROUGE-L scores. Despite its effectiveness, there\n",
      "are potential issues with high-dimensional tuning and\n",
      "    Summary:\n",
      "\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "    Write a concise summary of the document.\n",
      "    text: of learned embeddings, demonstrating strong BLEU-4\n",
      "and ROUGE-L scores. Despite its effectiveness, there\n",
      "are potential issues with high-dimensional tuning and\n",
      "stability of the model in various scenarios [3].\n",
      "Fan et al. used over 300 thousand narratives to\n",
      "explore hierarchical story generation. They used pre-\n",
      "trained embeddings like FastText with fusion of Con-\n",
      "volutional, Seq2Seq and self-attention models. Due\n",
      "to the complex architecture, they faced challenges\n",
      "in tuning, but the low perplexity scores show good\n",
      "coherence in the test dataset [4].\n",
      "Brown et al. showcased the flexibility and adaptabil-\n",
      "ity of GPT-3 models in tasks like sentiment analysis\n",
      "and cloze tests. Although GPT-3 models struggled with\n",
      "fine-tuning demands and interpretability issues, they\n",
      "provided high precision on datasets such as Common-\n",
      "Crawl and WebText2 [5].\n",
      "Tambwekar et al. used the encoder-decoder archi-\n",
      "tecture to introduce a reward-shaping technique to\n",
      "generate plot-directed stories. They used WordNet and\n",
      "VerbNet Sysnets embeddings and DRL models and\n",
      "achieved low perplexity scores, but the comparisons\n",
      "were made on the existing corpus and not the unseen\n",
      "plots [6].\n",
      "Mangal et al. used the Game of Thrones data to eval-\n",
      "uate different RNN architectures like GRU, LSTM and\n",
      "Bidirectional RNN. LSTM and GRU models though\n",
      "generated coherent texts, they failed to capture the\n",
      "intricate character descriptions and interactions, indi-\n",
      "cating room for improvement in complex sequences\n",
      "[7].\n",
      "Yao et al. introduce the Plan-and-Write framework,\n",
      "integrating static and dynamic schema for coherence in\n",
      "story. Using GloVe embeddings and Seq2Seq models\n",
      "on ROCStories dataset, the models performed well but\n",
      "failed to handle complex narrative relationships and\n",
      "events [8].\n",
      "Zhu et al. develop a narrative-guided script genera-\n",
      "tion model by using the Word2Vec embedding with\n",
      "DL2R and MVLSTM models on the GraphMovie\n",
      "dataset. The approach adheres strictly to the structured\n",
      "    Summary:\n",
      "\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "    Write a concise summary of the document.\n",
      "    text: Zhu et al. develop a narrative-guided script genera-\n",
      "tion model by using the Word2Vec embedding with\n",
      "DL2R and MVLSTM models on the GraphMovie\n",
      "dataset. The approach adheres strictly to the structured\n",
      "design leading to limitation of creative storytelling [9].\n",
      "Bhat et al. apply hierarchical encoders to screen-\n",
      "play modelling, to classification of genre and mood\n",
      "classification using Bag-of-Embeddings and GRU on\n",
      "    Summary:\n",
      "\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "    Write a concise summary of the document.\n",
      "    text: Bhat et al. apply hierarchical encoders to screen-\n",
      "play modelling, to classification of genre and mood\n",
      "classification using Bag-of-Embeddings and GRU on\n",
      "the ScriptBase-J corpus [10].\n",
      "Fang et al. used the WritingPrompts and WikiPlots\n",
      "datasets and proposed a fine-grained, controllable text\n",
      "generation model that builds on cascaded events. They\n",
      "used GloVe, TextRank, RAKE and BERT embed-\n",
      "dings with models like FUSION, FIST and PSA and\n",
      "achieved strong BLEU and ROUGE scores [11].\n",
      "Sakaguchi et al. developed the proScript framework\n",
      "to solve the problem of producing high-quality par-\n",
      "tially ordered scripts for everyday scenarios. The study\n",
      "established two complementary tasks: script edge pre-\n",
      "diction and script generation, using a crowd sourced\n",
      "dataset of 6,414 scripts, which was significantly larger\n",
      "than previous datasets. With the use of pre-trained\n",
      "language models such as T5, the models showed no-\n",
      "table gains in event generation and script organization,\n",
      "attaining an F1 score of up to 75.71 in edge prediction.\n",
      "Despite the progress, issues like generalization outside\n",
      "of the domain and attaining human-level performance\n",
      "point to areas that require further study [12].\n",
      "Dayo et al. analyzed how AI has transformed con-\n",
      "temporary scriptwriting, emphasizing how it affects\n",
      "the cinema business and story development. They\n",
      "carried out a thorough examination of AI tools such\n",
      "as AI authoring and Natural Language Processing\n",
      "(NLP), showcasing how they might improve interactive\n",
      "storytelling, character development, and narrative cre-\n",
      "ation. Case studies like ”Sunspring” (2016) and ”Zone\n",
      "Out” (2022) showed how human creativity and AI-\n",
      "generated content may work together. Despite these\n",
      "developments, there are still issues to be resolved, such\n",
      "as moral dilemmas, how to balance human and AI co-\n",
      "    Summary:\n",
      "\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "    Write a concise summary of the document.\n",
      "    text: operation, and the requirement to preserve narrative’s\n",
      "emotional nuance and cultural authenticity [13].\n",
      "III. M ETHODOLOGY\n",
      "A. Model Architecture\n",
      "The Transformer architecture [2] is composed of\n",
      "two parts: Encoder and the Decoder. The Encoder is\n",
      "responsible for processing the input sequences and\n",
      "generating useful representations of the input (em-\n",
      "beddings). The Decoder is responsible for using the\n",
      "encoder’s outputs and target sequences to generate\n",
      "predictions.\n",
      "Transformers address the issue of Seq2Seq models\n",
      "through Attention Mechanism. In Seq2Seq models, the\n",
      "decoder uses the ”summarized” version of the input\n",
      "sequence done by the encoder, which raises the issue\n",
      "of lack of context. The Decoder cannot focus on the\n",
      "important parts of the input which leads to sub-optimal\n",
      "outputs.\n",
      "Through Attention Mechanism, transformers gain\n",
      "the ability to produce context-specific outputs by de-\n",
      "termining the relevance of each of the tokens in the\n",
      "sequence with respect to others and focusing on certain\n",
      "aspects of the input which would help generate optimal\n",
      "outputs. The type of attention mechanisms used in\n",
      "Transformer architecture are Multi-Head and Masked\n",
      "Multi-Head attention mechanisms.\n",
      "Fig. 1: Transformer Architecture\n",
      "Attention Mechanism computes the attention scores\n",
      "for each token to evaluate the relevance of the token\n",
      "with respect to the output sequence to be generated.\n",
      "To compute the attention score, three vectors are used:\n",
      "1) Query Matrix (Q): It represents the part of\n",
      "input sequence the model is focusing on.\n",
      "2) Key Matrix (K): It represents the information\n",
      "carried by each input token.\n",
      "3) Value Matrix (V): It represents the correspond-\n",
      "ing output tokens for which the input tokens are\n",
      "being evaluated.\n",
      "Each of the input elements (word embeddings for\n",
      "each token) is projected onto these vectors via some\n",
      "learned weight matrices. Mathematically, the input\n",
      "representations are defined as:\n",
      "Q = XWQ (1)\n",
      "K = XWK (2)\n",
      "V = XWV (3)\n",
      "where X is Input matrix, and WQ, WK, WV are the\n",
      "    Summary:\n",
      "\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "    Write a concise summary of the document.\n",
      "    text: learned weight matrices. Mathematically, the input\n",
      "representations are defined as:\n",
      "Q = XWQ (1)\n",
      "K = XWK (2)\n",
      "V = XWV (3)\n",
      "where X is Input matrix, and WQ, WK, WV are the\n",
      "learned weight matrices.\n",
      "The attention score then calculated as a dot product\n",
      "of each element of the Query and Key matrices (q and\n",
      "k respectively) and is scaled using a scaling factor -\n",
      "square root of the key dimension dk to prevent large\n",
      "values leading to unstable gradients.\n",
      "Score(q, k) = q · k√dk\n",
      "(4)\n",
      "The raw scores are passed through a softmax func-\n",
      "tion which normalizes these scores to get a probability\n",
      "distribution, with each probability representing the\n",
      "importance of the input element.\n",
      "αij = softmax\n",
      "\u0012qi · kj√dk\n",
      "\u0013\n",
      "(5)\n",
      "Finally, the weighted sum of each of the value\n",
      "vectors (v) is computed with the attention scores being\n",
      "the weights.\n",
      "Attention(Q, K, V) =\n",
      "nX\n",
      "j=1\n",
      "αijvj (6)\n",
      "The above calculations are for a single-head at-\n",
      "tention mechanism, since transformers use multi-head\n",
      "attention mechanism, multiple single-head attention\n",
      "mechanisms run parallelly and their individual results\n",
      "are concatenated. Along with the concatenated heads\n",
      "and a learned weight matrix WO, the Multi-Head\n",
      "attention score is calculated.\n",
      "Multi-Head(Q, K, V) =Concat(head1, . . . ,headh)WO\n",
      "(7)\n",
      "The attention mechanism thus assists the transform-\n",
      "ers architecture to focus on the important parts of the\n",
      "input and generate contextually relevant outputs.\n",
      "B. RAG Architecture\n",
      "RAG - Retrieval Augmented Generation, is a frame-\n",
      "work used to help LLMs provide a better response\n",
      "by providing relevant information from an external\n",
      "database (usually a vector database) which reduces\n",
      "the chance that the LLM will lead to inaccurate or\n",
      "incomplete responses.\n",
      "    Summary:\n",
      "\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "    Write a concise summary of the document.\n",
      "    text: Fig. 2: RAG Pipeline\n",
      "LLMs have a tendency of hallucinating when it\n",
      "comes to generating responses and have a limitation\n",
      "of knowledge, hence RAG helps mitigate these limi-\n",
      "tations of LLMs and provide better responses.\n",
      "The scripts used for training are converted into\n",
      "chunks using the Recursive Character Text splitter\n",
      "which recursively identifies and segments scripts en-\n",
      "suring that each chunk maintains its coherent context\n",
      "and structure,thereby focusing on specific character\n",
      "scenes and transitions.\n",
      "These chunks are then converted into embeddings\n",
      "using sentence transformer in order to capture the\n",
      "semantic relationships within the chunks and between\n",
      "the chunks. The chunk embeddings are then stored in a\n",
      "FAISS vector database, along with their metadata like\n",
      "index of the chunk and name of the movie that chunk\n",
      "is from.\n",
      "This vector database is used for performing semantic\n",
      "similarity search based on a query to retrieve top ’k’\n",
      "chunks which are most similar to the query which will\n",
      "be used as contextual information for the LLMs, so as\n",
      "to generate contextually relevant scripts (k value used\n",
      "for the proposed methodology is 5).\n",
      "The above semantic similarity search is further\n",
      "optimized using IVF-Flat (Inverted File with Flat\n",
      "Quantization), which segregates all the chunks into\n",
      "clusters, this would help the RAG Framework to focus\n",
      "on only limited number of chunks for fetching the\n",
      "semantically most similar chunks rather than searching\n",
      "in the entire database. The clustering is done using\n",
      "the K-Means Clustering, where in the data points\n",
      "being close to each other are considered as ”similar”\n",
      "and are therefore grouped in one cluster. Doing so\n",
      "for the entire vector database would help divide all\n",
      "the chunk embeddings into clusters. IVF-Flat thus\n",
      "significantly improves upon the time complexity of\n",
      "searching especially when dealing with a dataset of\n",
      "large number of movie scripts.\n",
      "For a given Query Embedding, the algorithm calcu-\n",
      "lates the L2 Norm (Euclidean Distance) between the\n",
      "    Summary:\n",
      "\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "    Write a concise summary of the document.\n",
      "    text: searching especially when dealing with a dataset of\n",
      "large number of movie scripts.\n",
      "For a given Query Embedding, the algorithm calcu-\n",
      "lates the L2 Norm (Euclidean Distance) between the\n",
      "Query Embedding and the Centroid of each region\n",
      "(cluster), in order to narrow-down the search and\n",
      "perform semantic similarity search within that cluster\n",
      "for the top ’k’ chunks.\n",
      "The top ’k’ chunks are evaluated using cosine sim-\n",
      "ilarity (to measure degree of similarity between two\n",
      "vectors or embeddings) and Euclidean Distance, this\n",
      "way the retrieved chunks are ranked based on how high\n",
      "is the cosine similarity and how low the Euclidean\n",
      "Distance between the Query Embedding and chunk\n",
      "embeddings (with priority given to cosine similarity).\n",
      "These retrieved chunks (along with their metadata)\n",
      "will be provided to the LLM to generate an accurate\n",
      "script which adheres to the input query while prevent-\n",
      "ing the LLM from hallucinating. The LLM used for\n",
      "RAG implementation is Gemini-Pro.\n",
      "1) Gemini-Pro\n",
      "Gemini-Pro developed by Google DeepMind, is\n",
      "a state-of-the-art LLM with enhanced capabilities\n",
      "for Natural Language Generation and Understanding\n",
      "tasks. It excels in complex reasoning thereby gener-\n",
      "ating nuanced and coherent movie scripts tailored to\n",
      "the specifications. With the inclusion of RAG, Gemini-\n",
      "Pro’s potential hallucination is successfully mitigated.\n",
      "Gemini-Pro has the ability to use either decoder-\n",
      "only or encoder-decoder architecture, based on the\n",
      "structure and type of task, making it a versatile LLM.\n",
      "C. Fine-Tuning LLMs\n",
      "Fine-tuning Large Language Models involves using\n",
      "a pre-trained model and down-streaming it to a specific\n",
      "task like script generation by training it on the task-\n",
      "specific dataset. This process modifies the weights of\n",
      "the pre-trained model to align the predictions accord-\n",
      "ing to the specific task.\n",
      "Using the embeddings of these pre-trained mod-\n",
      "els ensures that the semantic relationships within the\n",
      "movie scripts are captured, so as to generate a proper\n",
      "    Summary:\n",
      "\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "    Write a concise summary of the document.\n",
      "    text: ing to the specific task.\n",
      "Using the embeddings of these pre-trained mod-\n",
      "els ensures that the semantic relationships within the\n",
      "movie scripts are captured, so as to generate a proper\n",
      "dialogue flow and adhere to specifications.\n",
      "    Summary:\n",
      "\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "    Write a concise summary of the document.\n",
      "    text: Fig. 3: Fine-Tuning LLMs Pipeline\n",
      "1) GPT-2\n",
      "GPT-2 (Generative Pre-trained Transformer 2) [14]\n",
      "is a state-of-the-art language model based on the trans-\n",
      "formers architecture developed by OpenAI. It consists\n",
      "of multiple self attention mechanisms and feed forward\n",
      "neural networks to generate contextually relevant and\n",
      "coherent text. GPT-2 is a pre-trained model used for\n",
      "a variety of NLP tasks and thus fine tuning it on a\n",
      "downstream task like text generation would achieve\n",
      "great results. The GPT-2 model used in this paper has\n",
      "approximately 124 million parameters (GPT-2 Small).\n",
      "GPT-2 uses its own tokenizer, as other basic tok-\n",
      "enizers are unable to capture the contextual meaning\n",
      "behind the dialogues and scene settings in a script.\n",
      "It generates tokens based on the contextual under-\n",
      "standing of the sequences, thus capturing the relation\n",
      "between different sequences.\n",
      "It tokenizes words into individual characters and\n",
      "makes character pairs based on consecutive characters.\n",
      "Then it combines two characters into the same token\n",
      "based on the frequency of the repeating character pairs.\n",
      "This process is repeated until a predefined vocabulary\n",
      "size is reached, efficiently and deterministically form-\n",
      "ing a set of subword units which represent the text\n",
      "corpus.\n",
      "The GPT-2 tokenizer has a limitation of only allow-\n",
      "ing a maximum length of 1024 tokens to be encoded.\n",
      "On average the GPT-2 tokenizer makes approximately\n",
      "4 tokens for every 3 words, therefore the scripts get\n",
      "chunked into 700 word chunks and then tokenized.\n",
      "The model is then trained on these individual chunks,\n",
      "retaining all information from the entire script.\n",
      "Once the tokenization is complete, it is ready to be\n",
      "fit into the model for fine-tuning. This approach allows\n",
      "the model to fine-tune on scripts regardless of their size\n",
      "and helps in retaining context as it trains the model on\n",
      "the largest possible chunks, learning patterns between\n",
      "words in a larger sequence.\n",
      "2) Bloom\n",
      "Bloom (BigScience Large Open-science Open-\n",
      "    Summary:\n",
      "\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "    Write a concise summary of the document.\n",
      "    text: and helps in retaining context as it trains the model on\n",
      "the largest possible chunks, learning patterns between\n",
      "words in a larger sequence.\n",
      "2) Bloom\n",
      "Bloom (BigScience Large Open-science Open-\n",
      "access Multilingual) [15] is another state-of-the-art\n",
      "language model based on the transformers architecture.\n",
      "Similar to GPT-2, it also consists of multiple self at-\n",
      "tention mechanisms and feed forward neural networks\n",
      "to generate contextually relevant and coherent text.\n",
      "Bloom is a pre-trained model which is trained on mul-\n",
      "tilingual data. It has 560 million parameters (Bloom\n",
      "560m) therefore can still prove to have significantly\n",
      "positive results for generating text in a single language.\n",
      "Bloom also uses its own tokenizer which tokenizes\n",
      "text based on a probabilistic approach which is op-\n",
      "timized for diverse scripts and has a more flexible\n",
      "tokenization approach and allows better capturing of\n",
      "context and relationships of words in diverse datasets.\n",
      "It uses SentencePiece which uses a uni-gram language\n",
      "model to build its vocabulary.\n",
      "SentencePiece iteratively learns tokens that are most\n",
      "likely to occur in the training data. It merges the most\n",
      "frequently occurring token pairs into larger tokens and\n",
      "probabilistically estimates the likelihood of merging\n",
      "pairs based on observed frequency distributions of\n",
      "merged tokens. This forms a set of subword units\n",
      "which represent the text corpus.\n",
      "The Bloom tokenizer also has a maximum length of\n",
      "2048 tokens to be encoded. Chunking is also used here\n",
      "to chunk a maximum of 512 tokens per chunk. This\n",
      "allowed for a more efficient tokenization process due\n",
      "to the parallelization of the task using a GPU. After\n",
      "the tokenization, the tokens are ready to fit into the\n",
      "Bloom model for fine-tuning.\n",
      "Since LLM is only using a small percentage of the\n",
      "total parameters, there is loss of accuracy in the script\n",
      "generation, the key is to find the trade-off between\n",
      "the loss of accuracy and reducing computational cost\n",
      "which would make this approach scalable and efficient\n",
      "    Summary:\n",
      "\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "    Write a concise summary of the document.\n",
      "    text: generation, the key is to find the trade-off between\n",
      "the loss of accuracy and reducing computational cost\n",
      "which would make this approach scalable and efficient\n",
      "for large and complex datasets.\n",
      "    Summary:\n",
      "\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "    Write a concise summary of the document.\n",
      "    text: D. Text-Image Generation\n",
      "Text-Image generation would allow users to visual-\n",
      "ize the scripts through scenes, and hence ideate upon\n",
      "the movie script generation in a robust manner. Text-\n",
      "Image generation begins with tokenizing and creating\n",
      "an embedding of the query to capture the semantic\n",
      "meaning and context of the query.\n",
      "Fig. 4: Working of Stable Diffusion for Text-Image\n",
      "Generation\n",
      "Tokenization creates tokens which are smaller com-\n",
      "ponents of the input query and the embedding is a\n",
      "numerical vector which represents the tokens. Stable\n",
      "Diffusion [16], one of the best algorithms for image\n",
      "generation, begins with random noise and progres-\n",
      "sively learns to refine the noisy image by de-noising\n",
      "it and eventually generating a clear image relevant\n",
      "to the query. It operates within a latent space - a\n",
      "compressed space in which image generation can be\n",
      "done efficiently.\n",
      "Stable Diffusion uses a process called de-noising\n",
      "diffusion which refines the noisy latent representation\n",
      "in a step-by-step process to create a meaningful image.\n",
      "The model aligns the patterns of the image with that\n",
      "of the embedding to form an image which matches the\n",
      "semantical meaning of the given query. Once the image\n",
      "de-noising is performed, a decoder model is used to\n",
      "upsample this image and transform it into a visible\n",
      "image.\n",
      "The algorithm makes use of cross-attention layers\n",
      "which allows the model to focus on different parts\n",
      "of the query embedding at various stages of the de-\n",
      "noising process. This helps in refining the image in\n",
      "order to maintain the coherence and semantic integrity\n",
      "of the input text during the generation of the image.\n",
      "The Stable Diffusion model used for this approach\n",
      "is CompVis.\n",
      "IV. E VALUATION\n",
      "1) Cosine Similarity:\n",
      "Cosine Similarity is a popular metric for assess-\n",
      "ing how semantically similar a generated script\n",
      "is to its input prompt. In a multidimensional\n",
      "space, it is calculated as the cosine of the angle\n",
      "formed by two vectors. The input prompt and the\n",
      "    Summary:\n",
      "\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "    Write a concise summary of the document.\n",
      "    text: ing how semantically similar a generated script\n",
      "is to its input prompt. In a multidimensional\n",
      "space, it is calculated as the cosine of the angle\n",
      "formed by two vectors. The input prompt and the\n",
      "resulting script’s text are represented by these\n",
      "vectors, respectively.\n",
      "The range of a cosine similarity value is -1 to\n",
      "1. A value of 1 denotes complete alignment, in\n",
      "which the output script’s semantic meaning is\n",
      "exactly the same as that of the input prompt.\n",
      "Being orthogonal, a value of 0 indicates no\n",
      "semantic resemblance. A value of -1, on the\n",
      "other hand, indicates total dissimilarity, with the\n",
      "vectors pointing in opposing directions.\n",
      "The model’s ability to preserve semantic co-\n",
      "herence between the input and the generated\n",
      "output improves with increasing cosine similar-\n",
      "ity. When guaranteeing semantic consistency in\n",
      "text creation is a primary goal, this metric is\n",
      "essential.\n",
      "Cosine Similarity(A, B) = A · B\n",
      "∥A∥∥B∥ (8)\n",
      "where, A and B are vectors.\n",
      "2) Perplexity:\n",
      "Perplexity is another crucial assessment metric ,\n",
      "which is mainly applied to text generation tasks.\n",
      "It evaluates a probabilistic model’s ability to\n",
      "anticipate a word sequence. The entropy of the\n",
      "anticipated probability is used to calculate the\n",
      "perplexity value, which goes from 1 to infinity.\n",
      "The model is more certain of its predictions for\n",
      "the subsequent token in the sequence when the\n",
      "perplexity score is lower. On the other hand,\n",
      "greater uncertainty is indicated by a larger per-\n",
      "plexity, which exposes flaws in the probability\n",
      "distribution of the model. A diagnostic method\n",
      "for assessing a language model’s dependability\n",
      "and fluency is perplexity.\n",
      "Low perplexity is a crucial parameter for as-\n",
      "sessing performance in natural language genera-\n",
      "tion tasks since models with low perplexity are\n",
      "generally better able to generate coherent and\n",
      "contextually relevant sequences. Mathematically,\n",
      "Perplexity (PPL) is calculated as:\n",
      "PPL = exp\n",
      " \n",
      "− 1\n",
      "N\n",
      "NX\n",
      "i=1\n",
      "log P(wi | w1, . . . , wi−1)\n",
      "!\n",
      "(9)\n",
      "where, P(wi | w1, . . . , wi−1) is the conditional\n",
      "    Summary:\n",
      "\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "    Write a concise summary of the document.\n",
      "    text: contextually relevant sequences. Mathematically,\n",
      "Perplexity (PPL) is calculated as:\n",
      "PPL = exp\n",
      " \n",
      "− 1\n",
      "N\n",
      "NX\n",
      "i=1\n",
      "log P(wi | w1, . . . , wi−1)\n",
      "!\n",
      "(9)\n",
      "where, P(wi | w1, . . . , wi−1) is the conditional\n",
      "probability of the i-th word given all the previous\n",
      "words w1, . . . , wi−1 in the sequence and N is\n",
      "the total number of words in the test sequence.\n",
      "3) CLIP Score:\n",
      "It is a metric used to assess how well created\n",
      "    Summary:\n",
      "\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "    Write a concise summary of the document.\n",
      "    text: words w1, . . . , wi−1 in the sequence and N is\n",
      "the total number of words in the test sequence.\n",
      "3) CLIP Score:\n",
      "It is a metric used to assess how well created\n",
      "images match the written prompts that go with\n",
      "them. CLIP generates vector representations for\n",
      "the created image and the text prompt using\n",
      "a shared embedding space. Cosine similarity is\n",
      "    Summary:\n",
      "\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "    Write a concise summary of the document.\n",
      "    text: then used to calculate how similar these embed-\n",
      "dings are to one another.\n",
      "While a lower score signifies poor alignment,\n",
      "a higher CLIP Score shows that the resulting\n",
      "image closely reflects the text prompt’s semantic\n",
      "intent. In multi-modal applications where pre-\n",
      "serving the prompt’s integrity in the visual rep-\n",
      "resentation is crucial, such as picture synthesis\n",
      "from textual descriptions, this measure is very\n",
      "useful.\n",
      "The CLIP Score guarantees that produced out-\n",
      "puts satisfy the required degree of semantic\n",
      "accuracy by offering a measurable indicator of\n",
      "textual and visual coherence.\n",
      "CLIP(T, I) = ET · EI\n",
      "∥ET ∥∥EI∥ (10)\n",
      "where, ET and EI are the embeddings of the\n",
      "text and image, respectively and ∥ET ∥ and ∥EI∥\n",
      "represent the norms (magnitudes) of these em-\n",
      "bedding vectors.\n",
      "V. R ESULTS\n",
      "TABLE I: Model evaluation metrics and their average\n",
      "scores\n",
      "Model Metric Score (Average)\n",
      "GPT-2 Cosine Similarity 0.5011\n",
      "GPT-2 Perplexity 1.7443\n",
      "Bloom Cosine Similarity 0.5058\n",
      "Bloom Perplexity 1.6892\n",
      "Gemini-Pro Cosine Similarity 0.5713\n",
      "CompVis CLIP Score 0.3061\n",
      "1) GPT-2 (Cosine Similarity):\n",
      "Fig.5 shows a density plot of cosine similarity\n",
      "using the fine-tuned GPT-2 model. The values\n",
      "go as high as 0.8 and as low as 0.2. The graph\n",
      "suggests that the generated script at times has\n",
      "very high contextual similarity between the input\n",
      "query and the generated script and at times very\n",
      "low.\n",
      "Fig. 5: Density Plot for Cosine Similarity (fine-tuned\n",
      "GPT-2)\n",
      "The lower values can suggest poor generation\n",
      "leading to lesser context being included in the\n",
      "generated script or can be due to high creativity\n",
      "which leads to a variety of information along\n",
      "with the details outlined in the prompt being\n",
      "mentioned in the script.\n",
      "The higher values suggest that the script per-\n",
      "fectly encompasses the required details from the\n",
      "prompt but can also suggest that the generation\n",
      "had lesser creativity and did not add many details\n",
      "which were not mentioned. This can suggest\n",
      "that a great input prompt with a lot of details\n",
      "    Summary:\n",
      "\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "    Write a concise summary of the document.\n",
      "    text: prompt but can also suggest that the generation\n",
      "had lesser creativity and did not add many details\n",
      "which were not mentioned. This can suggest\n",
      "that a great input prompt with a lot of details\n",
      "was mentioned or the generation was with poor\n",
      "creativity.\n",
      "Majority of the cosine similarity values lying\n",
      "near the average of 0.5011 suggests that the\n",
      "approach was able to generate a script which\n",
      "contained the details from the prompt and was\n",
      "also able to include creative aspects in the script.\n",
      "2) GPT-2 (Perplexity):\n",
      "Fig.6 shows a density plot of the perplexity using\n",
      "fine-tuned GPT-2. The perplexity had an average\n",
      "of 1.7443. The perplexity value varied on the\n",
      "lower side and upper side of this average value.\n",
      "The lower values suggest that the model was\n",
      "less surprised in the token generation of these\n",
      "scripts leading to a well structured script where\n",
      "followup words were expected more often than\n",
      "not.\n",
      "Fig. 6: Density Plot for Perplexity (GPT-2)\n",
      "The higher values can signify a script which\n",
      "made the model more surprised during the token\n",
      "generation. This suggests that the grammatical\n",
      "and semantic clarity of the sentences was jeopar-\n",
      "dized and the sentences more often than not, did\n",
      "not make sense grammatically and contextually.\n",
      "The scripts with perplexity near the average\n",
      "value can suggest that they made sense gram-\n",
      "matically and contextually to some degree but\n",
      "could have either left something to be desired\n",
      "in the generation or the creative aspect of the\n",
      "generation left the model more surprised at the\n",
      "token generation, attributing to its slightly higher\n",
      "perplexity score. This could suggest that the\n",
      "ideal value of perplexity for script generation\n",
      "which includes good creativity could be that with\n",
      "values near the average perplexity of 1.7443.\n",
      "3) Bloom (Cosine Similarity):\n",
      "    Summary:\n",
      "\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "    Write a concise summary of the document.\n",
      "    text: Fig.7 shows a density plot of cosine similar-\n",
      "ity using the fine-tuned Bloom model, which\n",
      "differs from the fine-tuned GPT-2 model in its\n",
      "distribution and average values. While the cosine\n",
      "similarity for GPT-2 averaged at 0.5011, the\n",
      "Bloom model’s average was 0.5058.\n",
      "Fig. 7: Density Plot for Cosine Similarity (fine-tuned\n",
      "Bloom)\n",
      "Both models showed a range of values from\n",
      "0.2 to 0.8, indicating varying levels of con-\n",
      "textual similarity between the input query and\n",
      "the generated script. However, the Bloom model\n",
      "appears to strike a slightly different balance, with\n",
      "its clustering around the average suggesting a\n",
      "consistent ability to include prompt details while\n",
      "introducing creative aspects.\n",
      "In comparison, the GPT-2 model’s lower and\n",
      "higher values might more distinctly reflect out-\n",
      "puts that either deviate significantly from the\n",
      "prompt or align too closely, potentially at the\n",
      "expense of creativity. The differences in average\n",
      "values and distributions suggest that Bloom may\n",
      "provide a more balanced generation, while GPT-\n",
      "2 may exhibit greater variance in its outputs\n",
      "depending on the nature of the prompt.\n",
      "According to the variations in average values\n",
      "and distributions, Bloom might produce a more\n",
      "balanced generation, but GPT-2 might produce\n",
      "outputs that vary more depending on the prompt.\n",
      "4) Bloom (Perplexity):\n",
      "Fig.6 compares the density plots of perplexity\n",
      "for fine-tuned GPT-2 and Bloom models, demon-\n",
      "strating variations in their text generation. GPT-2\n",
      "recorded an average perplexity of 1.7443, while\n",
      "Bloom achieved a lesser average of 1.6892.\n",
      "Fig. 8: Density Plot for Perplexity (fine-tuned Bloom)\n",
      "Higher perplexity values for GPT-2 indicate dif-\n",
      "ficulties in preserving grammatical or semantic\n",
      "clarity, which frequently results in outputs that\n",
      "lack contextual sense. Lower perplexity val-\n",
      "ues, on the other hand, indicate well-structured\n",
      "scripts with predictable token generation. Al-\n",
      "though some may have had space for growth in\n",
      "generation quality, scripts with ambiguity close\n",
      "    Summary:\n",
      "\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "    Write a concise summary of the document.\n",
      "    text: ues, on the other hand, indicate well-structured\n",
      "scripts with predictable token generation. Al-\n",
      "though some may have had space for growth in\n",
      "generation quality, scripts with ambiguity close\n",
      "to the average demonstrated a balance between\n",
      "coherence and inventiveness.\n",
      "Bloom’s tighter grouping and lower confusion,\n",
      "on the other hand, point to a more reliable\n",
      "capacity for producing language that is both con-\n",
      "textually relevant and coherent. Its values close\n",
      "to the mean show a steady equilibrium between\n",
      "following the prompt and adding originality.\n",
      "Bloom’s smaller range of perplexity scores sug-\n",
      "gests a lower variability than GPT-2, which\n",
      "makes it more dependable for applications de-\n",
      "manding accuracy. However, applications that\n",
      "value diversity and flexibility in script produc-\n",
      "tion could find GPT-2 more appropriate due to\n",
      "its wider range\n",
      "5) Gemini-Pro (Cosine Similarity):\n",
      "Fig.9 shows the density plot shows the distri-\n",
      "bution of cosine similarity values for outputs\n",
      "produced by the Gemini-Pro model using RAG,\n",
      "with an average cosine similarity of 0.5713.The\n",
      "range is from 0.2 to 0.8.\n",
      "This variability shows how well the model per-\n",
      "forms in striking a balance between contex-\n",
      "tual alignment of generated scripts and creative\n",
      "flexibility; lower cosine similarity values, closer\n",
      "to 0.2, indicate instances where the generated\n",
      "scripts either lack sufficient context from the in-\n",
      "put prompt or exhibit high creativity by deviating\n",
      "from the input to include diverse information;\n",
      "higher values, approaching 0.8, indicate outputs\n",
      "that closely align with the prompt, effectively\n",
      "capturing its details; however, such outputs may\n",
      "also suggest limited creativity, as the generation\n",
      "may strictly follow the prompt without adding\n",
      "subtle or unique information.\n",
      "Fig. 9: Density Plot for Cosine Similarity (Gemini-\n",
      "Pro)\n",
      "The concentration of cosine similarity values\n",
      "around the average of 0.5713 shows that Gemini-\n",
      "    Summary:\n",
      "\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "    Write a concise summary of the document.\n",
      "    text: Pro successfully strikes a balance between cre-\n",
      "ativity and relevance, generating scripts that use\n",
      "RAG to add meaningful and creative elabora-\n",
      "tion to the content while incorporating relevant\n",
      "information from the prompt.This performance\n",
      "shows how well Gemini-Pro combines creative\n",
      "flexibility with rapid alignment, outperforming\n",
      "other models in the process.\n",
      "6) CompVis (CLIP Score):\n",
      "Fig.10 shows a density plot for the CLIP score\n",
      "of the image generated from the input prompt.\n",
      "The average CLIP score was 0.3061.\n",
      "This shows a weaker alignment of the image\n",
      "with the features mentioned in the prompt or\n",
      "could also suggest that the features in the image\n",
      "are loosely related to the details in the prompt.\n",
      "This could be due to the model under-performing\n",
      "or the input prompts not being detailed enough\n",
      "to generate distinct features in the image.\n",
      "Fig. 10: Density Plot for CLIP Score (CompVis)\n",
      "Aside from lack of details in the prompt, abstract\n",
      "or complex details could also lead to a lower\n",
      "CLIP score since the model might be unable to\n",
      "make a strong connection between these con-\n",
      "cepts and features in the image.\n",
      "7) Reason why Gemini-Pro cannot be evalu-\n",
      "ated using Perplexity: To calculate perplexity,\n",
      "a probabilistic token-based prediction approach\n",
      "is required but since Gemini-Pro is being inte-\n",
      "grated with the RAG Pipeline, it is not using\n",
      "any probability distribution to predict the next\n",
      "tokens, it rather combines the retrieval mecha-\n",
      "nisms of RAG with generation.\n",
      "Since RAG models do not use a probabilistic\n",
      "approach to predict the next tokens, Gemini-Pro\n",
      "thus does not produce a probability distribution\n",
      "and perplexity cannot be used as an evaluation\n",
      "metric for Gemini-Pro.\n",
      "VI. F UTURE SCOPE\n",
      "Due to hardware constraints, the LLMs used in the\n",
      "proposed methodology have limited capabilities. Al-\n",
      "though LLMs provided accurate responses to the query\n",
      "and performed well on the evaluation metrics, better\n",
      "models with a greater number of parameters can be\n",
      "    Summary:\n",
      "\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "    Write a concise summary of the document.\n",
      "    text: though LLMs provided accurate responses to the query\n",
      "and performed well on the evaluation metrics, better\n",
      "models with a greater number of parameters can be\n",
      "used to further refine the movie scripts to adhere to the\n",
      "specifications in a better way. Better stable diffusion\n",
      "models could also be used to generate accurate text\n",
      "inside an image, or generate higher quality images for\n",
      "better visualization of the generated movie script.\n",
      "The models could also be optimized to give sug-\n",
      "gestions for what kind of lighting or scene setting is\n",
      "needed to direct such a movie script in an apt manner\n",
      "by storing more metadata about the script in the vector\n",
      "database.\n",
      "VII. C ONCLUSION\n",
      "The proposed methodologies demonstrate the poten-\n",
      "tial of advanced NLP techniques like RAG and Fine-\n",
      "Tuning LLMs, and Image Generation algorithms like\n",
      "Stable Diffusion in order to automate script and scene\n",
      "generation in the cinema industry.\n",
      "The lower perplexity and high cosine similarity\n",
      "values indicate a high level of coherence and fluency\n",
      "in generated dialogues, which is important for main-\n",
      "taining human-like script writing techniques. CLIP\n",
      "Score indicates that despite the room for improvement,\n",
      "Stable Diffusion can help visualize the input query in\n",
      "the form of a movie scene with a moderate level of\n",
      "alignment.\n",
      "This approach reduces the barriers in creative pro-\n",
      "cesses, allowing a better overall script generation.\n",
      "ACKNOWLEDGMENT\n",
      "We would like to extend our sincere gratitude to\n",
      "Symbiosis Institute of Technology, Symbiosis Interna-\n",
      "tional (Deemed University), Pune, India, for providing\n",
      "the invaluable support and platform necessary to con-\n",
      "duct our research work. We are thankful for providing\n",
      "the nurturing environment where we had the privilege\n",
      "to learn and explore.\n",
      "REFERENCES\n",
      "[1] Asli Celikyilmaz, Elizabeth Clark, and Jianfeng Gao. Eval-\n",
      "uation of text generation: A survey. arXiv preprint\n",
      "arXiv:2006.14799, 2020.\n",
      "[2] A Vaswani. Attention is all you need. Advances in Neural\n",
      "Information Processing Systems , 2017.\n",
      "    Summary:\n",
      "\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "    Write a concise summary of the document.\n",
      "    text: uation of text generation: A survey. arXiv preprint\n",
      "arXiv:2006.14799, 2020.\n",
      "[2] A Vaswani. Attention is all you need. Advances in Neural\n",
      "Information Processing Systems , 2017.\n",
      "[3] Xiang Li, John Thickstun, Ishaan Gulrajani, Percy S Liang,\n",
      "and Tatsunori B Hashimoto. Diffusion-lm improves con-\n",
      "trollable text generation. Advances in Neural Information\n",
      "    Summary:\n",
      "\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "    Write a concise summary of the document.\n",
      "    text: [3] Xiang Li, John Thickstun, Ishaan Gulrajani, Percy S Liang,\n",
      "and Tatsunori B Hashimoto. Diffusion-lm improves con-\n",
      "trollable text generation. Advances in Neural Information\n",
      "Processing Systems, 35:4328–4343, 2022.\n",
      "[4] Angela Fan, Mike Lewis, and Yann Dauphin. Hierarchical\n",
      "neural story generation. arXiv preprint arXiv:1805.04833 ,\n",
      "2018.\n",
      "[5] Tom B Brown. Language models are few-shot learners. arXiv\n",
      "preprint arXiv:2005.14165, 2020.\n",
      "[6] Pradyumna Tambwekar, Murtaza Dhuliawala, Lara J Martin,\n",
      "Animesh Mehta, Brent Harrison, and Mark O Riedl. Control-\n",
      "lable neural story plot generation via reward shaping. arXiv\n",
      "preprint arXiv:1809.10736, 2018.\n",
      "[7] Sanidhya Mangal, Poorva Joshi, and Rahul Modak. Lstm vs.\n",
      "gru vs. bidirectional rnn for script generation. arXiv preprint\n",
      "arXiv:1908.04332, 2019.\n",
      "[8] Lili Yao, Nanyun Peng, Ralph Weischedel, Kevin Knight,\n",
      "Dongyan Zhao, and Rui Yan. Plan-and-write: Towards better\n",
      "automatic storytelling. In Proceedings of the AAAI Conference\n",
      "on Artificial Intelligence , volume 33, pages 7378–7385, 2019.\n",
      "[9] Yutao Zhu, Ruihua Song, Zhicheng Dou, Jian-Yun Nie, and Jin\n",
      "Zhou. Scriptwriter: Narrative-guided script generation. arXiv\n",
      "preprint arXiv:2005.10331, 2020.\n",
      "    Summary:\n",
      "\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "    Write a concise summary of the document.\n",
      "    text: [10] Gayatri Bhat, Avneesh Saluja, Melody Dye, and Jan Flor-\n",
      "janczyk. Hierarchical encoders for modeling and interpreting\n",
      "screenplays. arXiv preprint arXiv:2004.14532 , 2020.\n",
      "[11] Le Fang, Tao Zeng, Chaochun Liu, Liefeng Bo, Wen Dong,\n",
      "and Changyou Chen. Outline to story: Fine-grained control-\n",
      "lable story generation from cascaded events. arXiv preprint\n",
      "arXiv:2101.00822, 2021.\n",
      "[12] Keisuke Sakaguchi, Chandra Bhagavatula, Ronan Le Bras,\n",
      "Niket Tandon, Peter Clark, and Yejin Choi. proscript: Partially\n",
      "ordered scripts generation via pre-trained language models.\n",
      "arXiv preprint arXiv:2104.08251 , 2021.\n",
      "[13] Fatima Dayo, Ahmed Ali Memon, and Nasrullah Dharejo.\n",
      "Scriptwriting in the age of ai: Revolutionizing storytelling with\n",
      "artificial intelligence. Journal of Media & Communication ,\n",
      "4(1):24–38, 2023.\n",
      "[14] Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario\n",
      "Amodei, Ilya Sutskever, et al. Language models are unsuper-\n",
      "vised multitask learners. OpenAI blog, 1(8):9, 2019.\n",
      "[15] Teven Le Scao, Angela Fan, Christopher Akiki, Ellie Pavlick,\n",
      "Suzana Ili ´c, Daniel Hesslow, Roman Castagn ´e, Alexan-\n",
      "dra Sasha Luccioni, Franc ¸ois Yvon, Matthias Gall ´e, et al.\n",
      "Bloom: A 176b-parameter open-access multilingual language\n",
      "model. 2023.\n",
      "[16] Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick\n",
      "Esser, and Bj ¨orn Ommer. High-resolution image synthesis\n",
      "with latent diffusion models. In Proceedings of the IEEE/CVF\n",
      "conference on computer vision and pattern recognition , pages\n",
      "10684–10695, 2022.\n",
      "[17] Y Zhang. Dialogpt: Large-scale generative pre-training\n",
      "for conversational response generation. arXiv preprint\n",
      "arXiv:1911.00536, 2019.\n",
      "    Summary:\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ansh Lulla\\VS-Code\\Langchain_tutorial\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (3238 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "    Provide the final summary of the entire speech with these important points.\n",
      "    Add a motivational title, start the summary with a hook, and end with a call to action and provide the summary points in numbers. \n",
      "    Text: Here is a concise summary of the document:\n",
      "\n",
      "The PlotPoint framework is an AI-driven system that automates movie scriptwriting and scene generation using Natural Language Processing and Deep Learning algorithms. The system uses a prompt-based approach, where a user inputs a simple prompt and the system generates a customizable movie script. The framework combines Retrieval Augmented Generation (RAG) and fine-tuning of Large Language Models (LLMs) to generate context-specific output. Additionally, Stable Diffusion is used to visualize script elements and extend script generation to scene generation. The system has been tested on a dataset of movie scripts and shown promising results, with a cosine similarity of 0.5713 and perplexity of 1.6892.\n",
      "\n",
      "The document discusses the use of Natural Language Processing (NLP) and Deep Learning models to automate scriptwriting, particularly in the entertainment industry. The authors demonstrate the effectiveness of using GPT-2 and Bloom models to generate coherent and relevant scripts, achieving a cosine similarity of 0.5011 and 0.5058, respectively, with the input prompt. They also show that CompVis can be used to generate movie scenes, achieving a CLIP score of 0.3061. The authors highlight the benefits of automating scriptwriting, including reduced time and effort required, and the potential to create high-quality, personalized content.\n",
      "\n",
      "Here is a concise summary of the document:\n",
      "\n",
      "Systems can use pre-existing movie script and dialogue datasets to understand human-like dialogue structures, enabling personalized script generation.\n",
      "\n",
      "The document discusses the need for personalized script generation, which is not currently addressed by existing tools. These tools are primarily focused on general text generation, but lack the ability to incorporate customizable elements such as character descriptions, behavior, and scene specifications. The motivation for this research is to streamline the script generation process, enabling rapid prototyping and customization, which can lead to improved plot complexity and quality.\n",
      "\n",
      "The document discusses the potential of automated script generation using Large Language Models (LLMs) and Reinforcement-Aware Generators (RAG) systems. The goal is to reduce barriers for individuals to create high-quality scripts, promoting creative freedom and refining ideas. The document also provides a literature review of existing research on text generation, highlighting the strengths and challenges of various evaluation metrics, models, and architectures.\n",
      "\n",
      "The document discusses various approaches to story generation using natural language processing (NLP) techniques. Different models and architectures are evaluated for their performance in generating coherent and engaging stories. The approaches range from using pre-trained embeddings and fusion of different models to introducing reward-shaping techniques and incorporating static and dynamic schema for coherence. While some models demonstrate strong performance, others struggle with fine-tuning demands, interpretability issues, and capturing complex sequences. Overall, the document highlights the challenges and opportunities in story generation and the need for further improvement in this area.\n",
      "\n",
      "Here is a concise summary of the document:\n",
      "\n",
      "Researchers propose two different approaches to script generation and analysis. Zhu et al. use Word2Vec embeddings with DL2R and MVLSTM models to develop a narrative-guided script generation model, but this approach is limited by its structured design. Bhat et al. apply hierarchical encoders to screenplay modeling, genre classification, and mood classification using Bag-of-Embeddings and GRU.\n",
      "\n",
      "The document discusses the application of AI in scriptwriting and storytelling. Researchers have used various techniques such as hierarchical encoders, Bag-of-Embeddings, GRU, and pre-trained language models like T5 to develop models for screenplay modeling, genre and mood classification, and script generation. The models have shown promising results, but challenges remain, including generalization outside of the domain and achieving human-level performance. The document also highlights the potential impact of AI on the cinema industry, including improving interactive storytelling, character development, and narrative creation, as well as the need to address ethical concerns such as moral dilemmas and balancing human and AI collaboration.\n",
      "\n",
      "Here is a concise summary of the document:\n",
      "\n",
      "The Transformer architecture is a type of neural network model that is used for natural language processing tasks, particularly machine translation. It consists of an Encoder and a Decoder, which work together to generate predictions. The Encoder processes the input sequence and generates embeddings, while the Decoder uses these embeddings and the target sequence to generate predictions. The Transformer addresses the limitations of traditional Seq2Seq models by using Attention Mechanism, which allows it to focus on specific parts of the input sequence and generate more optimal outputs. The Attention Mechanism computes attention scores for each token based on three vectors: Query, Key, and Value.\n",
      "\n",
      "Here is a concise summary of the document:\n",
      "\n",
      "The attention mechanism in transformers is used to focus on important parts of the input and generate contextually relevant outputs. It consists of three learned weight matrices (Q, K, V) and calculates scores, which are then normalized using a softmax function to produce a probability distribution. The weighted sum of value vectors is then computed using these scores. The multi-head attention mechanism runs multiple single-head attention mechanisms in parallel and concatenates their results with a learned weight matrix. This attention mechanism helps transformers generate more accurate and complete responses. Additionally, the RAG (Retrieval Augmented Generation) framework is introduced, which uses an external database to provide relevant information to LLMs and improve their responses.\n",
      "\n",
      "Here is a concise summary of the document:\n",
      "\n",
      "The RAG pipeline aims to improve language model limitations by leveraging a vector database of movie script chunks, which are segmented and embedded using a sentence transformer. The database is optimized using IVF-Flat, a clustering algorithm that reduces search time complexity. When a query is input, the algorithm calculates the L2 Norm between the query embedding and the chunk embeddings to retrieve the top 5 most similar chunks, which are then used to generate contextually relevant responses.\n",
      "\n",
      "Here is a concise summary of the document:\n",
      "\n",
      "The document describes a Natural Language Generation (NLG) algorithm, called RAG, that uses a Large Language Model (LLM) to generate movie scripts. To achieve this, RAG uses a query embedding to narrow down the search for relevant movie script chunks, and then uses cosine similarity and Euclidean distance to rank the retrieved chunks. The algorithm uses Gemini-Pro, a state-of-the-art LLM, to generate the final script while preventing hallucination. Fine-tuning the LLM on a task-specific dataset ensures that the generated script captures the semantic relationships within the movie scripts.\n",
      "\n",
      "The document discusses the use of pre-trained language models' embeddings to capture semantic relationships in movie scripts, ensuring proper dialogue flow and adherence to specifications.\n",
      "\n",
      "The document describes the fine-tuning of large language models (LLMs) for text generation tasks. Specifically, it introduces two language models: GPT-2, a state-of-the-art language model based on the transformer architecture, and Bloom, a large-scale open-source LLM. The document explains the tokenizer used by GPT-2, which captures contextual meaning and limits the maximum length of input text to 1024 tokens. The tokenizer breaks down scripts into 700-word chunks and trains the model on each chunk, allowing it to retain context and learn patterns between words.\n",
      "\n",
      "Here is a concise summary of the document:\n",
      "\n",
      "The document discusses two state-of-the-art language models: GPT-2 and Bloom. Both models are based on the transformers architecture and use self-attention mechanisms and feed-forward neural networks to generate contextually relevant text. Bloom is a pre-trained model trained on multilingual data with 560 million parameters, and its tokenizer uses a probabilistic approach to capture context and relationships in diverse datasets. The document highlights the importance of finding a balance between accuracy and computational cost to make this approach scalable and efficient.\n",
      "\n",
      "The key to efficient generation methods is finding a balance between accuracy and computational cost, allowing for scalability and efficiency on large and complex datasets.\n",
      "\n",
      "Here is a concise summary of the document:\n",
      "\n",
      "Text-Image generation is a technique that allows users to visualize movie scripts as scenes, enabling robust ideation. It starts by tokenizing and embedding the query to capture its semantic meaning and context. The Stable Diffusion algorithm, a state-of-the-art image generation method, is used to generate an image from the query. It refines a noisy latent representation step-by-step, aligning the image patterns with the query embedding to form a meaningful image. A decoder upsamples the image and transforms it into a visible image. Cross-attention layers help maintain the coherence and semantic integrity of the input text during generation.\n",
      "\n",
      "Here is a concise summary of the document:\n",
      "\n",
      "The document discusses two metrics used to evaluate the performance of a language model: Cosine Similarity and Perplexity. Cosine Similarity measures the semantic similarity between the input prompt and the generated script, with a value ranging from -1 to 1, where 1 indicates complete alignment and 0 indicates no semantic resemblance. Perplexity, on the other hand, evaluates a language model's ability to anticipate a word sequence, with lower perplexity indicating more certain predictions and higher perplexity indicating uncertainty. Both metrics are crucial for assessing a language model's performance in natural language generation tasks, with low perplexity indicating better performance.\n",
      "\n",
      "The document discusses two metrics used to evaluate the quality of language models: Perplexity (PPL) and CLIP Score. Perplexity is calculated as the expected log probability of a test sequence, given the model's parameters. It is a measure of how well the model predicts the next word in a sequence, with lower values indicating better performance. CLIP Score, on the other hand, is a metric used to assess how well created sequences are in a language model.\n",
      "\n",
      "The document discusses two metrics used to evaluate the quality of generated text or images: 1) Perplexity, which measures how well a model predicts the next word in a sequence of words, and 2) CLIP Score, which assesses how well created images match written prompts by generating vector representations for both and comparing their similarity.\n",
      "\n",
      "The document discusses the CLIP (Contrastive Language-Image Pre-training) Score, a measure of the similarity between text and image embeddings. A higher CLIP Score indicates that the generated image closely reflects the semantic intent of the text prompt. The score is useful in multi-modal applications, such as picture synthesis from textual descriptions, where preserving the prompt's integrity in the visual representation is crucial. The document also presents evaluation metrics for several models, including GPT-2, Bloom, and Gemini-Pro, and provides a density plot for the cosine similarity of a fine-tuned GPT-2 model.\n",
      "\n",
      "Here is a concise summary of the document:\n",
      "\n",
      "The document examines the performance of three language models (GPT-2, Bloom, and a custom generation model) in generating scripts based on input prompts. The results show that the custom generation model produced scripts with average cosine similarity values near 0.5011, suggesting a balance between including details from the prompt and adding creative aspects. GPT-2's perplexity scores had an average value of 1.7443, with lower values indicating well-structured scripts and higher values suggesting grammatical and semantic errors. The results suggest that the ideal value of perplexity for script generation with good creativity may be near the average value.\n",
      "\n",
      "Here is a concise summary of the document:\n",
      "\n",
      "The document compares the performance of two language models, GPT-2 and Bloom, in terms of their fine-tuning for text generation. The results show that the Bloom model has a slightly higher average cosine similarity (0.5058) and lower average perplexity (1.6892) compared to the GPT-2 model (0.5011 and 1.7443, respectively). The analysis suggests that the Bloom model may produce more balanced generations, while the GPT-2 model may produce outputs that vary more depending on the prompt.\n",
      "\n",
      "Here is a concise summary of the document:\n",
      "\n",
      "The document compares the performance of three language models (GPT-2, Bloom, and Gemini-Pro) in generating scripts. It highlights their strengths and weaknesses in terms of coherence, inventiveness, and contextual relevance. GPT-2 shows a wider range of perplexity scores, indicating more variability in its script production, but also potentially more creative and diverse outputs. Bloom, on the other hand, demonstrates a more reliable capacity for producing coherent and contextually relevant language, with a smaller range of perplexity scores indicating more dependability. Gemini-Pro, as measured by cosine similarity, balances contextual alignment and creative flexibility, with a majority of outputs falling around an average similarity of 0.5713.\n",
      "\n",
      "The document evaluates the performance of Gemini-Pro, a language model that combines creative flexibility with rapid alignment using the RAG pipeline. The results show that Gemini-Pro outperforms other models in generating scripts that add meaningful and creative elaboration to the content while incorporating relevant information from the prompt. However, the CompVis model (CLIP score) shows a weaker alignment of the generated image with the features mentioned in the prompt, which could be due to the model underperforming or the input prompts not being detailed enough. Additionally, the document explains that perplexity cannot be used as an evaluation metric for Gemini-Pro since it does not use a probabilistic approach to predict the next tokens. Finally, the authors suggest that better models with a greater number of parameters can be used in the future to further improve the performance of Gemini-Pro.\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "    Provide the final summary of the entire speech with these important points.\n",
      "    Add a motivational title, start the summary with a hook, and end with a call to action and provide the summary points in numbers. \n",
      "    Text: The document proposes using advanced natural language processing (NLP) techniques, such as RAG and fine-tuning large language models, to automate script and scene generation in the cinema industry. While the current models provide accurate responses and perform well on evaluation metrics, further refinement can be achieved with better models and stable diffusion models. Additionally, optimizing the models to provide suggestions for lighting, scene setting, and metadata storage could enhance the output. The approach has the potential to reduce creative process barriers and improve overall script generation.\n",
      "\n",
      "The document is a survey on the evaluation of text generation, a preprint published on arXiv in 2020.\n",
      "\n",
      "The provided document appears to be a list of references to research papers in the field of artificial intelligence, specifically in the area of controlled text generation and storytelling. The papers discuss various techniques for generating text, such as diffusion-based methods, hierarchical neural story generation, reward shaping, and narrative-guided script generation. The references include papers published between 2018 and 2022, and appear to be a collection of relevant research in the field.\n",
      "\n",
      "Here is a concise summary of the document:\n",
      "\n",
      "The document appears to be a list of academic papers and articles related to artificial intelligence (AI) and natural language processing (NLP) in the context of storytelling and scriptwriting. The papers discuss various AI models and techniques for generating screenplays, stories, and scripts, as well as interpreting and controlling the narrative flow. Some of the papers also explore the potential applications of AI in scriptwriting, such as revolutionizing storytelling and improving the creative process.\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "    Provide the final summary of the entire speech with these important points.\n",
      "    Add a motivational title, start the summary with a hook, and end with a call to action and provide the summary points in numbers. \n",
      "    Text: **\"Unleashing the Power of AI in Scriptwriting: A New Era of Creativity and Efficiency\"**\n",
      "\n",
      "**Summary:**\n",
      "\n",
      "In this comprehensive document, we explored the potential of Artificial Intelligence (AI) in scriptwriting, discussing the PlotPoint framework, which uses Natural Language Processing (NLP) and Deep Learning algorithms to automate movie scriptwriting and scene generation. We also examined the use of Large Language Models (LLMs) and Reinforcement-Aware Generators (RAG) systems to generate high-quality scripts, and the importance of fine-tuning LLMs for text generation tasks.\n",
      "\n",
      "**Key Points:**\n",
      "\n",
      "1. **Efficient Script Generation:** The PlotPoint framework automates movie scriptwriting and scene generation using NLP and Deep Learning algorithms, reducing the time and effort required to create high-quality scripts.\n",
      "2. **Personalized Script Generation:** The use of LLMs and RAG systems enables personalized script generation, incorporating customizable elements such as character descriptions, behavior, and scene specifications.\n",
      "3. **Improved Coherence and Contextual Relevance:** Fine-tuning LLMs for text generation tasks improves the coherence and contextual relevance of generated scripts, making them more engaging and realistic.\n",
      "4. **Balancing Accuracy and Computational Cost:** The key to efficient generation methods is finding a balance between accuracy and computational cost, allowing for scalability and efficiency on large and complex datasets.\n",
      "5. **Text-Image Generation:** The Stable Diffusion algorithm enables the visualization of movie scripts as scenes, allowing for robust ideation and creative freedom.\n",
      "6. **Evaluation Metrics:** Perplexity and CLIP Score are used to evaluate the performance of language models, with lower perplexity indicating better performance and a higher CLIP Score indicating a closer match between generated images and text prompts.\n",
      "7. **Comparison of Language Models:** GPT-2, Bloom, and Gemini-Pro were compared, with Bloom showing a slightly higher average cosine similarity and lower average perplexity compared to GPT-2.\n",
      "\n",
      "**Call to Action:**\n",
      "\n",
      "Join the revolution in scriptwriting and storytelling by embracing the power of AI. With the PlotPoint framework and LLMs, you can create high-quality, personalized scripts and scenes, revolutionizing the way you tell stories.\n",
      "\n",
      "**\"Revolutionizing the Art of Storytelling: Unlocking the Power of AI\"**\n",
      "\n",
      "**Hook:** Imagine a world where the creative process of scriptwriting is transformed by the power of artificial intelligence. A world where ideas flow effortlessly, and scripts are generated with precision and accuracy.\n",
      "\n",
      "**Summary:**\n",
      "\n",
      "Here are the key points from the document:\n",
      "\n",
      "1. **Advanced NLP Techniques**: The document proposes using advanced natural language processing (NLP) techniques, such as RAG and fine-tuning large language models, to automate script and scene generation in the cinema industry.\n",
      "2. **Model Refining**: Further refinement can be achieved with better models and stable diffusion models, which can lead to more accurate and creative output.\n",
      "3. **Optimization**: Optimizing the models to provide suggestions for lighting, scene setting, and metadata storage can enhance the output and improve the creative process.\n",
      "4. **Barrier Reduction**: The approach has the potential to reduce creative process barriers and improve overall script generation, making it easier for writers to bring their ideas to life.\n",
      "5. **Research Overview**: The document appears to be a list of references to research papers in the field of artificial intelligence, specifically in the area of controlled text generation and storytelling.\n",
      "6. **Controlled Text Generation**: The papers discuss various techniques for generating text, such as diffusion-based methods, hierarchical neural story generation, reward shaping, and narrative-guided script generation.\n",
      "7. **Potential Applications**: The papers explore the potential applications of AI in scriptwriting, such as revolutionizing storytelling and improving the creative process.\n",
      "\n",
      "**Call to Action:** Join the revolution in storytelling by embracing the power of AI and its potential to transform the scriptwriting process. Together, let's unlock new creative possibilities and push the boundaries of what's possible in the world of cinema.\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Here is the rewritten summary with the requested format:\n",
      "\n",
      "**\"Revolutionizing the Art of Storytelling: Unlocking the Power of AI\"**\n",
      "\n",
      "**Hook:** Imagine a world where the creative process of scriptwriting is transformed by the power of artificial intelligence. A world where ideas flow effortlessly, and scripts are generated with precision and accuracy.\n",
      "\n",
      "**Summary:**\n",
      "\n",
      "Here are the key points from the document:\n",
      "\n",
      "1. **Efficient Script Generation:** The PlotPoint framework automates movie scriptwriting and scene generation using NLP and Deep Learning algorithms, reducing the time and effort required to create high-quality scripts.\n",
      "2. **Personalized Script Generation:** The use of LLMs and RAG systems enables personalized script generation, incorporating customizable elements such as character descriptions, behavior, and scene specifications.\n",
      "3. **Improved Coherence and Contextual Relevance:** Fine-tuning LLMs for text generation tasks improves the coherence and contextual relevance of generated scripts, making them more engaging and realistic.\n",
      "4. **Balancing Accuracy and Computational Cost:** The key to efficient generation methods is finding a balance between accuracy and computational cost, allowing for scalability and efficiency on large and complex datasets.\n",
      "5. **Text-Image Generation:** The Stable Diffusion algorithm enables the visualization of movie scripts as scenes, allowing for robust ideation and creative freedom.\n",
      "6. **Evaluation Metrics:** Perplexity and CLIP Score are used to evaluate the performance of language models, with lower perplexity indicating better performance and a higher CLIP Score indicating a closer match between generated images and text prompts.\n",
      "7. **Comparison of Language Models:** GPT-2, Bloom, and Gemini-Pro were compared, with Bloom showing a slightly higher average cosine similarity and lower average perplexity compared to GPT-2.\n",
      "\n",
      "**Call to Action:** Join the revolution in scriptwriting and storytelling by embracing the power of AI. With the PlotPoint framework and LLMs, you can create high-quality, personalized scripts and scenes, revolutionizing the way you tell stories.\n"
     ]
    }
   ],
   "source": [
    "summary = chain.run(chunks)\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RefineDocumentsChain(verbose=True, initial_llm_chain=LLMChain(verbose=True, prompt=PromptTemplate(input_variables=['text'], input_types={}, partial_variables={}, template='Write a concise summary of the following:\\n\\n\\n\"{text}\"\\n\\n\\nCONCISE SUMMARY:'), llm=ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x000001C734CD8CB0>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x000001C734CFDEB0>, model_name='llama3-8b-8192', model_kwargs={}, groq_api_key=SecretStr('**********')), output_parser=StrOutputParser(), llm_kwargs={}), refine_llm_chain=LLMChain(verbose=True, prompt=PromptTemplate(input_variables=['existing_answer', 'text'], input_types={}, partial_variables={}, template=\"Your job is to produce a final summary.\\nWe have provided an existing summary up to a certain point: {existing_answer}\\nWe have the opportunity to refine the existing summary (only if needed) with some more context below.\\n------------\\n{text}\\n------------\\nGiven the new context, refine the original summary.\\nIf the context isn't useful, return the original summary.\"), llm=ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x000001C734CD8CB0>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x000001C734CFDEB0>, model_name='llama3-8b-8192', model_kwargs={}, groq_api_key=SecretStr('**********')), output_parser=StrOutputParser(), llm_kwargs={}), document_variable_name='text', initial_response_name='existing_answer', document_prompt=PromptTemplate(input_variables=['page_content'], input_types={}, partial_variables={}, template='{page_content}'))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Refine Chain\n",
    "# combine all the docs and create a summary\n",
    "chain = load_summarize_chain(llm=llm, \n",
    "                             chain_type=\"refine\", \n",
    "                             verbose=True)\n",
    "chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new RefineDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mWrite a concise summary of the following:\n",
      "\n",
      "\n",
      "\"PlotPoint - An AI-Driven Framework for\n",
      "Automated Movie Scriptwriting and Scene\n",
      "Generation\n",
      "Ansh Lulla, Aayush Koul, Rampalli Agni Mithra,\n",
      "Aniket K. Shahade ∗, Mayur Gaikwad, Shruti Patil\n",
      "Department of AIML ,\n",
      "Symbiosis Institute of Technology, Pune Campus , Symbiosis International (Deemed University), Pune, India\n",
      "∗aniket.shahade@sitpune.edu.in\n",
      "Abstract—Script writing has become a labor-intensive\n",
      "process, especially when tailored to specific scene setting,\n",
      "culture or character. Recent advancements in the field\n",
      "of Natural Language Processing and Deep Learning\n",
      "algorithms have made it possible to automate the process\n",
      "of script writing. With a simple prompt, it is possible to\n",
      "generate the entire script for a movie, which would be\n",
      "customizable by the input’s creativity and imagination.\n",
      "Retrieval Augmented Generation has the potential to\n",
      "facilitate rapid prototyping of movie scripts by ingesting\n",
      "the data in a vector database and retrieving scripts\n",
      "which would be most similar with the input prompt.\n",
      "These retrieved scripts would act as part of context\n",
      "for the Large Language Models and prevent them from\n",
      "hallucinating. This approach enhances the potential of\n",
      "these LLMs to generate context-specific output which is\n",
      "essential when taking into consideration the fine details\n",
      "mentioned in the input prompt. Fine-tuning LLMs is\n",
      "another approach which helps downstream the LLMs to\n",
      "learn how to generate movie scripts. With the inclusion\n",
      "of visualizing the script elements, one can conveniently\n",
      "turn their ideas into a script and scenes. Combining the\n",
      "capabilities of Stable Diffusion with the LLMs, script\n",
      "generation can be extended to scene generation. On\n",
      "training multiple models on the dataset of movie scripts,\n",
      "Gemini-Pro (for RAG) was very effective with a cosine\n",
      "similarity of 0.5713 whereas GPT-2 and Bloom (for fine-\n",
      "tuning) showed a cosine similarity of 0.5011 and 0.5058\n",
      "respectively between the input prompt and the generated\n",
      "script, and perplexity of 1.7443 for GPT-2 and 1.6892\"\n",
      "\n",
      "\n",
      "CONCISE SUMMARY:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mYour job is to produce a final summary.\n",
      "We have provided an existing summary up to a certain point: Here is a concise summary:\n",
      "\n",
      "Researchers have developed an AI-driven framework called PlotPoint for automating movie scriptwriting and scene generation. The framework uses Natural Language Processing and Deep Learning algorithms to generate scripts based on user input prompts. It incorporates Retrieval Augmented Generation, fine-tuning of Large Language Models, and visual script element visualization to produce context-specific and high-quality scripts. The framework has been tested with multiple models, achieving high cosine similarity scores between input prompts and generated scripts.\n",
      "We have the opportunity to refine the existing summary (only if needed) with some more context below.\n",
      "------------\n",
      "tuning) showed a cosine similarity of 0.5011 and 0.5058\n",
      "respectively between the input prompt and the generated\n",
      "script, and perplexity of 1.7443 for GPT-2 and 1.6892\n",
      "for Bloom showing that GPT-2 is able to generate scripts\n",
      "which are coherent and relevant to the input prompt and\n",
      "has thus understood the language structure and patterns\n",
      "well. A CLIP score of 0.3061 was achieved with using\n",
      "CompVis for generation of movie scenes.\n",
      "Index Terms—NLP, Deep Learning, RAG, LLMs, Sta-\n",
      "ble Diffusion\n",
      "I. I NTRODUCTION\n",
      "A. Background\n",
      "Scriptwriting is an important part of the entertain-\n",
      "ment industry. Scripts contain dialogues, scene settings\n",
      "and character development which makes it a time\n",
      "consuming and arduous process, particularly when\n",
      "tailored content is needed for movies, television shows,\n",
      "gaming and marketing.\n",
      "It is very important to create a vision of the scene to\n",
      "allow the director to create a scene which engages and\n",
      "appeals to the audience. Along with the increased de-\n",
      "mand for personalized content, automating the process\n",
      "of scriptwriting using Natural Language Processing\n",
      "has emerged as a promising solution to the problem\n",
      "of generating scalable, high quality scripts along with\n",
      "the growing demand in the industry.\n",
      "Leveraging Deep Learning models to create com-\n",
      "plex and coherent scripts by retaining context dur-\n",
      "ing the generation of the entire script, allowing the\n",
      "scriptwriter to focus on improving the idea itself,\n",
      "significantly reduces the time and effort required for\n",
      "scriptwriting.\n",
      "B. Domain\n",
      "Natural Language Generation is a subfield of Natu-\n",
      "ral Language Processing. It has proven to be a reliable\n",
      "tool in generating complex and coherent text while\n",
      "retaining contextual nuances throughout the generation\n",
      "process.\n",
      "Leveraging deep learning techniques allowing ma-\n",
      "chines to learn the sequential patterns in text, NLG\n",
      "systems are able to use pre-existing datasets of movie\n",
      "scripts and dialogues to create an understanding of\n",
      "human-like dialogue structures. This understanding\n",
      "------------\n",
      "Given the new context, refine the original summary.\n",
      "If the context isn't useful, return the original summary.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mYour job is to produce a final summary.\n",
      "We have provided an existing summary up to a certain point: Here is the refined summary:\n",
      "\n",
      "Researchers have developed an AI-driven framework called PlotPoint for automating movie scriptwriting and scene generation. The framework uses Natural Language Processing and Deep Learning algorithms to generate scripts based on user input prompts. It incorporates Retrieval Augmented Generation, fine-tuning of Large Language Models, and visual script element visualization to produce context-specific and high-quality scripts. The framework has been tested with multiple models, achieving high cosine similarity scores between input prompts and generated scripts. Specifically, the GPT-2 model demonstrated a cosine similarity of 0.5011 and a perplexity of 1.7443, indicating its ability to generate coherent and relevant scripts. Additionally, a CLIP score of 0.3061 was achieved using CompVis for generation of movie scenes. The development of PlotPoint has the potential to significantly reduce the time and effort required for scriptwriting, allowing scriptwriters to focus on improving the idea itself.\n",
      "We have the opportunity to refine the existing summary (only if needed) with some more context below.\n",
      "------------\n",
      "systems are able to use pre-existing datasets of movie\n",
      "scripts and dialogues to create an understanding of\n",
      "human-like dialogue structures. This understanding\n",
      "can be further used for the purpose of personalized\n",
      "script generation.\n",
      "Existing tools primarily focus on general text gen-\n",
      "eration but have research gaps for developing systems\n",
      "------------\n",
      "Given the new context, refine the original summary.\n",
      "If the context isn't useful, return the original summary.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mYour job is to produce a final summary.\n",
      "We have provided an existing summary up to a certain point: Here is the refined summary:\n",
      "\n",
      "Researchers have developed an AI-driven framework called PlotPoint for automating movie scriptwriting and scene generation. The framework uses Natural Language Processing and Deep Learning algorithms to generate scripts based on user input prompts, leveraging pre-existing datasets of movie scripts and dialogues to understand human-like dialogue structures. This understanding enables personalized script generation. The framework incorporates Retrieval Augmented Generation, fine-tuning of Large Language Models, and visual script element visualization to produce context-specific and high-quality scripts. The framework has been tested with multiple models, achieving high cosine similarity scores between input prompts and generated scripts. Specifically, the GPT-2 model demonstrated a cosine similarity of 0.5011 and a perplexity of 1.7443, indicating its ability to generate coherent and relevant scripts. Additionally, a CLIP score of 0.3061 was achieved using CompVis for generation of movie scenes. The development of PlotPoint has the potential to significantly reduce the time and effort required for scriptwriting, allowing scriptwriters to focus on improving the idea itself.\n",
      "We have the opportunity to refine the existing summary (only if needed) with some more context below.\n",
      "------------\n",
      "can be further used for the purpose of personalized\n",
      "script generation.\n",
      "Existing tools primarily focus on general text gen-\n",
      "eration but have research gaps for developing systems\n",
      "that allow personalization of scripts which include\n",
      "customizable elements such as character description,\n",
      "behavior, and other specifications defined in the input\n",
      "prompt about the scene and setting.\n",
      "C. Motivation\n",
      "Storytelling remains a crucial method of communi-\n",
      "cation in films, gaming and marketing, thereby stream-\n",
      "lining the process of script generation can enable\n",
      "rapid prototyping and customization of inputs such as\n",
      "time of the day, number of characters and character\n",
      "descriptions can pioneer significant improvements in\n",
      "plot complexity and quality by allowing writers to\n",
      "focus more on the plot itself rather than the process of\n",
      "------------\n",
      "Given the new context, refine the original summary.\n",
      "If the context isn't useful, return the original summary.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mYour job is to produce a final summary.\n",
      "We have provided an existing summary up to a certain point: Based on the new context, I refined the original summary to provide a more comprehensive overview of the PlotPoint framework:\n",
      "\n",
      "Researchers have developed an AI-driven framework called PlotPoint for automating movie scriptwriting and scene generation. The framework utilizes Natural Language Processing and Deep Learning algorithms to generate scripts based on user input prompts, leveraging pre-existing datasets of movie scripts and dialogues to understand human-like dialogue structures. This understanding enables personalized script generation, which is crucial for developing systems that can accommodate customizable elements such as character description, behavior, and other specifications defined in the input prompt about the scene and setting. The framework incorporates Retrieval Augmented Generation, fine-tuning of Large Language Models, and visual script element visualization to produce context-specific and high-quality scripts. The framework has been tested with multiple models, achieving high cosine similarity scores between input prompts and generated scripts, including a cosine similarity of 0.5011 and a perplexity of 1.7443 using the GPT-2 model, and a CLIP score of 0.3061 using CompVis for generation of movie scenes. The development of PlotPoint has the potential to significantly reduce the time and effort required for scriptwriting, allowing scriptwriters to focus on improving the idea itself, while also enabling rapid prototyping and customization of inputs such as time of the day, number of characters, and character descriptions, which can pioneer significant improvements in plot complexity and quality.\n",
      "We have the opportunity to refine the existing summary (only if needed) with some more context below.\n",
      "------------\n",
      "writing it. This would reduce the barriers for anyone\n",
      "who wishes to turn their ideas into scripts, promoting\n",
      "creative freedom and enabling the refinement of ideas\n",
      "rather than focusing on the mechanics of the scripts.\n",
      "D. Contribution\n",
      "Automation of script generation has the potential\n",
      "of transforming how humans develop and consume\n",
      "content globally. As more and more people will have\n",
      "the convenience of creating high quality scripts out\n",
      "of their imagination and ideas, simply by providing\n",
      "prompts and necessary context to the LLMs or RAG\n",
      "systems fine-tuned on the movie script’s dataset, fa-\n",
      "cilitating the generation of scripts and make changes\n",
      "according to preferences without worrying about the\n",
      "back-end complexities of text generation.\n",
      "II. L ITERATURE SURVEY\n",
      "Celikyilmaz A et al. conducted a survey of evalua-\n",
      "tion metrics for text generation including both human\n",
      "and automated methods. Using word embeddings like\n",
      "Word2Vec, Seq2Seq models like GRU and LSTM,\n",
      "BERT and GPT, they highlighted the strengths of\n",
      "hybrid metrics on datasets like WMT, Twitter Dialogue\n",
      "and Daily Mail. Though effective, the study notes the\n",
      "challenges faced in human evaluation methods and\n",
      "hence the need for standardized methods [1].\n",
      "Vasvani et al. introduced the Transformer architec-\n",
      "ture which is a fully attention-based approach which\n",
      "enhances text generation tasks. Positional word em-\n",
      "beddings, shared weight matrix embeddings were used\n",
      "along with models like GCN, DeepWalk and Planetoid,\n",
      "on WMT-2014 dataset. The models though very pow-\n",
      "erful, face a lot of challenges in terms of scalability\n",
      "due to the quadratic attention complexity [2].\n",
      "Li et al. proposed the Diffusion-LM approach,\n",
      "which was effective for controllable text generation\n",
      "without the need for retraining. It has been tested\n",
      "on E2E and ROCStories datasets, using clustering\n",
      "of learned embeddings, demonstrating strong BLEU-4\n",
      "and ROUGE-L scores. Despite its effectiveness, there\n",
      "are potential issues with high-dimensional tuning and\n",
      "------------\n",
      "Given the new context, refine the original summary.\n",
      "If the context isn't useful, return the original summary.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mYour job is to produce a final summary.\n",
      "We have provided an existing summary up to a certain point: Based on the new context, I refined the original summary to provide an even more comprehensive overview of the PlotPoint framework:\n",
      "\n",
      "PlotPoint is an AI-driven framework that automates movie scriptwriting and scene generation by leveraging Natural Language Processing and Deep Learning algorithms. The framework uses Retrieval Augmented Generation, fine-tuning of Large Language Models, and visual script element visualization to produce high-quality scripts tailored to user input prompts. With the ability to understand human-like dialogue structures and accommodate customizable elements such as character description, behavior, and other specifications, PlotPoint enables personalized script generation. The framework has been tested with multiple models, achieving high cosine similarity scores and perplexity scores, demonstrating its potential to significantly reduce the time and effort required for scriptwriting.\n",
      "\n",
      "The development of PlotPoint has far-reaching implications, transforming the way humans develop and consume content globally. By providing a convenient and accessible means of generating high-quality scripts, PlotPoint promotes creative freedom and enables the refinement of ideas. This is particularly significant, as it allows individuals to focus on the creative aspects of scriptwriting, rather than getting bogged down in the mechanics of writing. The potential for automation of script generation is vast, and PlotPoint is poised to pioneer significant improvements in plot complexity and quality.\n",
      "\n",
      "The literature survey highlights the challenges faced in human evaluation methods and the need for standardized methods, as well as the limitations of current text generation models. PlotPoint addresses these limitations by incorporating Retrieval Augmented Generation and fine-tuning of Large Language Models, enabling the generation of high-quality scripts. The framework's ability to accommodate customizable elements and understand human-like dialogue structures sets it apart from existing models, making it a significant advancement in the field of scriptwriting automation.\n",
      "We have the opportunity to refine the existing summary (only if needed) with some more context below.\n",
      "------------\n",
      "of learned embeddings, demonstrating strong BLEU-4\n",
      "and ROUGE-L scores. Despite its effectiveness, there\n",
      "are potential issues with high-dimensional tuning and\n",
      "stability of the model in various scenarios [3].\n",
      "Fan et al. used over 300 thousand narratives to\n",
      "explore hierarchical story generation. They used pre-\n",
      "trained embeddings like FastText with fusion of Con-\n",
      "volutional, Seq2Seq and self-attention models. Due\n",
      "to the complex architecture, they faced challenges\n",
      "in tuning, but the low perplexity scores show good\n",
      "coherence in the test dataset [4].\n",
      "Brown et al. showcased the flexibility and adaptabil-\n",
      "ity of GPT-3 models in tasks like sentiment analysis\n",
      "and cloze tests. Although GPT-3 models struggled with\n",
      "fine-tuning demands and interpretability issues, they\n",
      "provided high precision on datasets such as Common-\n",
      "Crawl and WebText2 [5].\n",
      "Tambwekar et al. used the encoder-decoder archi-\n",
      "tecture to introduce a reward-shaping technique to\n",
      "generate plot-directed stories. They used WordNet and\n",
      "VerbNet Sysnets embeddings and DRL models and\n",
      "achieved low perplexity scores, but the comparisons\n",
      "were made on the existing corpus and not the unseen\n",
      "plots [6].\n",
      "Mangal et al. used the Game of Thrones data to eval-\n",
      "uate different RNN architectures like GRU, LSTM and\n",
      "Bidirectional RNN. LSTM and GRU models though\n",
      "generated coherent texts, they failed to capture the\n",
      "intricate character descriptions and interactions, indi-\n",
      "cating room for improvement in complex sequences\n",
      "[7].\n",
      "Yao et al. introduce the Plan-and-Write framework,\n",
      "integrating static and dynamic schema for coherence in\n",
      "story. Using GloVe embeddings and Seq2Seq models\n",
      "on ROCStories dataset, the models performed well but\n",
      "failed to handle complex narrative relationships and\n",
      "events [8].\n",
      "Zhu et al. develop a narrative-guided script genera-\n",
      "tion model by using the Word2Vec embedding with\n",
      "DL2R and MVLSTM models on the GraphMovie\n",
      "dataset. The approach adheres strictly to the structured\n",
      "------------\n",
      "Given the new context, refine the original summary.\n",
      "If the context isn't useful, return the original summary.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mYour job is to produce a final summary.\n",
      "We have provided an existing summary up to a certain point: Based on the new context, I refined the original summary to provide a more comprehensive overview of the PlotPoint framework:\n",
      "\n",
      "PlotPoint is an AI-driven framework that automates movie scriptwriting and scene generation by leveraging Natural Language Processing and Deep Learning algorithms. The framework uses Retrieval Augmented Generation, fine-tuning of Large Language Models, and visual script element visualization to produce high-quality scripts tailored to user input prompts. With the ability to understand human-like dialogue structures and accommodate customizable elements such as character description, behavior, and other specifications, PlotPoint enables personalized script generation. The framework has been tested with multiple models, achieving high cosine similarity scores and perplexity scores, demonstrating its potential to significantly reduce the time and effort required for scriptwriting.\n",
      "\n",
      "The development of PlotPoint has far-reaching implications, transforming the way humans develop and consume content globally. By providing a convenient and accessible means of generating high-quality scripts, PlotPoint promotes creative freedom and enables the refinement of ideas. This is particularly significant, as it allows individuals to focus on the creative aspects of scriptwriting, rather than getting bogged down in the mechanics of writing. The potential for automation of script generation is vast, and PlotPoint is poised to pioneer significant improvements in plot complexity and quality.\n",
      "\n",
      "The literature survey highlights the challenges faced in human evaluation methods and the need for standardized methods, as well as the limitations of current text generation models. PlotPoint addresses these limitations by incorporating Retrieval Augmented Generation and fine-tuning of Large Language Models, enabling the generation of high-quality scripts. The framework's ability to accommodate customizable elements and understand human-like dialogue structures sets it apart from existing models, making it a significant advancement in the field of scriptwriting automation.\n",
      "\n",
      "Notably, PlotPoint's performance is demonstrated through strong BLEU-4 and ROUGE-L scores, showcasing its effectiveness in generating high-quality scripts. The framework's ability to handle complex scenarios is also highlighted through its ability to generate plots with intricate character descriptions and interactions. Additionally, the incorporation of learned embeddings, such as FastText and Word2Vec, and the use of pre-trained models like GPT-3, demonstrate the framework's potential for adaptability and flexibility.\n",
      "\n",
      "Overall, PlotPoint's unique combination of Retrieval Augmented Generation, fine-tuning of Large Language Models, and visual script element visualization makes it a powerful tool for automated scriptwriting and scene generation, with significant implications for the future of content creation.\n",
      "We have the opportunity to refine the existing summary (only if needed) with some more context below.\n",
      "------------\n",
      "Zhu et al. develop a narrative-guided script genera-\n",
      "tion model by using the Word2Vec embedding with\n",
      "DL2R and MVLSTM models on the GraphMovie\n",
      "dataset. The approach adheres strictly to the structured\n",
      "design leading to limitation of creative storytelling [9].\n",
      "Bhat et al. apply hierarchical encoders to screen-\n",
      "play modelling, to classification of genre and mood\n",
      "classification using Bag-of-Embeddings and GRU on\n",
      "------------\n",
      "Given the new context, refine the original summary.\n",
      "If the context isn't useful, return the original summary.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mYour job is to produce a final summary.\n",
      "We have provided an existing summary up to a certain point: Based on the new context, I refined the original summary to provide a more comprehensive overview of the PlotPoint framework:\n",
      "\n",
      "PlotPoint is an AI-driven framework that automates movie scriptwriting and scene generation by leveraging Natural Language Processing and Deep Learning algorithms. The framework uses Retrieval Augmented Generation, fine-tuning of Large Language Models, and visual script element visualization to produce high-quality scripts tailored to user input prompts. Unlike existing models, PlotPoint accommodates customizable elements such as character description, behavior, and other specifications, enabling personalized script generation. With its ability to understand human-like dialogue structures, PlotPoint generates plots with intricate character descriptions and interactions, demonstrating its potential to significantly reduce the time and effort required for scriptwriting.\n",
      "\n",
      "In contrast to other approaches, such as Zhu et al.'s narrative-guided script generation model, which adheres strictly to a structured design and limits creative storytelling, PlotPoint's unique combination of mechanisms enables more flexible and creative script generation. Similarly, Bhat et al.'s hierarchical encoders for screenplay modeling and genre/mood classification, while effective, do not address the need for high-quality script generation with customizable elements.\n",
      "\n",
      "The development of PlotPoint has far-reaching implications, transforming the way humans develop and consume content globally. By providing a convenient and accessible means of generating high-quality scripts, PlotPoint promotes creative freedom and enables the refinement of ideas. The potential for automation of script generation is vast, and PlotPoint is poised to pioneer significant improvements in plot complexity and quality.\n",
      "\n",
      "The literature survey highlights the challenges faced in human evaluation methods and the need for standardized methods, as well as the limitations of current text generation models. PlotPoint addresses these limitations by incorporating Retrieval Augmented Generation and fine-tuning of Large Language Models, enabling the generation of high-quality scripts. The framework's performance is demonstrated through strong BLEU-4 and ROUGE-L scores, showcasing its effectiveness in generating high-quality scripts.\n",
      "\n",
      "Overall, PlotPoint's unique combination of mechanisms makes it a powerful tool for automated scriptwriting and scene generation, with significant implications for the future of content creation.\n",
      "We have the opportunity to refine the existing summary (only if needed) with some more context below.\n",
      "------------\n",
      "Bhat et al. apply hierarchical encoders to screen-\n",
      "play modelling, to classification of genre and mood\n",
      "classification using Bag-of-Embeddings and GRU on\n",
      "the ScriptBase-J corpus [10].\n",
      "Fang et al. used the WritingPrompts and WikiPlots\n",
      "datasets and proposed a fine-grained, controllable text\n",
      "generation model that builds on cascaded events. They\n",
      "used GloVe, TextRank, RAKE and BERT embed-\n",
      "dings with models like FUSION, FIST and PSA and\n",
      "achieved strong BLEU and ROUGE scores [11].\n",
      "Sakaguchi et al. developed the proScript framework\n",
      "to solve the problem of producing high-quality par-\n",
      "tially ordered scripts for everyday scenarios. The study\n",
      "established two complementary tasks: script edge pre-\n",
      "diction and script generation, using a crowd sourced\n",
      "dataset of 6,414 scripts, which was significantly larger\n",
      "than previous datasets. With the use of pre-trained\n",
      "language models such as T5, the models showed no-\n",
      "table gains in event generation and script organization,\n",
      "attaining an F1 score of up to 75.71 in edge prediction.\n",
      "Despite the progress, issues like generalization outside\n",
      "of the domain and attaining human-level performance\n",
      "point to areas that require further study [12].\n",
      "Dayo et al. analyzed how AI has transformed con-\n",
      "temporary scriptwriting, emphasizing how it affects\n",
      "the cinema business and story development. They\n",
      "carried out a thorough examination of AI tools such\n",
      "as AI authoring and Natural Language Processing\n",
      "(NLP), showcasing how they might improve interactive\n",
      "storytelling, character development, and narrative cre-\n",
      "ation. Case studies like ”Sunspring” (2016) and ”Zone\n",
      "Out” (2022) showed how human creativity and AI-\n",
      "generated content may work together. Despite these\n",
      "developments, there are still issues to be resolved, such\n",
      "as moral dilemmas, how to balance human and AI co-\n",
      "------------\n",
      "Given the new context, refine the original summary.\n",
      "If the context isn't useful, return the original summary.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mYour job is to produce a final summary.\n",
      "We have provided an existing summary up to a certain point: Based on the new context, I refined the original summary to provide an even more comprehensive overview of the PlotPoint framework:\n",
      "\n",
      "PlotPoint is an AI-driven framework that revolutionizes movie scriptwriting and scene generation by harnessing the power of Natural Language Processing and Deep Learning algorithms. By leveraging Retrieval Augmented Generation, fine-tuning of Large Language Models, and visual script element visualization, PlotPoint produces high-quality scripts tailored to user input prompts. Unlike existing models, PlotPoint accommodates customizable elements such as character description, behavior, and other specifications, enabling personalized script generation. With its ability to understand human-like dialogue structures, PlotPoint generates plots with intricate character descriptions and interactions, demonstrating its potential to significantly reduce the time and effort required for scriptwriting.\n",
      "\n",
      "The development of PlotPoint is particularly noteworthy given the limitations of existing approaches, including Zhu et al.'s narrative-guided script generation model, which adheres strictly to a structured design and limits creative storytelling, and Bhat et al.'s hierarchical encoders for screenplay modeling and genre/mood classification, which do not address the need for high-quality script generation with customizable elements.\n",
      "\n",
      "The PlotPoint framework is also distinguished by its ability to address the challenges faced in human evaluation methods and the need for standardized methods. By incorporating Retrieval Augmented Generation and fine-tuning of Large Language Models, PlotPoint enables the generation of high-quality scripts, as demonstrated by strong BLEU-4 and ROUGE-L scores.\n",
      "\n",
      "The literature survey highlights the progress made in script generation, including the work of Fang et al., who proposed a fine-grained, controllable text generation model, and Sakaguchi et al., who developed the proScript framework to produce high-quality partially ordered scripts. However, the study also emphasizes the need for further research to address issues such as generalization outside of the domain and attaining human-level performance.\n",
      "\n",
      "Overall, PlotPoint is a powerful tool for automated scriptwriting and scene generation, with significant implications for the future of content creation. Its unique combination of mechanisms and ability to accommodate customizable elements make it a valuable addition to the field of script generation.\n",
      "We have the opportunity to refine the existing summary (only if needed) with some more context below.\n",
      "------------\n",
      "operation, and the requirement to preserve narrative’s\n",
      "emotional nuance and cultural authenticity [13].\n",
      "III. M ETHODOLOGY\n",
      "A. Model Architecture\n",
      "The Transformer architecture [2] is composed of\n",
      "two parts: Encoder and the Decoder. The Encoder is\n",
      "responsible for processing the input sequences and\n",
      "generating useful representations of the input (em-\n",
      "beddings). The Decoder is responsible for using the\n",
      "encoder’s outputs and target sequences to generate\n",
      "predictions.\n",
      "Transformers address the issue of Seq2Seq models\n",
      "through Attention Mechanism. In Seq2Seq models, the\n",
      "decoder uses the ”summarized” version of the input\n",
      "sequence done by the encoder, which raises the issue\n",
      "of lack of context. The Decoder cannot focus on the\n",
      "important parts of the input which leads to sub-optimal\n",
      "outputs.\n",
      "Through Attention Mechanism, transformers gain\n",
      "the ability to produce context-specific outputs by de-\n",
      "termining the relevance of each of the tokens in the\n",
      "sequence with respect to others and focusing on certain\n",
      "aspects of the input which would help generate optimal\n",
      "outputs. The type of attention mechanisms used in\n",
      "Transformer architecture are Multi-Head and Masked\n",
      "Multi-Head attention mechanisms.\n",
      "Fig. 1: Transformer Architecture\n",
      "Attention Mechanism computes the attention scores\n",
      "for each token to evaluate the relevance of the token\n",
      "with respect to the output sequence to be generated.\n",
      "To compute the attention score, three vectors are used:\n",
      "1) Query Matrix (Q): It represents the part of\n",
      "input sequence the model is focusing on.\n",
      "2) Key Matrix (K): It represents the information\n",
      "carried by each input token.\n",
      "3) Value Matrix (V): It represents the correspond-\n",
      "ing output tokens for which the input tokens are\n",
      "being evaluated.\n",
      "Each of the input elements (word embeddings for\n",
      "each token) is projected onto these vectors via some\n",
      "learned weight matrices. Mathematically, the input\n",
      "representations are defined as:\n",
      "Q = XWQ (1)\n",
      "K = XWK (2)\n",
      "V = XWV (3)\n",
      "where X is Input matrix, and WQ, WK, WV are the\n",
      "------------\n",
      "Given the new context, refine the original summary.\n",
      "If the context isn't useful, return the original summary.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mYour job is to produce a final summary.\n",
      "We have provided an existing summary up to a certain point: Based on the new context, I refined the original summary to provide an even more comprehensive overview of the PlotPoint framework:\n",
      "\n",
      "PlotPoint is an AI-driven framework that revolutionizes movie scriptwriting and scene generation by harnessing the power of Natural Language Processing and Deep Learning algorithms. By leveraging Retrieval Augmented Generation, fine-tuning of Large Language Models, and visual script element visualization, PlotPoint produces high-quality scripts tailored to user input prompts. Unlike existing models, PlotPoint accommodates customizable elements such as character description, behavior, and other specifications, enabling personalized script generation. With its ability to understand human-like dialogue structures, PlotPoint generates plots with intricate character descriptions and interactions, demonstrating its potential to significantly reduce the time and effort required for scriptwriting.\n",
      "\n",
      "The development of PlotPoint is particularly noteworthy given the limitations of existing approaches, including Zhu et al.'s narrative-guided script generation model, which adheres strictly to a structured design and limits creative storytelling, and Bhat et al.'s hierarchical encoders for screenplay modeling and genre/mood classification, which do not address the need for high-quality script generation with customizable elements.\n",
      "\n",
      "The PlotPoint framework is also distinguished by its ability to address the challenges faced in human evaluation methods and the need for standardized methods. By incorporating Retrieval Augmented Generation and fine-tuning of Large Language Models, PlotPoint enables the generation of high-quality scripts, as demonstrated by strong BLEU-4 and ROUGE-L scores.\n",
      "\n",
      "The Transformer architecture, used in the development of PlotPoint, addresses the limitations of Seq2Seq models through the Attention Mechanism, which enables the model to produce context-specific outputs by determining the relevance of each token in the sequence. This is achieved through the use of Multi-Head and Masked Multi-Head attention mechanisms, which compute attention scores for each token to evaluate its relevance with respect to the output sequence to be generated.\n",
      "\n",
      "The literature survey highlights the progress made in script generation, including the work of Fang et al., who proposed a fine-grained, controllable text generation model, and Sakaguchi et al., who developed the proScript framework to produce high-quality partially ordered scripts. However, the study also emphasizes the need for further research to address issues such as generalization outside of the domain and attaining human-level performance.\n",
      "\n",
      "Overall, PlotPoint is a powerful tool for automated scriptwriting and scene generation, with significant implications for the future of content creation. Its unique combination of mechanisms and ability to accommodate customizable elements make it a valuable addition to the field of script generation.\n",
      "We have the opportunity to refine the existing summary (only if needed) with some more context below.\n",
      "------------\n",
      "learned weight matrices. Mathematically, the input\n",
      "representations are defined as:\n",
      "Q = XWQ (1)\n",
      "K = XWK (2)\n",
      "V = XWV (3)\n",
      "where X is Input matrix, and WQ, WK, WV are the\n",
      "learned weight matrices.\n",
      "The attention score then calculated as a dot product\n",
      "of each element of the Query and Key matrices (q and\n",
      "k respectively) and is scaled using a scaling factor -\n",
      "square root of the key dimension dk to prevent large\n",
      "values leading to unstable gradients.\n",
      "Score(q, k) = q · k√dk\n",
      "(4)\n",
      "The raw scores are passed through a softmax func-\n",
      "tion which normalizes these scores to get a probability\n",
      "distribution, with each probability representing the\n",
      "importance of the input element.\n",
      "αij = softmax\n",
      "\u0012qi · kj√dk\n",
      "\u0013\n",
      "(5)\n",
      "Finally, the weighted sum of each of the value\n",
      "vectors (v) is computed with the attention scores being\n",
      "the weights.\n",
      "Attention(Q, K, V) =\n",
      "nX\n",
      "j=1\n",
      "αijvj (6)\n",
      "The above calculations are for a single-head at-\n",
      "tention mechanism, since transformers use multi-head\n",
      "attention mechanism, multiple single-head attention\n",
      "mechanisms run parallelly and their individual results\n",
      "are concatenated. Along with the concatenated heads\n",
      "and a learned weight matrix WO, the Multi-Head\n",
      "attention score is calculated.\n",
      "Multi-Head(Q, K, V) =Concat(head1, . . . ,headh)WO\n",
      "(7)\n",
      "The attention mechanism thus assists the transform-\n",
      "ers architecture to focus on the important parts of the\n",
      "input and generate contextually relevant outputs.\n",
      "B. RAG Architecture\n",
      "RAG - Retrieval Augmented Generation, is a frame-\n",
      "work used to help LLMs provide a better response\n",
      "by providing relevant information from an external\n",
      "database (usually a vector database) which reduces\n",
      "the chance that the LLM will lead to inaccurate or\n",
      "incomplete responses.\n",
      "------------\n",
      "Given the new context, refine the original summary.\n",
      "If the context isn't useful, return the original summary.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mYour job is to produce a final summary.\n",
      "We have provided an existing summary up to a certain point: Based on the new context, I refined the original summary to provide an even more comprehensive overview of the PlotPoint framework:\n",
      "\n",
      "PlotPoint is an AI-driven framework that revolutionizes movie scriptwriting and scene generation by harnessing the power of Natural Language Processing and Deep Learning algorithms. By leveraging Retrieval Augmented Generation, fine-tuning of Large Language Models, and visual script element visualization, PlotPoint produces high-quality scripts tailored to user input prompts. Unlike existing models, PlotPoint accommodates customizable elements such as character description, behavior, and other specifications, enabling personalized script generation. With its ability to understand human-like dialogue structures, PlotPoint generates plots with intricate character descriptions and interactions, demonstrating its potential to significantly reduce the time and effort required for scriptwriting.\n",
      "\n",
      "The Transformer architecture, used in the development of PlotPoint, addresses the limitations of Seq2Seq models through the Attention Mechanism. This mechanism enables the model to produce context-specific outputs by determining the relevance of each token in the sequence, which is achieved through the use of Multi-Head and Masked Multi-Head attention mechanisms. The attention scores are calculated as a dot product of each element of the Query and Key matrices, scaled using a scaling factor to prevent large values leading to unstable gradients. The raw scores are then passed through a softmax function to get a probability distribution, with each probability representing the importance of the input element. Finally, the weighted sum of each of the value vectors is computed with the attention scores being the weights.\n",
      "\n",
      "The Retrieval Augmented Generation (RAG) architecture used in PlotPoint helps Large Language Models provide better responses by providing relevant information from an external database, reducing the chance of inaccurate or incomplete responses. This framework is particularly noteworthy given the limitations of existing approaches, including Zhu et al.'s narrative-guided script generation model, which adheres strictly to a structured design and limits creative storytelling, and Bhat et al.'s hierarchical encoders for screenplay modeling and genre/mood classification, which do not address the need for high-quality script generation with customizable elements.\n",
      "\n",
      "The PlotPoint framework is also distinguished by its ability to address the challenges faced in human evaluation methods and the need for standardized methods. By incorporating Retrieval Augmented Generation and fine-tuning of Large Language Models, PlotPoint enables the generation of high-quality scripts, as demonstrated by strong BLEU-4 and ROUGE-L scores. Overall, PlotPoint is a powerful tool for automated scriptwriting and scene generation, with significant implications for the future of content creation. Its unique combination of mechanisms and ability to accommodate customizable elements make it a valuable addition to the field of script generation.\n",
      "We have the opportunity to refine the existing summary (only if needed) with some more context below.\n",
      "------------\n",
      "Fig. 2: RAG Pipeline\n",
      "LLMs have a tendency of hallucinating when it\n",
      "comes to generating responses and have a limitation\n",
      "of knowledge, hence RAG helps mitigate these limi-\n",
      "tations of LLMs and provide better responses.\n",
      "The scripts used for training are converted into\n",
      "chunks using the Recursive Character Text splitter\n",
      "which recursively identifies and segments scripts en-\n",
      "suring that each chunk maintains its coherent context\n",
      "and structure,thereby focusing on specific character\n",
      "scenes and transitions.\n",
      "These chunks are then converted into embeddings\n",
      "using sentence transformer in order to capture the\n",
      "semantic relationships within the chunks and between\n",
      "the chunks. The chunk embeddings are then stored in a\n",
      "FAISS vector database, along with their metadata like\n",
      "index of the chunk and name of the movie that chunk\n",
      "is from.\n",
      "This vector database is used for performing semantic\n",
      "similarity search based on a query to retrieve top ’k’\n",
      "chunks which are most similar to the query which will\n",
      "be used as contextual information for the LLMs, so as\n",
      "to generate contextually relevant scripts (k value used\n",
      "for the proposed methodology is 5).\n",
      "The above semantic similarity search is further\n",
      "optimized using IVF-Flat (Inverted File with Flat\n",
      "Quantization), which segregates all the chunks into\n",
      "clusters, this would help the RAG Framework to focus\n",
      "on only limited number of chunks for fetching the\n",
      "semantically most similar chunks rather than searching\n",
      "in the entire database. The clustering is done using\n",
      "the K-Means Clustering, where in the data points\n",
      "being close to each other are considered as ”similar”\n",
      "and are therefore grouped in one cluster. Doing so\n",
      "for the entire vector database would help divide all\n",
      "the chunk embeddings into clusters. IVF-Flat thus\n",
      "significantly improves upon the time complexity of\n",
      "searching especially when dealing with a dataset of\n",
      "large number of movie scripts.\n",
      "For a given Query Embedding, the algorithm calcu-\n",
      "lates the L2 Norm (Euclidean Distance) between the\n",
      "------------\n",
      "Given the new context, refine the original summary.\n",
      "If the context isn't useful, return the original summary.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mYour job is to produce a final summary.\n",
      "We have provided an existing summary up to a certain point: Based on the new context, I refined the original summary to provide an even more comprehensive overview of the PlotPoint framework:\n",
      "\n",
      "PlotPoint is an AI-driven framework that revolutionizes movie scriptwriting and scene generation by harnessing the power of Natural Language Processing and Deep Learning algorithms. By leveraging Retrieval Augmented Generation, fine-tuning of Large Language Models, and visual script element visualization, PlotPoint produces high-quality scripts tailored to user input prompts. Unlike existing models, PlotPoint accommodates customizable elements such as character description, behavior, and other specifications, enabling personalized script generation. With its ability to understand human-like dialogue structures, PlotPoint generates plots with intricate character descriptions and interactions, demonstrating its potential to significantly reduce the time and effort required for scriptwriting.\n",
      "\n",
      "The Transformer architecture, used in the development of PlotPoint, addresses the limitations of Seq2Seq models through the Attention Mechanism. This mechanism enables the model to produce context-specific outputs by determining the relevance of each token in the sequence, which is achieved through the use of Multi-Head and Masked Multi-Head attention mechanisms.\n",
      "\n",
      "The Retrieval Augmented Generation (RAG) architecture used in PlotPoint helps Large Language Models provide better responses by providing relevant information from an external database, reducing the chance of inaccurate or incomplete responses. Specifically, the RAG pipeline (Fig. 2) uses a recursive character text splitter to convert scripts into chunks, which are then converted into embeddings using a sentence transformer. The chunk embeddings are stored in a FAISS vector database and used for performing semantic similarity search to retrieve top-k chunks that are most similar to the query. This contextual information is then used to generate contextually relevant scripts.\n",
      "\n",
      "The RAG framework further optimizes semantic similarity search using IVF-Flat, which segregates all the chunks into clusters using K-Means Clustering. This significantly improves the time complexity of searching, especially when dealing with a large dataset of movie scripts. The algorithm calculates the L2 Norm (Euclidean Distance) between the query embedding and the chunk embeddings to determine the most similar chunks.\n",
      "\n",
      "The PlotPoint framework is distinguished by its ability to address the challenges faced in human evaluation methods and the need for standardized methods. By incorporating Retrieval Augmented Generation and fine-tuning of Large Language Models, PlotPoint enables the generation of high-quality scripts, as demonstrated by strong BLEU-4 and ROUGE-L scores. Overall, PlotPoint is a powerful tool for automated scriptwriting and scene generation, with significant implications for the future of content creation. Its unique combination of mechanisms and ability to accommodate customizable elements make it a valuable addition to the field of script generation.\n",
      "We have the opportunity to refine the existing summary (only if needed) with some more context below.\n",
      "------------\n",
      "searching especially when dealing with a dataset of\n",
      "large number of movie scripts.\n",
      "For a given Query Embedding, the algorithm calcu-\n",
      "lates the L2 Norm (Euclidean Distance) between the\n",
      "Query Embedding and the Centroid of each region\n",
      "(cluster), in order to narrow-down the search and\n",
      "perform semantic similarity search within that cluster\n",
      "for the top ’k’ chunks.\n",
      "The top ’k’ chunks are evaluated using cosine sim-\n",
      "ilarity (to measure degree of similarity between two\n",
      "vectors or embeddings) and Euclidean Distance, this\n",
      "way the retrieved chunks are ranked based on how high\n",
      "is the cosine similarity and how low the Euclidean\n",
      "Distance between the Query Embedding and chunk\n",
      "embeddings (with priority given to cosine similarity).\n",
      "These retrieved chunks (along with their metadata)\n",
      "will be provided to the LLM to generate an accurate\n",
      "script which adheres to the input query while prevent-\n",
      "ing the LLM from hallucinating. The LLM used for\n",
      "RAG implementation is Gemini-Pro.\n",
      "1) Gemini-Pro\n",
      "Gemini-Pro developed by Google DeepMind, is\n",
      "a state-of-the-art LLM with enhanced capabilities\n",
      "for Natural Language Generation and Understanding\n",
      "tasks. It excels in complex reasoning thereby gener-\n",
      "ating nuanced and coherent movie scripts tailored to\n",
      "the specifications. With the inclusion of RAG, Gemini-\n",
      "Pro’s potential hallucination is successfully mitigated.\n",
      "Gemini-Pro has the ability to use either decoder-\n",
      "only or encoder-decoder architecture, based on the\n",
      "structure and type of task, making it a versatile LLM.\n",
      "C. Fine-Tuning LLMs\n",
      "Fine-tuning Large Language Models involves using\n",
      "a pre-trained model and down-streaming it to a specific\n",
      "task like script generation by training it on the task-\n",
      "specific dataset. This process modifies the weights of\n",
      "the pre-trained model to align the predictions accord-\n",
      "ing to the specific task.\n",
      "Using the embeddings of these pre-trained mod-\n",
      "els ensures that the semantic relationships within the\n",
      "movie scripts are captured, so as to generate a proper\n",
      "------------\n",
      "Given the new context, refine the original summary.\n",
      "If the context isn't useful, return the original summary.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mYour job is to produce a final summary.\n",
      "We have provided an existing summary up to a certain point: Based on the new context, I refined the original summary to provide an even more comprehensive overview of the PlotPoint framework:\n",
      "\n",
      "PlotPoint is an AI-driven framework that revolutionizes movie scriptwriting and scene generation by harnessing the power of Natural Language Processing and Deep Learning algorithms. By leveraging Retrieval Augmented Generation, fine-tuning of Large Language Models, and visual script element visualization, PlotPoint produces high-quality scripts tailored to user input prompts. Unlike existing models, PlotPoint accommodates customizable elements such as character description, behavior, and other specifications, enabling personalized script generation. With its ability to understand human-like dialogue structures, PlotPoint generates plots with intricate character descriptions and interactions, demonstrating its potential to significantly reduce the time and effort required for scriptwriting.\n",
      "\n",
      "The Transformer architecture, used in the development of PlotPoint, addresses the limitations of Seq2Seq models through the Attention Mechanism. This mechanism enables the model to produce context-specific outputs by determining the relevance of each token in the sequence, which is achieved through the use of Multi-Head and Masked Multi-Head attention mechanisms.\n",
      "\n",
      "The Retrieval Augmented Generation (RAG) pipeline used in PlotPoint involves a recursive character text splitter to convert scripts into chunks, which are then converted into embeddings using a sentence transformer. The chunk embeddings are stored in a FAISS vector database and used for performing semantic similarity search to retrieve top-k chunks that are most similar to the query. The RAG framework further optimizes semantic similarity search using IVF-Flat, which segregates all the chunks into clusters using K-Means Clustering, significantly improving the time complexity of searching, especially when dealing with a large dataset of movie scripts.\n",
      "\n",
      "The RAG pipeline also utilizes the Gemini-Pro Large Language Model, which is fine-tuned for script generation tasks. Gemini-Pro's ability to use either decoder-only or encoder-decoder architecture makes it a versatile LLM. The fine-tuning process involves modifying the weights of the pre-trained model to align the predictions according to the specific task, ensuring that the semantic relationships within the movie scripts are captured to generate a proper script.\n",
      "\n",
      "The PlotPoint framework's ability to address the challenges faced in human evaluation methods and the need for standardized methods is evident in its strong BLEU-4 and ROUGE-L scores. Overall, PlotPoint is a powerful tool for automated scriptwriting and scene generation, with significant implications for the future of content creation. Its unique combination of mechanisms and ability to accommodate customizable elements make it a valuable addition to the field of script generation.\n",
      "We have the opportunity to refine the existing summary (only if needed) with some more context below.\n",
      "------------\n",
      "ing to the specific task.\n",
      "Using the embeddings of these pre-trained mod-\n",
      "els ensures that the semantic relationships within the\n",
      "movie scripts are captured, so as to generate a proper\n",
      "dialogue flow and adhere to specifications.\n",
      "------------\n",
      "Given the new context, refine the original summary.\n",
      "If the context isn't useful, return the original summary.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mYour job is to produce a final summary.\n",
      "We have provided an existing summary up to a certain point: Based on the new context, I refined the original summary to provide an even more comprehensive overview of the PlotPoint framework:\n",
      "\n",
      "PlotPoint is an AI-driven framework that revolutionizes movie scriptwriting and scene generation by harnessing the power of Natural Language Processing and Deep Learning algorithms. By leveraging Retrieval Augmented Generation, fine-tuning of Large Language Models, and visual script element visualization, PlotPoint produces high-quality scripts tailored to user input prompts. Unlike existing models, PlotPoint accommodates customizable elements such as character description, behavior, and other specifications, enabling personalized script generation. With its ability to understand human-like dialogue structures, PlotPoint generates plots with intricate character descriptions and interactions, demonstrating its potential to significantly reduce the time and effort required for scriptwriting.\n",
      "\n",
      "The framework's architecture incorporates the Transformer model, which addresses the limitations of Seq2Seq models through the Attention Mechanism. This mechanism enables the model to produce context-specific outputs by determining the relevance of each token in the sequence, achieved through the use of Multi-Head and Masked Multi-Head attention mechanisms. The Retrieval Augmented Generation (RAG) pipeline involves a recursive character text splitter, chunk embeddings generated using a sentence transformer, and storage in a FAISS vector database for semantic similarity search. The RAG framework optimizes search using IVF-Flat and K-Means Clustering, significantly improving time complexity when dealing with large datasets.\n",
      "\n",
      "The Gemini-Pro Large Language Model is fine-tuned for script generation tasks, utilizing either decoder-only or encoder-decoder architecture. The fine-tuning process modifies the pre-trained model's weights to align predictions with the specific task, capturing semantic relationships within movie scripts to generate a proper script. PlotPoint's strong BLEU-4 and ROUGE-L scores demonstrate its ability to address challenges in human evaluation methods and the need for standardized methods. Overall, PlotPoint is a powerful tool for automated scriptwriting and scene generation, offering significant implications for the future of content creation.\n",
      "We have the opportunity to refine the existing summary (only if needed) with some more context below.\n",
      "------------\n",
      "Fig. 3: Fine-Tuning LLMs Pipeline\n",
      "1) GPT-2\n",
      "GPT-2 (Generative Pre-trained Transformer 2) [14]\n",
      "is a state-of-the-art language model based on the trans-\n",
      "formers architecture developed by OpenAI. It consists\n",
      "of multiple self attention mechanisms and feed forward\n",
      "neural networks to generate contextually relevant and\n",
      "coherent text. GPT-2 is a pre-trained model used for\n",
      "a variety of NLP tasks and thus fine tuning it on a\n",
      "downstream task like text generation would achieve\n",
      "great results. The GPT-2 model used in this paper has\n",
      "approximately 124 million parameters (GPT-2 Small).\n",
      "GPT-2 uses its own tokenizer, as other basic tok-\n",
      "enizers are unable to capture the contextual meaning\n",
      "behind the dialogues and scene settings in a script.\n",
      "It generates tokens based on the contextual under-\n",
      "standing of the sequences, thus capturing the relation\n",
      "between different sequences.\n",
      "It tokenizes words into individual characters and\n",
      "makes character pairs based on consecutive characters.\n",
      "Then it combines two characters into the same token\n",
      "based on the frequency of the repeating character pairs.\n",
      "This process is repeated until a predefined vocabulary\n",
      "size is reached, efficiently and deterministically form-\n",
      "ing a set of subword units which represent the text\n",
      "corpus.\n",
      "The GPT-2 tokenizer has a limitation of only allow-\n",
      "ing a maximum length of 1024 tokens to be encoded.\n",
      "On average the GPT-2 tokenizer makes approximately\n",
      "4 tokens for every 3 words, therefore the scripts get\n",
      "chunked into 700 word chunks and then tokenized.\n",
      "The model is then trained on these individual chunks,\n",
      "retaining all information from the entire script.\n",
      "Once the tokenization is complete, it is ready to be\n",
      "fit into the model for fine-tuning. This approach allows\n",
      "the model to fine-tune on scripts regardless of their size\n",
      "and helps in retaining context as it trains the model on\n",
      "the largest possible chunks, learning patterns between\n",
      "words in a larger sequence.\n",
      "2) Bloom\n",
      "Bloom (BigScience Large Open-science Open-\n",
      "------------\n",
      "Given the new context, refine the original summary.\n",
      "If the context isn't useful, return the original summary.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mYour job is to produce a final summary.\n",
      "We have provided an existing summary up to a certain point: Based on the new context, I refined the original summary to provide an even more comprehensive overview of the PlotPoint framework:\n",
      "\n",
      "PlotPoint is a groundbreaking AI-driven framework that revolutionizes movie scriptwriting and scene generation by leveraging the power of Natural Language Processing and Deep Learning algorithms. By harnessing Retrieval Augmented Generation, fine-tuning of Large Language Models, and visual script element visualization, PlotPoint produces high-quality scripts tailored to user input prompts. The framework's architecture incorporates the Transformer model, which addresses the limitations of Seq2Seq models through the Attention Mechanism, enabling context-specific outputs.\n",
      "\n",
      "The Retrieval Augmented Generation (RAG) pipeline, which includes a recursive character text splitter, chunk embeddings generated using a sentence transformer, and storage in a FAISS vector database for semantic similarity search, optimizes search using IVF-Flat and K-Means Clustering to significantly improve time complexity when dealing with large datasets. PlotPoint's strong BLEU-4 and ROUGE-L scores demonstrate its ability to address challenges in human evaluation methods and the need for standardized methods.\n",
      "\n",
      "The framework's fine-tuning process involves the use of Large Language Models (LLMs), specifically GPT-2 and Bloom, which are pre-trained models used for a variety of NLP tasks. GPT-2, with approximately 124 million parameters, is a state-of-the-art language model based on the transformers architecture developed by OpenAI. Its own tokenizer is used to capture the contextual meaning behind dialogues and scene settings in a script. Bloom, a BigScience Large Open-science Open-source model, is also used for fine-tuning.\n",
      "\n",
      "The fine-tuning process involves tokenizing words into individual characters and making character pairs based on consecutive characters. The GPT-2 tokenizer has a limitation of only allowing a maximum length of 1024 tokens to be encoded, which is addressed by chunking scripts into 700-word chunks and then tokenizing. This approach allows the model to fine-tune on scripts regardless of their size and helps in retaining context.\n",
      "\n",
      "Overall, PlotPoint is a powerful tool for automated scriptwriting and scene generation, offering significant implications for the future of content creation. Its ability to understand human-like dialogue structures, generate plots with intricate character descriptions and interactions, and accommodate customizable elements such as character description, behavior, and other specifications make it a valuable asset for the entertainment industry.\n",
      "We have the opportunity to refine the existing summary (only if needed) with some more context below.\n",
      "------------\n",
      "and helps in retaining context as it trains the model on\n",
      "the largest possible chunks, learning patterns between\n",
      "words in a larger sequence.\n",
      "2) Bloom\n",
      "Bloom (BigScience Large Open-science Open-\n",
      "access Multilingual) [15] is another state-of-the-art\n",
      "language model based on the transformers architecture.\n",
      "Similar to GPT-2, it also consists of multiple self at-\n",
      "tention mechanisms and feed forward neural networks\n",
      "to generate contextually relevant and coherent text.\n",
      "Bloom is a pre-trained model which is trained on mul-\n",
      "tilingual data. It has 560 million parameters (Bloom\n",
      "560m) therefore can still prove to have significantly\n",
      "positive results for generating text in a single language.\n",
      "Bloom also uses its own tokenizer which tokenizes\n",
      "text based on a probabilistic approach which is op-\n",
      "timized for diverse scripts and has a more flexible\n",
      "tokenization approach and allows better capturing of\n",
      "context and relationships of words in diverse datasets.\n",
      "It uses SentencePiece which uses a uni-gram language\n",
      "model to build its vocabulary.\n",
      "SentencePiece iteratively learns tokens that are most\n",
      "likely to occur in the training data. It merges the most\n",
      "frequently occurring token pairs into larger tokens and\n",
      "probabilistically estimates the likelihood of merging\n",
      "pairs based on observed frequency distributions of\n",
      "merged tokens. This forms a set of subword units\n",
      "which represent the text corpus.\n",
      "The Bloom tokenizer also has a maximum length of\n",
      "2048 tokens to be encoded. Chunking is also used here\n",
      "to chunk a maximum of 512 tokens per chunk. This\n",
      "allowed for a more efficient tokenization process due\n",
      "to the parallelization of the task using a GPU. After\n",
      "the tokenization, the tokens are ready to fit into the\n",
      "Bloom model for fine-tuning.\n",
      "Since LLM is only using a small percentage of the\n",
      "total parameters, there is loss of accuracy in the script\n",
      "generation, the key is to find the trade-off between\n",
      "the loss of accuracy and reducing computational cost\n",
      "which would make this approach scalable and efficient\n",
      "------------\n",
      "Given the new context, refine the original summary.\n",
      "If the context isn't useful, return the original summary.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mYour job is to produce a final summary.\n",
      "We have provided an existing summary up to a certain point: Based on the provided context, I refined the original summary to provide an even more comprehensive overview of the PlotPoint framework:\n",
      "\n",
      "PlotPoint is a groundbreaking AI-driven framework that revolutionizes movie scriptwriting and scene generation by leveraging the power of Natural Language Processing and Deep Learning algorithms. By harnessing Retrieval Augmented Generation, fine-tuning of Large Language Models, and visual script element visualization, PlotPoint produces high-quality scripts tailored to user input prompts. The framework's architecture incorporates the Transformer model, which addresses the limitations of Seq2Seq models through the Attention Mechanism, enabling context-specific outputs.\n",
      "\n",
      "The Retrieval Augmented Generation (RAG) pipeline, which includes a recursive character text splitter, chunk embeddings generated using a sentence transformer, and storage in a FAISS vector database for semantic similarity search, optimizes search using IVF-Flat and K-Means Clustering to significantly improve time complexity when dealing with large datasets. PlotPoint's strong BLEU-4 and ROUGE-L scores demonstrate its ability to address challenges in human evaluation methods and the need for standardized methods.\n",
      "\n",
      "The framework's fine-tuning process involves the use of Large Language Models (LLMs), specifically GPT-2 and Bloom, which are pre-trained models used for a variety of NLP tasks. GPT-2, with approximately 124 million parameters, is a state-of-the-art language model based on the transformers architecture developed by OpenAI. Its tokenizer is used to capture the contextual meaning behind dialogues and scene settings in a script. Bloom, a BigScience Large Open-science Open-source model, is also used for fine-tuning. Bloom, with 560 million parameters, is trained on multilingual data and uses its own tokenizer, which tokenizes text based on a probabilistic approach, optimized for diverse scripts, and allows better capturing of context and relationships of words in diverse datasets.\n",
      "\n",
      "The fine-tuning process involves tokenizing words into individual characters and making character pairs based on consecutive characters. Both GPT-2 and Bloom tokenizers have limitations, with a maximum length of 1024 and 2048 tokens, respectively. To address these limitations, chunking is used to chunk scripts into 700-word and 512-token chunks, respectively, allowing the models to fine-tune on scripts regardless of their size and retain context.\n",
      "\n",
      "Overall, PlotPoint is a powerful tool for automated scriptwriting and scene generation, offering significant implications for the future of content creation. Its ability to understand human-like dialogue structures, generate plots with intricate character descriptions and interactions, and accommodate customizable elements such as character description, behavior, and other specifications make it a valuable asset for the entertainment industry. By leveraging the strengths of both GPT-2 and Bloom, PlotPoint achieves a balance between accuracy and computational cost, making it a scalable and efficient approach to script generation.\n",
      "We have the opportunity to refine the existing summary (only if needed) with some more context below.\n",
      "------------\n",
      "generation, the key is to find the trade-off between\n",
      "the loss of accuracy and reducing computational cost\n",
      "which would make this approach scalable and efficient\n",
      "for large and complex datasets.\n",
      "------------\n",
      "Given the new context, refine the original summary.\n",
      "If the context isn't useful, return the original summary.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mYour job is to produce a final summary.\n",
      "We have provided an existing summary up to a certain point: Here is the refined summary:\n",
      "\n",
      "PlotPoint is a groundbreaking AI-driven framework that revolutionizes movie scriptwriting and scene generation by leveraging the power of Natural Language Processing and Deep Learning algorithms. By harnessing Retrieval Augmented Generation, fine-tuning of Large Language Models, and visual script element visualization, PlotPoint produces high-quality scripts tailored to user input prompts. The framework's architecture incorporates the Transformer model, which addresses the limitations of Seq2Seq models through the Attention Mechanism, enabling context-specific outputs.\n",
      "\n",
      "The Retrieval Augmented Generation (RAG) pipeline optimizes search using IVF-Flat and K-Means Clustering to significantly improve time complexity when dealing with large datasets. PlotPoint's strong BLEU-4 and ROUGE-L scores demonstrate its ability to address challenges in human evaluation methods and the need for standardized methods.\n",
      "\n",
      "The framework's fine-tuning process involves the use of Large Language Models (LLMs), specifically GPT-2 and Bloom, which are pre-trained models used for a variety of NLP tasks. The fine-tuning process tokenizes words into individual characters, making character pairs based on consecutive characters, and chunks scripts into segments to accommodate scripts of varying sizes.\n",
      "\n",
      "To achieve a balance between accuracy and computational cost, PlotPoint finds a trade-off between loss of accuracy and reducing computational cost, making it a scalable and efficient approach to script generation for large and complex datasets. By leveraging the strengths of both GPT-2 and Bloom, PlotPoint offers a powerful tool for automated scriptwriting and scene generation, with significant implications for the future of content creation. Its ability to understand human-like dialogue structures, generate plots with intricate character descriptions and interactions, and accommodate customizable elements make it a valuable asset for the entertainment industry.\n",
      "We have the opportunity to refine the existing summary (only if needed) with some more context below.\n",
      "------------\n",
      "D. Text-Image Generation\n",
      "Text-Image generation would allow users to visual-\n",
      "ize the scripts through scenes, and hence ideate upon\n",
      "the movie script generation in a robust manner. Text-\n",
      "Image generation begins with tokenizing and creating\n",
      "an embedding of the query to capture the semantic\n",
      "meaning and context of the query.\n",
      "Fig. 4: Working of Stable Diffusion for Text-Image\n",
      "Generation\n",
      "Tokenization creates tokens which are smaller com-\n",
      "ponents of the input query and the embedding is a\n",
      "numerical vector which represents the tokens. Stable\n",
      "Diffusion [16], one of the best algorithms for image\n",
      "generation, begins with random noise and progres-\n",
      "sively learns to refine the noisy image by de-noising\n",
      "it and eventually generating a clear image relevant\n",
      "to the query. It operates within a latent space - a\n",
      "compressed space in which image generation can be\n",
      "done efficiently.\n",
      "Stable Diffusion uses a process called de-noising\n",
      "diffusion which refines the noisy latent representation\n",
      "in a step-by-step process to create a meaningful image.\n",
      "The model aligns the patterns of the image with that\n",
      "of the embedding to form an image which matches the\n",
      "semantical meaning of the given query. Once the image\n",
      "de-noising is performed, a decoder model is used to\n",
      "upsample this image and transform it into a visible\n",
      "image.\n",
      "The algorithm makes use of cross-attention layers\n",
      "which allows the model to focus on different parts\n",
      "of the query embedding at various stages of the de-\n",
      "noising process. This helps in refining the image in\n",
      "order to maintain the coherence and semantic integrity\n",
      "of the input text during the generation of the image.\n",
      "The Stable Diffusion model used for this approach\n",
      "is CompVis.\n",
      "IV. E VALUATION\n",
      "1) Cosine Similarity:\n",
      "Cosine Similarity is a popular metric for assess-\n",
      "ing how semantically similar a generated script\n",
      "is to its input prompt. In a multidimensional\n",
      "space, it is calculated as the cosine of the angle\n",
      "formed by two vectors. The input prompt and the\n",
      "------------\n",
      "Given the new context, refine the original summary.\n",
      "If the context isn't useful, return the original summary.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mYour job is to produce a final summary.\n",
      "We have provided an existing summary up to a certain point: Here is the refined summary:\n",
      "\n",
      "PlotPoint is a groundbreaking AI-driven framework that revolutionizes movie scriptwriting and scene generation by leveraging the power of Natural Language Processing and Deep Learning algorithms. By harnessing Retrieval Augmented Generation, fine-tuning of Large Language Models, and visual script element visualization, PlotPoint produces high-quality scripts tailored to user input prompts. The framework's architecture incorporates the Transformer model, which addresses the limitations of Seq2Seq models through the Attention Mechanism, enabling context-specific outputs.\n",
      "\n",
      "The Retrieval Augmented Generation (RAG) pipeline optimizes search using IVF-Flat and K-Means Clustering to significantly improve time complexity when dealing with large datasets. PlotPoint's strong BLEU-4 and ROUGE-L scores demonstrate its ability to address challenges in human evaluation methods and the need for standardized methods.\n",
      "\n",
      "The framework's fine-tuning process involves the use of Large Language Models (LLMs), specifically GPT-2 and Bloom, which are pre-trained models used for a variety of NLP tasks. The fine-tuning process tokenizes words into individual characters, making character pairs based on consecutive characters, and chunks scripts into segments to accommodate scripts of varying sizes.\n",
      "\n",
      "To achieve a balance between accuracy and computational cost, PlotPoint finds a trade-off between loss of accuracy and reducing computational cost, making it a scalable and efficient approach to script generation for large and complex datasets. By leveraging the strengths of both GPT-2 and Bloom, PlotPoint offers a powerful tool for automated scriptwriting and scene generation, with significant implications for the future of content creation.\n",
      "\n",
      "Additionally, PlotPoint's Text-Image generation feature allows users to visualize scripts through scenes, enabling robust ideation and movie script generation. This feature uses Stable Diffusion, a state-of-the-art algorithm for image generation, to create high-quality images relevant to the input query. The algorithm refines noisy latent representations step-by-step, aligning patterns with the embedding to form a meaningful image that matches the semantic meaning of the query.\n",
      "\n",
      "In terms of evaluation, PlotPoint's performance is assessed using Cosine Similarity, a popular metric for measuring semantic similarity between generated scripts and input prompts. With its ability to understand human-like dialogue structures, generate plots with intricate character descriptions and interactions, and accommodate customizable elements, PlotPoint is a valuable asset for the entertainment industry.\n",
      "We have the opportunity to refine the existing summary (only if needed) with some more context below.\n",
      "------------\n",
      "ing how semantically similar a generated script\n",
      "is to its input prompt. In a multidimensional\n",
      "space, it is calculated as the cosine of the angle\n",
      "formed by two vectors. The input prompt and the\n",
      "resulting script’s text are represented by these\n",
      "vectors, respectively.\n",
      "The range of a cosine similarity value is -1 to\n",
      "1. A value of 1 denotes complete alignment, in\n",
      "which the output script’s semantic meaning is\n",
      "exactly the same as that of the input prompt.\n",
      "Being orthogonal, a value of 0 indicates no\n",
      "semantic resemblance. A value of -1, on the\n",
      "other hand, indicates total dissimilarity, with the\n",
      "vectors pointing in opposing directions.\n",
      "The model’s ability to preserve semantic co-\n",
      "herence between the input and the generated\n",
      "output improves with increasing cosine similar-\n",
      "ity. When guaranteeing semantic consistency in\n",
      "text creation is a primary goal, this metric is\n",
      "essential.\n",
      "Cosine Similarity(A, B) = A · B\n",
      "∥A∥∥B∥ (8)\n",
      "where, A and B are vectors.\n",
      "2) Perplexity:\n",
      "Perplexity is another crucial assessment metric ,\n",
      "which is mainly applied to text generation tasks.\n",
      "It evaluates a probabilistic model’s ability to\n",
      "anticipate a word sequence. The entropy of the\n",
      "anticipated probability is used to calculate the\n",
      "perplexity value, which goes from 1 to infinity.\n",
      "The model is more certain of its predictions for\n",
      "the subsequent token in the sequence when the\n",
      "perplexity score is lower. On the other hand,\n",
      "greater uncertainty is indicated by a larger per-\n",
      "plexity, which exposes flaws in the probability\n",
      "distribution of the model. A diagnostic method\n",
      "for assessing a language model’s dependability\n",
      "and fluency is perplexity.\n",
      "Low perplexity is a crucial parameter for as-\n",
      "sessing performance in natural language genera-\n",
      "tion tasks since models with low perplexity are\n",
      "generally better able to generate coherent and\n",
      "contextually relevant sequences. Mathematically,\n",
      "Perplexity (PPL) is calculated as:\n",
      "PPL = exp\n",
      " \n",
      "− 1\n",
      "N\n",
      "NX\n",
      "i=1\n",
      "log P(wi | w1, . . . , wi−1)\n",
      "!\n",
      "(9)\n",
      "where, P(wi | w1, . . . , wi−1) is the conditional\n",
      "------------\n",
      "Given the new context, refine the original summary.\n",
      "If the context isn't useful, return the original summary.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mYour job is to produce a final summary.\n",
      "We have provided an existing summary up to a certain point: After considering the new context, I refined the original summary to provide a more comprehensive overview of PlotPoint's capabilities and evaluation metrics. Here is the refined summary:\n",
      "\n",
      "PlotPoint is a revolutionary AI-driven framework that transforms movie scriptwriting and scene generation by harnessing the power of Natural Language Processing and Deep Learning algorithms. Leveraging Retrieval Augmented Generation, fine-tuning of Large Language Models, and visual script element visualization, PlotPoint produces high-quality scripts tailored to user input prompts. The framework's architecture incorporates the Transformer model, which addresses the limitations of Seq2Seq models through the Attention Mechanism, enabling context-specific outputs.\n",
      "\n",
      "PlotPoint's fine-tuning process involves the use of Large Language Models, specifically GPT-2 and Bloom, which are pre-trained models used for a variety of NLP tasks. The framework's ability to optimize search using IVF-Flat and K-Means Clustering significantly improves time complexity when dealing with large datasets. PlotPoint's strong BLEU-4 and ROUGE-L scores demonstrate its ability to address challenges in human evaluation methods and the need for standardized methods.\n",
      "\n",
      "To evaluate PlotPoint's performance, the framework uses two key metrics: Cosine Similarity and Perplexity. Cosine Similarity measures the semantic similarity between generated scripts and input prompts, with a range of -1 to 1, where a value of 1 indicates complete alignment and a value of 0 indicates no semantic resemblance. Perplexity, on the other hand, evaluates a model's ability to anticipate a word sequence, with lower perplexity scores indicating better performance.\n",
      "\n",
      "By leveraging the strengths of both GPT-2 and Bloom, PlotPoint offers a powerful tool for automated scriptwriting and scene generation, with significant implications for the future of content creation. The framework's Text-Image generation feature allows users to visualize scripts through scenes, enabling robust ideation and movie script generation. With its ability to understand human-like dialogue structures, generate plots with intricate character descriptions and interactions, and accommodate customizable elements, PlotPoint is a valuable asset for the entertainment industry.\n",
      "We have the opportunity to refine the existing summary (only if needed) with some more context below.\n",
      "------------\n",
      "contextually relevant sequences. Mathematically,\n",
      "Perplexity (PPL) is calculated as:\n",
      "PPL = exp\n",
      " \n",
      "− 1\n",
      "N\n",
      "NX\n",
      "i=1\n",
      "log P(wi | w1, . . . , wi−1)\n",
      "!\n",
      "(9)\n",
      "where, P(wi | w1, . . . , wi−1) is the conditional\n",
      "probability of the i-th word given all the previous\n",
      "words w1, . . . , wi−1 in the sequence and N is\n",
      "the total number of words in the test sequence.\n",
      "3) CLIP Score:\n",
      "It is a metric used to assess how well created\n",
      "------------\n",
      "Given the new context, refine the original summary.\n",
      "If the context isn't useful, return the original summary.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mYour job is to produce a final summary.\n",
      "We have provided an existing summary up to a certain point: Here is the refined summary:\n",
      "\n",
      "PlotPoint is a groundbreaking AI-driven framework that revolutionizes movie scriptwriting and scene generation by harnessing the power of Natural Language Processing, Deep Learning algorithms, and Retrieval Augmented Generation. By leveraging Large Language Models, specifically GPT-2 and Bloom, and incorporating the Transformer model with the Attention Mechanism, PlotPoint produces high-quality scripts tailored to user input prompts. The framework's architecture optimizes search using IVF-Flat and K-Means Clustering, significantly improving time complexity when dealing with large datasets.\n",
      "\n",
      "To evaluate PlotPoint's performance, the framework uses three key metrics: Cosine Similarity, Perplexity, and CLIP Score. Cosine Similarity measures the semantic similarity between generated scripts and input prompts, with a range of -1 to 1, where a value of 1 indicates complete alignment and a value of 0 indicates no semantic resemblance. Perplexity, mathematically calculated as exp(-1/NΣi=1log P(wi | w1, ..., wi−1)), evaluates a model's ability to anticipate a word sequence, with lower perplexity scores indicating better performance. The CLIP Score assesses how well created scenes align with the input prompts, providing a comprehensive evaluation of PlotPoint's scene generation capabilities.\n",
      "\n",
      "PlotPoint's Text-Image generation feature allows users to visualize scripts through scenes, enabling robust ideation and movie script generation. With its ability to understand human-like dialogue structures, generate plots with intricate character descriptions and interactions, and accommodate customizable elements, PlotPoint is a valuable asset for the entertainment industry, offering a powerful tool for automated scriptwriting and scene generation.\n",
      "We have the opportunity to refine the existing summary (only if needed) with some more context below.\n",
      "------------\n",
      "words w1, . . . , wi−1 in the sequence and N is\n",
      "the total number of words in the test sequence.\n",
      "3) CLIP Score:\n",
      "It is a metric used to assess how well created\n",
      "images match the written prompts that go with\n",
      "them. CLIP generates vector representations for\n",
      "the created image and the text prompt using\n",
      "a shared embedding space. Cosine similarity is\n",
      "------------\n",
      "Given the new context, refine the original summary.\n",
      "If the context isn't useful, return the original summary.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mYour job is to produce a final summary.\n",
      "We have provided an existing summary up to a certain point: Based on the new context, I refined the original summary to provide a more comprehensive overview of PlotPoint's capabilities and features. Here is the refined summary:\n",
      "\n",
      "PlotPoint is a groundbreaking AI-driven framework that revolutionizes movie scriptwriting and scene generation by harnessing the power of Natural Language Processing, Deep Learning algorithms, and Retrieval Augmented Generation. By leveraging Large Language Models, specifically GPT-2 and Bloom, and incorporating the Transformer model with the Attention Mechanism, PlotPoint produces high-quality scripts tailored to user input prompts. The framework's architecture optimizes search using IVF-Flat and K-Means Clustering, significantly improving time complexity when dealing with large datasets.\n",
      "\n",
      "To evaluate PlotPoint's performance, the framework uses three key metrics: Cosine Similarity, Perplexity, and CLIP Score. Cosine Similarity measures the semantic similarity between generated scripts and input prompts, with a range of -1 to 1, where a value of 1 indicates complete alignment and a value of 0 indicates no semantic resemblance. Perplexity, mathematically calculated as exp(-1/NΣi=1log P(wi | w1, ..., wi−1)), evaluates a model's ability to anticipate a word sequence, with lower perplexity scores indicating better performance. The CLIP Score assesses how well created scenes align with the input prompts, providing a comprehensive evaluation of PlotPoint's scene generation capabilities. CLIP Score is a metric that generates vector representations for the created image and the text prompt using a shared embedding space, and calculates the cosine similarity between them to measure the match.\n",
      "\n",
      "PlotPoint's Text-Image generation feature allows users to visualize scripts through scenes, enabling robust ideation and movie script generation. With its ability to understand human-like dialogue structures, generate plots with intricate character descriptions and interactions, and accommodate customizable elements, PlotPoint is a valuable asset for the entertainment industry, offering a powerful tool for automated scriptwriting and scene generation.\n",
      "We have the opportunity to refine the existing summary (only if needed) with some more context below.\n",
      "------------\n",
      "then used to calculate how similar these embed-\n",
      "dings are to one another.\n",
      "While a lower score signifies poor alignment,\n",
      "a higher CLIP Score shows that the resulting\n",
      "image closely reflects the text prompt’s semantic\n",
      "intent. In multi-modal applications where pre-\n",
      "serving the prompt’s integrity in the visual rep-\n",
      "resentation is crucial, such as picture synthesis\n",
      "from textual descriptions, this measure is very\n",
      "useful.\n",
      "The CLIP Score guarantees that produced out-\n",
      "puts satisfy the required degree of semantic\n",
      "accuracy by offering a measurable indicator of\n",
      "textual and visual coherence.\n",
      "CLIP(T, I) = ET · EI\n",
      "∥ET ∥∥EI∥ (10)\n",
      "where, ET and EI are the embeddings of the\n",
      "text and image, respectively and ∥ET ∥ and ∥EI∥\n",
      "represent the norms (magnitudes) of these em-\n",
      "bedding vectors.\n",
      "V. R ESULTS\n",
      "TABLE I: Model evaluation metrics and their average\n",
      "scores\n",
      "Model Metric Score (Average)\n",
      "GPT-2 Cosine Similarity 0.5011\n",
      "GPT-2 Perplexity 1.7443\n",
      "Bloom Cosine Similarity 0.5058\n",
      "Bloom Perplexity 1.6892\n",
      "Gemini-Pro Cosine Similarity 0.5713\n",
      "CompVis CLIP Score 0.3061\n",
      "1) GPT-2 (Cosine Similarity):\n",
      "Fig.5 shows a density plot of cosine similarity\n",
      "using the fine-tuned GPT-2 model. The values\n",
      "go as high as 0.8 and as low as 0.2. The graph\n",
      "suggests that the generated script at times has\n",
      "very high contextual similarity between the input\n",
      "query and the generated script and at times very\n",
      "low.\n",
      "Fig. 5: Density Plot for Cosine Similarity (fine-tuned\n",
      "GPT-2)\n",
      "The lower values can suggest poor generation\n",
      "leading to lesser context being included in the\n",
      "generated script or can be due to high creativity\n",
      "which leads to a variety of information along\n",
      "with the details outlined in the prompt being\n",
      "mentioned in the script.\n",
      "The higher values suggest that the script per-\n",
      "fectly encompasses the required details from the\n",
      "prompt but can also suggest that the generation\n",
      "had lesser creativity and did not add many details\n",
      "which were not mentioned. This can suggest\n",
      "that a great input prompt with a lot of details\n",
      "------------\n",
      "Given the new context, refine the original summary.\n",
      "If the context isn't useful, return the original summary.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mYour job is to produce a final summary.\n",
      "We have provided an existing summary up to a certain point: Here is the refined summary:\n",
      "\n",
      "PlotPoint is a groundbreaking AI-driven framework that revolutionizes movie scriptwriting and scene generation by leveraging Natural Language Processing, Deep Learning algorithms, and Retrieval Augmented Generation. The framework utilizes Large Language Models, specifically GPT-2 and Bloom, and incorporates the Transformer model with the Attention Mechanism to produce high-quality scripts tailored to user input prompts. The architecture optimizes search using IVF-Flat and K-Means Clustering, significantly improving time complexity when dealing with large datasets.\n",
      "\n",
      "To evaluate PlotPoint's performance, the framework uses three key metrics: Cosine Similarity, Perplexity, and CLIP Score. Cosine Similarity measures the semantic similarity between generated scripts and input prompts, with a range of -1 to 1, where a value of 1 indicates complete alignment and a value of 0 indicates no semantic resemblance. Perplexity evaluates a model's ability to anticipate a word sequence, with lower perplexity scores indicating better performance. The CLIP Score assesses how well created scenes align with the input prompts, providing a comprehensive evaluation of PlotPoint's scene generation capabilities.\n",
      "\n",
      "The CLIP Score is a valuable metric that generates vector representations for the created image and the text prompt using a shared embedding space, and calculates the cosine similarity between them to measure the match. A higher CLIP Score indicates that the resulting image closely reflects the text prompt's semantic intent, while a lower score signifies poor alignment. This measure is particularly useful in multi-modal applications where preserving the prompt's integrity in the visual representation is crucial.\n",
      "\n",
      "PlotPoint's Text-Image generation feature enables users to visualize scripts through scenes, facilitating robust ideation and movie script generation. With its ability to understand human-like dialogue structures, generate plots with intricate character descriptions and interactions, and accommodate customizable elements, PlotPoint is a valuable asset for the entertainment industry, offering a powerful tool for automated scriptwriting and scene generation.\n",
      "We have the opportunity to refine the existing summary (only if needed) with some more context below.\n",
      "------------\n",
      "prompt but can also suggest that the generation\n",
      "had lesser creativity and did not add many details\n",
      "which were not mentioned. This can suggest\n",
      "that a great input prompt with a lot of details\n",
      "was mentioned or the generation was with poor\n",
      "creativity.\n",
      "Majority of the cosine similarity values lying\n",
      "near the average of 0.5011 suggests that the\n",
      "approach was able to generate a script which\n",
      "contained the details from the prompt and was\n",
      "also able to include creative aspects in the script.\n",
      "2) GPT-2 (Perplexity):\n",
      "Fig.6 shows a density plot of the perplexity using\n",
      "fine-tuned GPT-2. The perplexity had an average\n",
      "of 1.7443. The perplexity value varied on the\n",
      "lower side and upper side of this average value.\n",
      "The lower values suggest that the model was\n",
      "less surprised in the token generation of these\n",
      "scripts leading to a well structured script where\n",
      "followup words were expected more often than\n",
      "not.\n",
      "Fig. 6: Density Plot for Perplexity (GPT-2)\n",
      "The higher values can signify a script which\n",
      "made the model more surprised during the token\n",
      "generation. This suggests that the grammatical\n",
      "and semantic clarity of the sentences was jeopar-\n",
      "dized and the sentences more often than not, did\n",
      "not make sense grammatically and contextually.\n",
      "The scripts with perplexity near the average\n",
      "value can suggest that they made sense gram-\n",
      "matically and contextually to some degree but\n",
      "could have either left something to be desired\n",
      "in the generation or the creative aspect of the\n",
      "generation left the model more surprised at the\n",
      "token generation, attributing to its slightly higher\n",
      "perplexity score. This could suggest that the\n",
      "ideal value of perplexity for script generation\n",
      "which includes good creativity could be that with\n",
      "values near the average perplexity of 1.7443.\n",
      "3) Bloom (Cosine Similarity):\n",
      "------------\n",
      "Given the new context, refine the original summary.\n",
      "If the context isn't useful, return the original summary.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mYour job is to produce a final summary.\n",
      "We have provided an existing summary up to a certain point: Here is the refined summary:\n",
      "\n",
      "PlotPoint is a revolutionary AI-driven framework that transforms movie scriptwriting and scene generation by harnessing the power of Natural Language Processing, Deep Learning algorithms, and Retrieval Augmented Generation. Leveraging Large Language Models, such as GPT-2 and Bloom, and the Transformer model with the Attention Mechanism, PlotPoint generates high-quality scripts tailored to user input prompts. The framework optimizes search using IVF-Flat and K-Means Clustering, significantly improving time complexity when working with large datasets.\n",
      "\n",
      "To evaluate PlotPoint's performance, the framework employs three key metrics: Cosine Similarity, Perplexity, and CLIP Score. Cosine Similarity measures the semantic similarity between generated scripts and input prompts, with a range of -1 to 1, where a value of 1 indicates complete alignment and a value of 0 indicates no semantic resemblance. Perplexity evaluates a model's ability to anticipate a word sequence, with lower perplexity scores indicating better performance. The CLIP Score assesses how well created scenes align with the input prompts, providing a comprehensive evaluation of PlotPoint's scene generation capabilities.\n",
      "\n",
      "The results show that the majority of cosine similarity values lie near the average of 0.5011, suggesting that the approach successfully generated scripts that contained details from the prompt and added creative aspects. GPT-2's perplexity had an average of 1.7443, with values varying on both sides of this average. Lower values indicate well-structured scripts with expected word sequences, while higher values suggest grammatical and semantic clarity was compromised. The ideal value of perplexity for script generation, which balances good creativity, appears to be near the average value of 1.7443.\n",
      "\n",
      "The CLIP Score provides a valuable metric for evaluating scene generation, generating vector representations for created images and text prompts using a shared embedding space, and calculating the cosine similarity between them. A higher CLIP Score indicates that the resulting image closely reflects the text prompt's semantic intent, while a lower score signifies poor alignment.\n",
      "\n",
      "PlotPoint's Text-Image generation feature enables users to visualize scripts through scenes, facilitating robust ideation and movie script generation. With its ability to understand human-like dialogue structures, generate plots with intricate character descriptions and interactions, and accommodate customizable elements, PlotPoint is a valuable asset for the entertainment industry, offering a powerful tool for automated scriptwriting and scene generation.\n",
      "We have the opportunity to refine the existing summary (only if needed) with some more context below.\n",
      "------------\n",
      "Fig.7 shows a density plot of cosine similar-\n",
      "ity using the fine-tuned Bloom model, which\n",
      "differs from the fine-tuned GPT-2 model in its\n",
      "distribution and average values. While the cosine\n",
      "similarity for GPT-2 averaged at 0.5011, the\n",
      "Bloom model’s average was 0.5058.\n",
      "Fig. 7: Density Plot for Cosine Similarity (fine-tuned\n",
      "Bloom)\n",
      "Both models showed a range of values from\n",
      "0.2 to 0.8, indicating varying levels of con-\n",
      "textual similarity between the input query and\n",
      "the generated script. However, the Bloom model\n",
      "appears to strike a slightly different balance, with\n",
      "its clustering around the average suggesting a\n",
      "consistent ability to include prompt details while\n",
      "introducing creative aspects.\n",
      "In comparison, the GPT-2 model’s lower and\n",
      "higher values might more distinctly reflect out-\n",
      "puts that either deviate significantly from the\n",
      "prompt or align too closely, potentially at the\n",
      "expense of creativity. The differences in average\n",
      "values and distributions suggest that Bloom may\n",
      "provide a more balanced generation, while GPT-\n",
      "2 may exhibit greater variance in its outputs\n",
      "depending on the nature of the prompt.\n",
      "According to the variations in average values\n",
      "and distributions, Bloom might produce a more\n",
      "balanced generation, but GPT-2 might produce\n",
      "outputs that vary more depending on the prompt.\n",
      "4) Bloom (Perplexity):\n",
      "Fig.6 compares the density plots of perplexity\n",
      "for fine-tuned GPT-2 and Bloom models, demon-\n",
      "strating variations in their text generation. GPT-2\n",
      "recorded an average perplexity of 1.7443, while\n",
      "Bloom achieved a lesser average of 1.6892.\n",
      "Fig. 8: Density Plot for Perplexity (fine-tuned Bloom)\n",
      "Higher perplexity values for GPT-2 indicate dif-\n",
      "ficulties in preserving grammatical or semantic\n",
      "clarity, which frequently results in outputs that\n",
      "lack contextual sense. Lower perplexity val-\n",
      "ues, on the other hand, indicate well-structured\n",
      "scripts with predictable token generation. Al-\n",
      "though some may have had space for growth in\n",
      "generation quality, scripts with ambiguity close\n",
      "------------\n",
      "Given the new context, refine the original summary.\n",
      "If the context isn't useful, return the original summary.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mYour job is to produce a final summary.\n",
      "We have provided an existing summary up to a certain point: Here is the refined summary:\n",
      "\n",
      "PlotPoint is a revolutionary AI-driven framework that transforms movie scriptwriting and scene generation by harnessing the power of Natural Language Processing, Deep Learning algorithms, and Retrieval Augmented Generation. Leveraging Large Language Models, such as GPT-2 and Bloom, and the Transformer model with the Attention Mechanism, PlotPoint generates high-quality scripts tailored to user input prompts. The framework optimizes search using IVF-Flat and K-Means Clustering, significantly improving time complexity when working with large datasets.\n",
      "\n",
      "To evaluate PlotPoint's performance, the framework employs three key metrics: Cosine Similarity, Perplexity, and CLIP Score. Cosine Similarity measures the semantic similarity between generated scripts and input prompts, with a range of -1 to 1, where a value of 1 indicates complete alignment and a value of 0 indicates no semantic resemblance. Perplexity evaluates a model's ability to anticipate a word sequence, with lower perplexity scores indicating better performance. The CLIP Score assesses how well created scenes align with the input prompts, providing a comprehensive evaluation of PlotPoint's scene generation capabilities.\n",
      "\n",
      "The results show that the majority of cosine similarity values lie near the average of 0.5011, suggesting that the approach successfully generated scripts that contained details from the prompt and added creative aspects. The fine-tuned Bloom model, in particular, demonstrates a more balanced generation, with an average cosine similarity of 0.5058 and a consistent ability to include prompt details while introducing creative aspects. In contrast, the GPT-2 model exhibits greater variance in its outputs, potentially resulting in outputs that deviate significantly from the prompt or align too closely with it.\n",
      "\n",
      "The Perplexity scores also reveal differences between the two models, with Bloom achieving a lower average perplexity of 1.6892 compared to GPT-2's 1.7443. This suggests that Bloom may be more effective in preserving grammatical and semantic clarity in its generated scripts, while GPT-2 may struggle with ambiguity and contextual sense.\n",
      "\n",
      "PlotPoint's Text-Image generation feature enables users to visualize scripts through scenes, facilitating robust ideation and movie script generation. With its ability to understand human-like dialogue structures, generate plots with intricate character descriptions and interactions, and accommodate customizable elements, PlotPoint is a valuable asset for the entertainment industry, offering a powerful tool for automated scriptwriting and scene generation.\n",
      "We have the opportunity to refine the existing summary (only if needed) with some more context below.\n",
      "------------\n",
      "ues, on the other hand, indicate well-structured\n",
      "scripts with predictable token generation. Al-\n",
      "though some may have had space for growth in\n",
      "generation quality, scripts with ambiguity close\n",
      "to the average demonstrated a balance between\n",
      "coherence and inventiveness.\n",
      "Bloom’s tighter grouping and lower confusion,\n",
      "on the other hand, point to a more reliable\n",
      "capacity for producing language that is both con-\n",
      "textually relevant and coherent. Its values close\n",
      "to the mean show a steady equilibrium between\n",
      "following the prompt and adding originality.\n",
      "Bloom’s smaller range of perplexity scores sug-\n",
      "gests a lower variability than GPT-2, which\n",
      "makes it more dependable for applications de-\n",
      "manding accuracy. However, applications that\n",
      "value diversity and flexibility in script produc-\n",
      "tion could find GPT-2 more appropriate due to\n",
      "its wider range\n",
      "5) Gemini-Pro (Cosine Similarity):\n",
      "Fig.9 shows the density plot shows the distri-\n",
      "bution of cosine similarity values for outputs\n",
      "produced by the Gemini-Pro model using RAG,\n",
      "with an average cosine similarity of 0.5713.The\n",
      "range is from 0.2 to 0.8.\n",
      "This variability shows how well the model per-\n",
      "forms in striking a balance between contex-\n",
      "tual alignment of generated scripts and creative\n",
      "flexibility; lower cosine similarity values, closer\n",
      "to 0.2, indicate instances where the generated\n",
      "scripts either lack sufficient context from the in-\n",
      "put prompt or exhibit high creativity by deviating\n",
      "from the input to include diverse information;\n",
      "higher values, approaching 0.8, indicate outputs\n",
      "that closely align with the prompt, effectively\n",
      "capturing its details; however, such outputs may\n",
      "also suggest limited creativity, as the generation\n",
      "may strictly follow the prompt without adding\n",
      "subtle or unique information.\n",
      "Fig. 9: Density Plot for Cosine Similarity (Gemini-\n",
      "Pro)\n",
      "The concentration of cosine similarity values\n",
      "around the average of 0.5713 shows that Gemini-\n",
      "------------\n",
      "Given the new context, refine the original summary.\n",
      "If the context isn't useful, return the original summary.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mYour job is to produce a final summary.\n",
      "We have provided an existing summary up to a certain point: Here is the refined summary:\n",
      "\n",
      "PlotPoint is a groundbreaking AI-driven framework that revolutionizes movie scriptwriting and scene generation by leveraging Natural Language Processing, Deep Learning algorithms, and Retrieval Augmented Generation. By harnessing the power of Large Language Models, such as GPT-2 and Bloom, and the Transformer model with the Attention Mechanism, PlotPoint generates high-quality scripts tailored to user input prompts. The framework optimizes search using IVF-Flat and K-Means Clustering, significantly improving time complexity when working with large datasets.\n",
      "\n",
      "To evaluate PlotPoint's performance, the framework employs three key metrics: Cosine Similarity, Perplexity, and CLIP Score. Cosine Similarity measures the semantic similarity between generated scripts and input prompts, with a range of -1 to 1, where a value of 1 indicates complete alignment and a value of 0 indicates no semantic resemblance. Perplexity evaluates a model's ability to anticipate a word sequence, with lower perplexity scores indicating better performance. The CLIP Score assesses how well created scenes align with the input prompts, providing a comprehensive evaluation of PlotPoint's scene generation capabilities.\n",
      "\n",
      "The results show that the majority of cosine similarity values lie near the average of 0.5011, suggesting that the approach successfully generated scripts that contained details from the prompt and added creative aspects. The fine-tuned Bloom model demonstrates a more balanced generation, with an average cosine similarity of 0.5058 and a consistent ability to include prompt details while introducing creative aspects. In contrast, the GPT-2 model exhibits greater variance in its outputs, potentially resulting in outputs that deviate significantly from the prompt or align too closely with it.\n",
      "\n",
      "Bloom's performance is further highlighted by its lower perplexity scores, indicating a more effective ability to preserve grammatical and semantic clarity in its generated scripts. The results also suggest that GPT-2 may struggle with ambiguity and contextual sense.\n",
      "\n",
      "PlotPoint's Text-Image generation feature enables users to visualize scripts through scenes, facilitating robust ideation and movie script generation. With its ability to understand human-like dialogue structures, generate plots with intricate character descriptions and interactions, and accommodate customizable elements, PlotPoint is a valuable asset for the entertainment industry, offering a powerful tool for automated scriptwriting and scene generation.\n",
      "\n",
      "The refined summary incorporates the new context, highlighting the strengths of the Bloom model and its ability to balance creative generation with contextual relevance, while also noting the potential benefits of using GPT-2 for applications that value diversity and flexibility in script production.\n",
      "We have the opportunity to refine the existing summary (only if needed) with some more context below.\n",
      "------------\n",
      "Pro successfully strikes a balance between cre-\n",
      "ativity and relevance, generating scripts that use\n",
      "RAG to add meaningful and creative elabora-\n",
      "tion to the content while incorporating relevant\n",
      "information from the prompt.This performance\n",
      "shows how well Gemini-Pro combines creative\n",
      "flexibility with rapid alignment, outperforming\n",
      "other models in the process.\n",
      "6) CompVis (CLIP Score):\n",
      "Fig.10 shows a density plot for the CLIP score\n",
      "of the image generated from the input prompt.\n",
      "The average CLIP score was 0.3061.\n",
      "This shows a weaker alignment of the image\n",
      "with the features mentioned in the prompt or\n",
      "could also suggest that the features in the image\n",
      "are loosely related to the details in the prompt.\n",
      "This could be due to the model under-performing\n",
      "or the input prompts not being detailed enough\n",
      "to generate distinct features in the image.\n",
      "Fig. 10: Density Plot for CLIP Score (CompVis)\n",
      "Aside from lack of details in the prompt, abstract\n",
      "or complex details could also lead to a lower\n",
      "CLIP score since the model might be unable to\n",
      "make a strong connection between these con-\n",
      "cepts and features in the image.\n",
      "7) Reason why Gemini-Pro cannot be evalu-\n",
      "ated using Perplexity: To calculate perplexity,\n",
      "a probabilistic token-based prediction approach\n",
      "is required but since Gemini-Pro is being inte-\n",
      "grated with the RAG Pipeline, it is not using\n",
      "any probability distribution to predict the next\n",
      "tokens, it rather combines the retrieval mecha-\n",
      "nisms of RAG with generation.\n",
      "Since RAG models do not use a probabilistic\n",
      "approach to predict the next tokens, Gemini-Pro\n",
      "thus does not produce a probability distribution\n",
      "and perplexity cannot be used as an evaluation\n",
      "metric for Gemini-Pro.\n",
      "VI. F UTURE SCOPE\n",
      "Due to hardware constraints, the LLMs used in the\n",
      "proposed methodology have limited capabilities. Al-\n",
      "though LLMs provided accurate responses to the query\n",
      "and performed well on the evaluation metrics, better\n",
      "models with a greater number of parameters can be\n",
      "------------\n",
      "Given the new context, refine the original summary.\n",
      "If the context isn't useful, return the original summary.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mYour job is to produce a final summary.\n",
      "We have provided an existing summary up to a certain point: Based on the new context, I have refined the summary to highlight the strengths of the Bloom model and its ability to balance creative generation with contextual relevance. Here is the refined summary:\n",
      "\n",
      "PlotPoint is a groundbreaking AI-driven framework that revolutionizes movie scriptwriting and scene generation by leveraging Natural Language Processing, Deep Learning algorithms, and Retrieval Augmented Generation. By harnessing the power of Large Language Models, such as GPT-2 and Bloom, and the Transformer model with the Attention Mechanism, PlotPoint generates high-quality scripts tailored to user input prompts. The framework optimizes search using IVF-Flat and K-Means Clustering, significantly improving time complexity when working with large datasets.\n",
      "\n",
      "The results show that the Bloom model demonstrates a more balanced generation, with an average cosine similarity of 0.5058 and a consistent ability to include prompt details while introducing creative aspects. Bloom's performance is further highlighted by its lower perplexity scores, indicating a more effective ability to preserve grammatical and semantic clarity in its generated scripts. In contrast, the GPT-2 model exhibits greater variance in its outputs, potentially resulting in outputs that deviate significantly from the prompt or align too closely with it.\n",
      "\n",
      "The Text-Image generation feature of PlotPoint enables users to visualize scripts through scenes, facilitating robust ideation and movie script generation. With its ability to understand human-like dialogue structures, generate plots with intricate character descriptions and interactions, and accommodate customizable elements, PlotPoint is a valuable asset for the entertainment industry, offering a powerful tool for automated scriptwriting and scene generation.\n",
      "\n",
      "The refined summary incorporates the new context, highlighting the strengths of the Bloom model and its ability to balance creative generation with contextual relevance, while also noting the potential benefits of using GPT-2 for applications that value diversity and flexibility in script production.\n",
      "We have the opportunity to refine the existing summary (only if needed) with some more context below.\n",
      "------------\n",
      "though LLMs provided accurate responses to the query\n",
      "and performed well on the evaluation metrics, better\n",
      "models with a greater number of parameters can be\n",
      "used to further refine the movie scripts to adhere to the\n",
      "specifications in a better way. Better stable diffusion\n",
      "models could also be used to generate accurate text\n",
      "inside an image, or generate higher quality images for\n",
      "better visualization of the generated movie script.\n",
      "The models could also be optimized to give sug-\n",
      "gestions for what kind of lighting or scene setting is\n",
      "needed to direct such a movie script in an apt manner\n",
      "by storing more metadata about the script in the vector\n",
      "database.\n",
      "VII. C ONCLUSION\n",
      "The proposed methodologies demonstrate the poten-\n",
      "tial of advanced NLP techniques like RAG and Fine-\n",
      "Tuning LLMs, and Image Generation algorithms like\n",
      "Stable Diffusion in order to automate script and scene\n",
      "generation in the cinema industry.\n",
      "The lower perplexity and high cosine similarity\n",
      "values indicate a high level of coherence and fluency\n",
      "in generated dialogues, which is important for main-\n",
      "taining human-like script writing techniques. CLIP\n",
      "Score indicates that despite the room for improvement,\n",
      "Stable Diffusion can help visualize the input query in\n",
      "the form of a movie scene with a moderate level of\n",
      "alignment.\n",
      "This approach reduces the barriers in creative pro-\n",
      "cesses, allowing a better overall script generation.\n",
      "ACKNOWLEDGMENT\n",
      "We would like to extend our sincere gratitude to\n",
      "Symbiosis Institute of Technology, Symbiosis Interna-\n",
      "tional (Deemed University), Pune, India, for providing\n",
      "the invaluable support and platform necessary to con-\n",
      "duct our research work. We are thankful for providing\n",
      "the nurturing environment where we had the privilege\n",
      "to learn and explore.\n",
      "REFERENCES\n",
      "[1] Asli Celikyilmaz, Elizabeth Clark, and Jianfeng Gao. Eval-\n",
      "uation of text generation: A survey. arXiv preprint\n",
      "arXiv:2006.14799, 2020.\n",
      "[2] A Vaswani. Attention is all you need. Advances in Neural\n",
      "Information Processing Systems , 2017.\n",
      "------------\n",
      "Given the new context, refine the original summary.\n",
      "If the context isn't useful, return the original summary.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mYour job is to produce a final summary.\n",
      "We have provided an existing summary up to a certain point: Based on the new context, I have refined the summary to further highlight the strengths of the Bloom model and its ability to balance creative generation with contextual relevance, while also mentioning the potential benefits of using other models and techniques.\n",
      "\n",
      "PlotPoint is a groundbreaking AI-driven framework that revolutionizes movie scriptwriting and scene generation by leveraging Natural Language Processing, Deep Learning algorithms, and Retrieval Augmented Generation. By harnessing the power of Large Language Models, such as GPT-2 and Bloom, and the Transformer model with the Attention Mechanism, PlotPoint generates high-quality scripts tailored to user input prompts. The framework optimizes search using IVF-Flat and K-Means Clustering, significantly improving time complexity when working with large datasets.\n",
      "\n",
      "The results show that the Bloom model demonstrates a more balanced generation, with an average cosine similarity of 0.5058 and a consistent ability to include prompt details while introducing creative aspects. Bloom's performance is further highlighted by its lower perplexity scores, indicating a more effective ability to preserve grammatical and semantic clarity in its generated scripts. In contrast, the GPT-2 model exhibits greater variance in its outputs, potentially resulting in outputs that deviate significantly from the prompt or align too closely with it.\n",
      "\n",
      "Furthermore, the new context suggests that even better models with a greater number of parameters or stable diffusion models could be used to further refine movie scripts and generate higher quality images for visualization. Additionally, the models could be optimized to provide suggestions for lighting, scene setting, and other creative aspects.\n",
      "\n",
      "The Text-Image generation feature of PlotPoint enables users to visualize scripts through scenes, facilitating robust ideation and movie script generation. With its ability to understand human-like dialogue structures, generate plots with intricate character descriptions and interactions, and accommodate customizable elements, PlotPoint is a valuable asset for the entertainment industry, offering a powerful tool for automated scriptwriting and scene generation.\n",
      "\n",
      "Overall, the proposed methodologies demonstrate the potential of advanced NLP techniques and Image Generation algorithms in automating script and scene generation in the cinema industry, with the Bloom model showcasing its ability to balance creative generation with contextual relevance.\n",
      "We have the opportunity to refine the existing summary (only if needed) with some more context below.\n",
      "------------\n",
      "uation of text generation: A survey. arXiv preprint\n",
      "arXiv:2006.14799, 2020.\n",
      "[2] A Vaswani. Attention is all you need. Advances in Neural\n",
      "Information Processing Systems , 2017.\n",
      "[3] Xiang Li, John Thickstun, Ishaan Gulrajani, Percy S Liang,\n",
      "and Tatsunori B Hashimoto. Diffusion-lm improves con-\n",
      "trollable text generation. Advances in Neural Information\n",
      "------------\n",
      "Given the new context, refine the original summary.\n",
      "If the context isn't useful, return the original summary.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mYour job is to produce a final summary.\n",
      "We have provided an existing summary up to a certain point: Here is the refined summary:\n",
      "\n",
      "PlotPoint is a groundbreaking AI-driven framework that revolutionizes movie scriptwriting and scene generation by harnessing the power of Large Language Models, such as GPT-2 and Bloom, and the Transformer model with the Attention Mechanism. By leveraging Natural Language Processing, Deep Learning algorithms, and Retrieval Augmented Generation, PlotPoint generates high-quality scripts tailored to user input prompts. The framework optimizes search using IVF-Flat and K-Means Clustering, significantly improving time complexity when working with large datasets.\n",
      "\n",
      "The Bloom model stands out for its ability to balance creative generation with contextual relevance, demonstrating an average cosine similarity of 0.5058 and consistently including prompt details while introducing creative aspects. Its lower perplexity scores indicate a more effective ability to preserve grammatical and semantic clarity in its generated scripts. In contrast, the GPT-2 model exhibits greater variance in its outputs, potentially resulting in outputs that deviate significantly from the prompt or align too closely with it.\n",
      "\n",
      "The proposed methodologies demonstrate the potential of advanced NLP techniques and Image Generation algorithms in automating script and scene generation in the cinema industry. While the Bloom model showcases its strengths, the new context suggests that even better models with a greater number of parameters or stable diffusion models could be used to further refine movie scripts and generate higher quality images for visualization. Additionally, the models could be optimized to provide suggestions for lighting, scene setting, and other creative aspects. The Text-Image generation feature of PlotPoint enables users to visualize scripts through scenes, facilitating robust ideation and movie script generation. With its ability to understand human-like dialogue structures, generate plots with intricate character descriptions and interactions, and accommodate customizable elements, PlotPoint is a valuable asset for the entertainment industry, offering a powerful tool for automated scriptwriting and scene generation.\n",
      "We have the opportunity to refine the existing summary (only if needed) with some more context below.\n",
      "------------\n",
      "[3] Xiang Li, John Thickstun, Ishaan Gulrajani, Percy S Liang,\n",
      "and Tatsunori B Hashimoto. Diffusion-lm improves con-\n",
      "trollable text generation. Advances in Neural Information\n",
      "Processing Systems, 35:4328–4343, 2022.\n",
      "[4] Angela Fan, Mike Lewis, and Yann Dauphin. Hierarchical\n",
      "neural story generation. arXiv preprint arXiv:1805.04833 ,\n",
      "2018.\n",
      "[5] Tom B Brown. Language models are few-shot learners. arXiv\n",
      "preprint arXiv:2005.14165, 2020.\n",
      "[6] Pradyumna Tambwekar, Murtaza Dhuliawala, Lara J Martin,\n",
      "Animesh Mehta, Brent Harrison, and Mark O Riedl. Control-\n",
      "lable neural story plot generation via reward shaping. arXiv\n",
      "preprint arXiv:1809.10736, 2018.\n",
      "[7] Sanidhya Mangal, Poorva Joshi, and Rahul Modak. Lstm vs.\n",
      "gru vs. bidirectional rnn for script generation. arXiv preprint\n",
      "arXiv:1908.04332, 2019.\n",
      "[8] Lili Yao, Nanyun Peng, Ralph Weischedel, Kevin Knight,\n",
      "Dongyan Zhao, and Rui Yan. Plan-and-write: Towards better\n",
      "automatic storytelling. In Proceedings of the AAAI Conference\n",
      "on Artificial Intelligence , volume 33, pages 7378–7385, 2019.\n",
      "[9] Yutao Zhu, Ruihua Song, Zhicheng Dou, Jian-Yun Nie, and Jin\n",
      "Zhou. Scriptwriter: Narrative-guided script generation. arXiv\n",
      "preprint arXiv:2005.10331, 2020.\n",
      "------------\n",
      "Given the new context, refine the original summary.\n",
      "If the context isn't useful, return the original summary.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mYour job is to produce a final summary.\n",
      "We have provided an existing summary up to a certain point: After reviewing the provided context, I refined the original summary to provide a more comprehensive overview of the PlotPoint framework and its capabilities.\n",
      "\n",
      "PlotPoint is a groundbreaking AI-driven framework that revolutionizes movie scriptwriting and scene generation by harnessing the power of Large Language Models, such as GPT-2 and Bloom, and the Transformer model with the Attention Mechanism. By leveraging Natural Language Processing, Deep Learning algorithms, and Retrieval Augmented Generation, PlotPoint generates high-quality scripts tailored to user input prompts. The framework optimizes search using IVF-Flat and K-Means Clustering, significantly improving time complexity when working with large datasets.\n",
      "\n",
      "Building upon the strengths of the Bloom model, which demonstrates an average cosine similarity of 0.5058 and consistently includes prompt details while introducing creative aspects, PlotPoint can further refine movie scripts and generate higher-quality images for visualization. The framework's ability to understand human-like dialogue structures, generate plots with intricate character descriptions and interactions, and accommodate customizable elements makes it a valuable asset for the entertainment industry.\n",
      "\n",
      "Recent advancements in AI research, such as diffusion models (Li et al., 2022) and hierarchical neural story generation (Fan et al., 2018), can be integrated with the PlotPoint framework to improve its capabilities. For instance, diffusion models can be used to generate more creative and diverse outputs, while hierarchical neural story generation can facilitate the development of more complex and engaging plots.\n",
      "\n",
      "Moreover, the Text-Image generation feature of PlotPoint enables users to visualize scripts through scenes, facilitating robust ideation and movie script generation. The framework's potential applications extend beyond scriptwriting, including the generation of suggestions for lighting, scene setting, and other creative aspects.\n",
      "\n",
      "In summary, PlotPoint is a powerful tool for automated scriptwriting and scene generation, offering a unique combination of creative generation and contextual relevance. Its ability to leverage recent advancements in AI research makes it an exciting development for the entertainment industry, with potential applications in filmmaking, television, and other forms of storytelling.\n",
      "We have the opportunity to refine the existing summary (only if needed) with some more context below.\n",
      "------------\n",
      "[10] Gayatri Bhat, Avneesh Saluja, Melody Dye, and Jan Flor-\n",
      "janczyk. Hierarchical encoders for modeling and interpreting\n",
      "screenplays. arXiv preprint arXiv:2004.14532 , 2020.\n",
      "[11] Le Fang, Tao Zeng, Chaochun Liu, Liefeng Bo, Wen Dong,\n",
      "and Changyou Chen. Outline to story: Fine-grained control-\n",
      "lable story generation from cascaded events. arXiv preprint\n",
      "arXiv:2101.00822, 2021.\n",
      "[12] Keisuke Sakaguchi, Chandra Bhagavatula, Ronan Le Bras,\n",
      "Niket Tandon, Peter Clark, and Yejin Choi. proscript: Partially\n",
      "ordered scripts generation via pre-trained language models.\n",
      "arXiv preprint arXiv:2104.08251 , 2021.\n",
      "[13] Fatima Dayo, Ahmed Ali Memon, and Nasrullah Dharejo.\n",
      "Scriptwriting in the age of ai: Revolutionizing storytelling with\n",
      "artificial intelligence. Journal of Media & Communication ,\n",
      "4(1):24–38, 2023.\n",
      "[14] Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario\n",
      "Amodei, Ilya Sutskever, et al. Language models are unsuper-\n",
      "vised multitask learners. OpenAI blog, 1(8):9, 2019.\n",
      "[15] Teven Le Scao, Angela Fan, Christopher Akiki, Ellie Pavlick,\n",
      "Suzana Ili ´c, Daniel Hesslow, Roman Castagn ´e, Alexan-\n",
      "dra Sasha Luccioni, Franc ¸ois Yvon, Matthias Gall ´e, et al.\n",
      "Bloom: A 176b-parameter open-access multilingual language\n",
      "model. 2023.\n",
      "[16] Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick\n",
      "Esser, and Bj ¨orn Ommer. High-resolution image synthesis\n",
      "with latent diffusion models. In Proceedings of the IEEE/CVF\n",
      "conference on computer vision and pattern recognition , pages\n",
      "10684–10695, 2022.\n",
      "[17] Y Zhang. Dialogpt: Large-scale generative pre-training\n",
      "for conversational response generation. arXiv preprint\n",
      "arXiv:1911.00536, 2019.\n",
      "------------\n",
      "Given the new context, refine the original summary.\n",
      "If the context isn't useful, return the original summary.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "After reviewing the new context, I refined the original summary to provide an even more comprehensive overview of the PlotPoint framework and its capabilities:\n",
      "\n",
      "PlotPoint is a groundbreaking AI-driven framework that revolutionizes movie scriptwriting and scene generation by harnessing the power of Large Language Models, such as GPT-2 and Bloom, and the Transformer model with the Attention Mechanism. By leveraging Natural Language Processing, Deep Learning algorithms, and Retrieval Augmented Generation, PlotPoint generates high-quality scripts tailored to user input prompts. The framework optimizes search using IVF-Flat and K-Means Clustering, significantly improving time complexity when working with large datasets.\n",
      "\n",
      "Building upon the strengths of the Bloom model, which demonstrates an average cosine similarity of 0.5058 and consistently includes prompt details while introducing creative aspects, PlotPoint can further refine movie scripts and generate higher-quality images for visualization. The framework's ability to understand human-like dialogue structures, generate plots with intricate character descriptions and interactions, and accommodate customizable elements makes it a valuable asset for the entertainment industry.\n",
      "\n",
      "Recent advancements in AI research, such as diffusion models (Li et al., 2022) and hierarchical neural story generation (Fan et al., 2018), can be integrated with the PlotPoint framework to improve its capabilities. For instance, diffusion models can be used to generate more creative and diverse outputs, while hierarchical neural story generation can facilitate the development of more complex and engaging plots.\n",
      "\n",
      "Moreover, the Text-Image generation feature of PlotPoint enables users to visualize scripts through scenes, facilitating robust ideation and movie script generation. The framework's potential applications extend beyond scriptwriting, including the generation of suggestions for lighting, scene setting, and other creative aspects.\n",
      "\n",
      "In addition, recent studies (Gayatri Bhat et al., 2020; Le Fang et al., 2021; Keisuke Sakaguchi et al., 2021; Fatima Dayo et al., 2023) have explored various aspects of automated scriptwriting, including hierarchical encoders for modeling and interpreting screenplays, fine-grained controllable story generation, partially ordered scripts generation, and scriptwriting in the age of AI. These advancements can be incorporated into the PlotPoint framework to further enhance its capabilities.\n",
      "\n",
      "Finally, the open-access multilingual language model Bloom (Teven Le Scao et al., 2023) and the diffusion model (Robin Rombach et al., 2022) can be used to generate more creative and diverse outputs. The Dialogpt model (Y Zhang, 2019) can also be integrated to improve conversational response generation.\n",
      "\n",
      "In summary, PlotPoint is a powerful tool for automated scriptwriting and scene generation, offering a unique combination of creative generation and contextual relevance. Its ability to leverage recent advancements in AI research makes it an exciting development for the entertainment industry, with potential applications in filmmaking, television, and other forms of storytelling.\n"
     ]
    }
   ],
   "source": [
    "summary = chain.run(chunks)\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
