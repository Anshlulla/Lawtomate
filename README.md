# Lawtomate

The project presents application of Generative AI in Legal Tech to automate some of the legal workflows which would aid a lot of legal professionals and also those who know very little about the law. The application leverages the latest technologies like RAG, Voice Assistants and LLMs to help automate the workflows. It integrates a Python backend framework using FastAPI, a JavaScript frontend framework using ReactJS along with CSS and HTML, and database integration with MongoDB. The results were very accurate and it is proven that the automated legal workflows can thus be extremely beneficial in the legal industry. The use of vector databases like FAISS ensures the embeddings of the text or PDF uploaded, are stored efficiently and retrieved effectively while passing the context to the LLM.

## Google OAuth Integration
As the user accesses the web-application, they are supposed to sign up/login via their Google account. This is done via GoogleOAuth and implemented in ReactJS via npm’s `react-oauth/google`. On authentication, an OAuth token is returned which is sent to the backend for verification and exchanged for a signed `JWT`. This JWT is used in the workflows to map the user’s query with the LLM’s responses and the user’s email account.  

## Dashboard (Central Hub) 
After successful login, the user is directed to the dashboard which gives them access to all the four workflows along with a Logout option to terminate the session.

## Summarization Workflow
The user can use the summarization in two ways - either by uploading a PDF of the legal document or inputting some text to be summarized. The text is passed to the LLM and `MapReduce Summarization` is performed via Langchain to output a summary of multiple summaries (one for each chunk of the text). If the user uploads a PDF file, the PDF is processed via Python’s `PyMuPDF` library to extract the text and images from the file. This text is then passed to the LLM for summarization in the same way as above. After generating the summary, the workflow attaches a downloadable PDF of the summary, allowing users to store the summary locally or maybe forward it to clients or other employees.

## Analysis Workflow: RAG 
This workflow also allows the user to upload a PDF file to process and query over. Upon successful upload of the PDF, the workflow processes the document, converts the document into chunks and generates chunk embeddings which are stored in the vector database - `FAISS`. After processing the document, the user can ask the LLM any questions regarding the document and get clarity about what the document is about and what it contains. The responses from the LLM continue to remain context-specific because the most similar chunk embeddings are passed as part of context to the LLM.  

## Law-Search: Chatbot 
This workflow allows the user to ask any legal query and get it answered by the LLM. The UI ensures a smooth experience for the users. The LLM has the ability to answer legal queries based on any jurisdiction or region or any procedures/legal clauses. This enables users to get information and assistance on a global level instead of limiting it to a certain jurisdiction or region. Once the response is generated by the LLM, it is stored in a MongoDB database along with the query. The query-response pair is mapped by the user’s email ID used for authentication. The stored `MongoDB` documents in the collection act as part of the history (or memory) for the LLM, enabling it to remember or refer to the previous responses of the user to provide answers to any follow-up questions about the already generated responses. This feature makes the Chatbot versatile and extremely useful in providing legal assistance accurately and efficiently. 

## Lexi: Voice Assistant 
This AI-powered Voice Assistant helps users interact with the LLMs hands-free and still get as good responses as with the Chatbot interface. The service used for making the voice assistant is `VAPI`. It provides a GUI to make personalized voice assistants with LLM and Embeddings of choice. It also gives the analysis of latency and costs per API call. It is connected to the frontend and backend via the API URLs and provided with necessary system prompts to tailor the assistant to answer legal-related queries. 

## Workflow Diagram
![Workflow Diagram](https://github.com/user-attachments/assets/9994da02-f58d-4706-aac2-03d13fcd4258)


